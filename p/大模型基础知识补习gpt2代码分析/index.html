<!DOCTYPE html>
<html lang="zh-cn" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="实操一下GPT2的代码，深刻理解transformer模型的结构">
<title>大模型基础知识补习&amp;GPT2代码分析</title>

<link rel='canonical' href='https://JiangZhiyu-1024.github.io/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%A1%A5%E4%B9%A0gpt2%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/'>

<link rel="stylesheet" href="/scss/style.min.819ac8ff77246a79c226a136382b6bcbe7c291f9fd1e0641c81bcb97ac7e8f89.css"><meta property='og:title' content="大模型基础知识补习&GPT2代码分析">
<meta property='og:description' content="实操一下GPT2的代码，深刻理解transformer模型的结构">
<meta property='og:url' content='https://JiangZhiyu-1024.github.io/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%A1%A5%E4%B9%A0gpt2%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/'>
<meta property='og:site_name' content='Zion Blaze'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2025-01-10T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2025-01-10T00:00:00&#43;00:00'/><meta property='og:image' content='https://JiangZhiyu-1024.github.io/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%A1%A5%E4%B9%A0gpt2%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/tree-838666_1280.jpg' />
<meta name="twitter:title" content="大模型基础知识补习&GPT2代码分析">
<meta name="twitter:description" content="实操一下GPT2的代码，深刻理解transformer模型的结构"><meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content='https://JiangZhiyu-1024.github.io/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%A1%A5%E4%B9%A0gpt2%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/tree-838666_1280.jpg' />
    <link rel="shortcut icon" href="/favicon.ico" />

    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="切换菜单">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/fireflies1_hu11714070595552142014.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">🍥</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Zion Blaze</a></h1>
            <h2 class="site-description">Welcome to my world!</h2>
        </div>
    </header><ol class="menu-social">
            
                <li>
                    <a 
                        href='https://github.com/CaiJimmy/hugo-theme-stack'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>主页</span>
            </a>
        </li>
        
        
        <li >
            <a href='/%E5%85%B3%E4%BA%8E/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>关于</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>归档</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>搜索</span>
            </a>
        </li>
        
        
        <li >
            <a href='/%E5%8F%8B%E6%83%85%E9%93%BE%E6%8E%A5/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5" />
  <path d="M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5" />
</svg>



                
                <span>友情链接</span>
            </a>
        </li>
        
        <li class="menu-bottom-section">
            <ol class="menu">

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>暗色模式</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">目录</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#model">model</a>
      <ol>
        <li><a href="#词汇表">词汇表</a>
          <ol>
            <li><a href="#词汇表的作用">词汇表的作用：</a></li>
            <li><a href="#词汇表的组成">词汇表的组成：</a></li>
          </ol>
        </li>
        <li><a href="#向量空间vector-space">向量空间（Vector Space）</a></li>
        <li><a href="#嵌入embedding">嵌入（Embedding）</a></li>
        <li><a href="#向量vector">向量（Vector）</a></li>
        <li><a href="#为什么要使用嵌入">为什么要使用嵌入？</a></li>
        <li><a href="#归一化步骤">归一化步骤：</a></li>
        <li><a href="#代码解释">代码解释：</a></li>
        <li><a href="#总结">总结：</a></li>
        <li><a href="#主要特点">主要特点：</a></li>
        <li><a href="#函数签名">函数签名</a>
          <ol>
            <li><a href="#参数">参数：</a></li>
            <li><a href="#返回值">返回值：</a></li>
          </ol>
        </li>
        <li><a href="#模型实现">模型实现</a>
          <ol>
            <li><a href="#1-定义变量作用域">1. 定义变量作用域</a></li>
            <li><a href="#2-初始化变量">2. 初始化变量</a></li>
            <li><a href="#3-定义嵌入矩阵">3. 定义嵌入矩阵</a></li>
            <li><a href="#4-计算位置偏移">4. 计算位置偏移</a></li>
            <li><a href="#5-transformer-层的前向计算">5. Transformer 层的前向计算</a></li>
            <li><a href="#6-输出层归一化">6. 输出层归一化</a></li>
            <li><a href="#7-输出层计算">7. 输出层计算</a></li>
          </ol>
        </li>
        <li><a href="#总结-1">总结</a></li>
      </ol>
    </li>
    <li><a href="#encoder">encoder</a>
      <ol>
        <li><a href="#def-bytes_to_unicode-主要功能">def bytes_to_unicode() <strong>主要功能</strong></a></li>
        <li><a href="#def-get_pairsword主要功能">def get_pairs(word):<strong>主要功能</strong></a>
          <ol>
            <li><a href="#bpe-的来源"><strong>BPE 的来源</strong></a></li>
            <li><a href="#bpe-的基本思想"><strong>BPE 的基本思想</strong></a></li>
            <li><a href="#bpe-的优点"><strong>BPE 的优点</strong></a></li>
            <li><a href="#bpe-的示例"><strong>BPE 的示例</strong></a></li>
            <li><a href="#实际用途"><strong>实际用途</strong></a></li>
          </ol>
        </li>
        <li><a href="#class-encoder">class Encoder:</a>
          <ol>
            <li><a href="#1-__init__-方法初始化"><strong>1. <code>__init__</code> 方法：初始化</strong></a></li>
            <li><a href="#2-bpe-方法核心的-bpe-分词逻辑"><strong>2. <code>bpe</code> 方法：核心的 BPE 分词逻辑</strong></a></li>
            <li><a href="#3-encode-方法文本分词"><strong>3. <code>encode</code> 方法：文本分词</strong></a></li>
            <li><a href="#4-decode-方法id-解码"><strong>4. <code>decode</code> 方法：ID 解码</strong></a></li>
          </ol>
        </li>
        <li><a href="#def-get_encodermodel_name-models_dir">def get_encoder(model_name, models_dir)</a>
          <ol>
            <li><a href="#1-函数签名"><strong>1. 函数签名</strong></a></li>
            <li><a href="#2-加载-encoderjson-文件"><strong>2. 加载 <code>encoder.json</code> 文件</strong></a></li>
            <li><a href="#3-加载-vocabbpe-文件"><strong>3. 加载 <code>vocab.bpe</code> 文件</strong></a></li>
            <li><a href="#4-提取合并规则"><strong>4. 提取合并规则</strong></a></li>
            <li><a href="#5-创建-encoder-实例"><strong>5. 创建 <code>Encoder</code> 实例</strong></a></li>
            <li><a href="#代码整体作用总结"><strong>代码整体作用总结</strong></a></li>
            <li><a href="#应用场景"><strong>应用场景</strong></a></li>
            <li><a href="#示例调用"><strong>示例调用</strong></a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#sample">sample</a>
      <ol>
        <li>
          <ol>
            <li><a href="#1-函数签名-1"><strong>1. 函数签名</strong></a></li>
            <li><a href="#2-特殊情况k0"><strong>2. 特殊情况：k=0</strong></a></li>
            <li><a href="#3-内部函数-_top_k"><strong>3. 内部函数 <code>_top_k</code></strong></a></li>
            <li><a href="#step-1-获取-top-k-候选项的分数"><strong>Step 1: 获取 Top-K 候选项的分数</strong></a></li>
            <li><a href="#step-2-屏蔽低于-top-k-的分数"><strong>Step 2: 屏蔽低于 Top-K 的分数</strong></a></li>
            <li><a href="#4-条件执行"><strong>4. 条件执行</strong></a></li>
            <li><a href="#5-工作原理总结"><strong>5. 工作原理总结</strong></a></li>
            <li><a href="#代码运行示例"><strong>代码运行示例</strong></a></li>
            <li><a href="#应用场景-1"><strong>应用场景</strong></a></li>
            <li><a href="#1-函数签名-2"><strong>1. 函数签名</strong></a></li>
            <li><a href="#2-获取输入维度"><strong>2. 获取输入维度</strong></a></li>
            <li><a href="#3-对-logits-按分数降序排序"><strong>3. 对 logits 按分数降序排序</strong></a></li>
            <li><a href="#4-计算累积概率"><strong>4. 计算累积概率</strong></a></li>
            <li><a href="#5-找到超过阈值-p-的最小索引"><strong>5. 找到超过阈值 <code>p</code> 的最小索引</strong></a></li>
            <li><a href="#分步解释"><strong>分步解释</strong>：</a></li>
            <li><a href="#6-找到累积概率阈值对应的最小分数"><strong>6. 找到累积概率阈值对应的最小分数</strong></a></li>
            <li><a href="#7-屏蔽分数低于阈值的-logits"><strong>7. 屏蔽分数低于阈值的 logits</strong></a></li>
            <li><a href="#代码总结"><strong>代码总结</strong></a></li>
            <li><a href="#代码运行示例-1"><strong>代码运行示例</strong></a></li>
            <li><a href="#执行过程"><strong>执行过程</strong>：</a></li>
            <li><a href="#应用场景-2"><strong>应用场景</strong></a></li>
          </ol>
        </li>
        <li><a href="#def-sample_sequence">def sample_sequence</a>
          <ol>
            <li><a href="#1-函数签名和输入参数"><strong>1. 函数签名和输入参数</strong></a></li>
            <li><a href="#2-参数验证和初始上下文设置"><strong>2. 参数验证和初始上下文设置</strong></a></li>
            <li><a href="#3-定义生成单步的函数-step"><strong>3. 定义生成单步的函数 <code>step</code></strong></a></li>
            <li><a href="#4-定义生成循环的-body-函数"><strong>4. 定义生成循环的 <code>body</code> 函数</strong></a></li>
            <li><a href="#5-初始化第一步"><strong>5. 初始化第一步</strong></a></li>
            <li><a href="#6-定义循环条件和主体"><strong>6. 定义循环条件和主体</strong></a></li>
            <li><a href="#7-返回生成的序列"><strong>7. 返回生成的序列</strong></a></li>
            <li><a href="#工作流程总结"><strong>工作流程总结</strong></a></li>
            <li><a href="#应用场景-3"><strong>应用场景</strong></a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#generate_unconditional_samples">generate_unconditional_samples</a>
      <ol>
        <li><a href="#1-头部代码">1. <strong>头部代码</strong></a></li>
        <li><a href="#2-引入依赖库">2. <strong>引入依赖库</strong></a></li>
        <li><a href="#3-sample_model-函数">3. <strong><code>sample_model</code> 函数</strong></a>
          <ol>
            <li><a href="#参数说明"><strong>参数说明</strong></a></li>
          </ol>
        </li>
        <li><a href="#4-主函数">4. <strong>主函数</strong></a>
          <ol>
            <li><a href="#运行方式"><strong>运行方式</strong></a></li>
            <li><a href="#核心模块"><strong>核心模块</strong></a></li>
            <li><a href="#总结-2"><strong>总结</strong></a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#interactive_conditional_samples">interactive_conditional_samples</a>
      <ol>
        <li><a href="#1-头部部分"><strong>1. 头部部分</strong></a></li>
        <li><a href="#2-interact_model-函数"><strong>2. <code>interact_model</code> 函数</strong></a></li>
        <li><a href="#3-核心逻辑"><strong>3. 核心逻辑</strong></a></li>
        <li><a href="#6-主函数部分"><strong>6. 主函数部分</strong></a>
          <ol>
            <li><a href="#运行方式-1"><strong>运行方式</strong></a></li>
          </ol>
        </li>
        <li><a href="#总结-3"><strong>总结</strong></a></li>
      </ol>
    </li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="has-image main-article">
    <header class="article-header">
        <div class="article-image">
            <a href="/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%A1%A5%E4%B9%A0gpt2%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/">
                <img src="/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%A1%A5%E4%B9%A0gpt2%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/tree-838666_1280_hu1105538485009176982.jpg"
                        srcset="/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%A1%A5%E4%B9%A0gpt2%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/tree-838666_1280_hu1105538485009176982.jpg 800w, /p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%A1%A5%E4%B9%A0gpt2%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/tree-838666_1280_hu14457667872741287151.jpg 1600w"
                        width="800" 
                        height="527" 
                        loading="lazy"
                        alt="Featured image of post 大模型基础知识补习&amp;GPT2代码分析" />
                
            </a>
        </div>
    

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/llm/" >
                LLM
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%A1%A5%E4%B9%A0gpt2%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/">大模型基础知识补习&amp;GPT2代码分析</a>
        </h2>
    
        
        <h3 class="article-subtitle">
            实操一下GPT2的代码，深刻理解transformer模型的结构
        </h3>
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">2025-01-10</time>
            </div>
        

        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <h1 id="大模型基础知识">大模型基础知识
</h1><p>代码来源：https://github.com/openai/gpt-2</p>
<p>GPT2源代码提供了以下几个文件：</p>
<p>encoder.py</p>
<p>generate_unconditional_samples.py</p>
<p>interactive_conditional_samples.py</p>
<p>model.py</p>
<p>sample.py</p>
<h2 id="model">model
</h2><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">def default_hparams():
</span></span><span class="line"><span class="cl">    return HParams(
</span></span><span class="line"><span class="cl">        n_vocab=0,        # 词汇表大小（通常是词汇表中包含的词语或符号数量）
</span></span><span class="line"><span class="cl">        n_ctx=1024,       # 输入序列的最大长度（例如，一个输入文本序列的最大 token 数量）
</span></span><span class="line"><span class="cl">        n_embd=768,       # 嵌入层的维度大小（每个词或符号在嵌入空间中的表示长度）
</span></span><span class="line"><span class="cl">        n_head=12,        # 多头自注意力机制中的头数（即注意力头的数量）
</span></span><span class="line"><span class="cl">        n_layer=12,       # Transformer 模型中的层数（即堆叠的 transformer 层数）
</span></span><span class="line"><span class="cl">    )
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="词汇表">词汇表
</h3><p>词汇表（Vocabulary）是自然语言处理（NLP）模型中用于将语言转换为数字表示的一组词或符号的集合。在深度学习模型中，词汇表用于将文本数据中的每个单词或符号映射为一个唯一的数字（通常是一个整数），以便计算机能够理解和处理。</p>
<h4 id="词汇表的作用">词汇表的作用：
</h4><ol>
<li><strong>映射文本到数字</strong>：由于机器学习模型无法直接处理文本数据，必须将文本中的每个词或符号转换为数字。词汇表就是这个映射的核心工具。例如，对于句子“我爱自然语言处理”，我们需要将“我”、“爱”、“自然”、“语言”、“处理”这些词转化为模型可以理解的数字。</li>
<li><strong>限制模型输入的规模</strong>：在实际操作中，词汇表的大小有限。通常，我们不会为每个可能的字词创建一个索引，而是根据训练数据中出现的词汇频率来限制词汇表的大小。这样，词汇表的规模可以控制模型的输入维度，避免过大的计算和内存开销。</li>
<li><strong>处理未知词汇</strong>：词汇表通常会为所有未出现在训练数据中的词汇或符号保留一个特殊的“未知词”标记（如 <code>[UNK]</code>）。当模型遇到这些未见过的词时，会用这个特殊标记来代替。</li>
</ol>
<h4 id="词汇表的组成">词汇表的组成：
</h4><ol>
<li>
<p><strong>词</strong>：如果你使用的是基于单词的词汇表，那么词汇表中的元素就是单词。例如，假设你有一个很小的词汇表：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">css
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">复制代码
</span></span><span class="line"><span class="cl">[&#39;我&#39;, &#39;爱&#39;, &#39;自然&#39;, &#39;语言&#39;, &#39;处理&#39;]
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p><strong>子词</strong>（Subword）：对于一些较为复杂的语言模型，尤其是像 GPT-2 和 BERT 这样的模型，它们通常使用 <strong>子词</strong> 作为词汇表的基本单元。子词是一个比单词更小的语言单位，它可以是词的一部分或者是一个常见的词根、前缀、后缀等。例如，词汇表中可能包含 <code>##ing</code>、<code>un</code> 等子词单元，而不是整个单词 <code>running</code> 或 <code>undo</code>。这有助于模型更好地处理未见过的词汇，并减少词汇表的大小。</p>
</li>
<li>
<p><strong>特殊标记</strong>：除了实际的词或子词，词汇表通常还会包含一些特殊标记：</p>
<ul>
<li><code>[PAD]</code>：填充标记，用于将输入文本填充到相同的长度。</li>
<li><code>[UNK]</code>：未知标记，用于处理那些在训练集中没有出现过的词。</li>
<li><code>[CLS]</code>：分类标记，通常用于标记输入的开始（特别是在 BERT 等模型中）。</li>
<li><code>[SEP]</code>：分隔标记，通常用于分隔不同句子或文本段落（在 BERT 等模型中也有使用）。</li>
</ul>
</li>
</ol>
<h3 id="向量空间vector-space">向量空间（Vector Space）
</h3><p><strong>向量空间</strong>是一个数学概念，指的是所有向量的集合，可以在其中进行加法和标量乘法等操作。在机器学习和自然语言处理中，我们通常将每个词、子词或符号表示为一个高维空间中的向量。例如，一个简单的二维向量空间可能包含了这样的一组向量：</p>
<ul>
<li><code>(1, 0)</code></li>
<li><code>(0, 1)</code></li>
<li><code>(1, 1)</code></li>
</ul>
<p>在 NLP 中，这些向量并没有具体的几何含义，而是用来表示不同的语义特征。每个向量的元素（即各维度的值）代表了某种抽象的语义属性。</p>
<p><strong>词向量空间</strong>意味着每个词都被映射为一个向量，且这些向量之间有一定的关系。例如，&ldquo;king&rdquo; 和 &ldquo;queen&rdquo; 可能在向量空间中非常接近，因为它们的语义相似，尽管它们的拼写不同。嵌入的目标就是将语言中的词语、句子或其他语言单位映射到这样一个向量空间中。</p>
<h3 id="嵌入embedding">嵌入（Embedding）
</h3><p>**嵌入（Embedding）**是将一个离散的词汇项（如单词、子词）转换为连续的向量表示的过程。这些向量通常具有固定的维度（例如 300 维、768 维等），并且能够捕捉该词的语义信息。</p>
<p>换句话说，嵌入是对词汇的数字表示，它通过将每个词或符号映射到一个向量空间中，使得模型能够理解和处理语言中的复杂结构。</p>
<p>例如，假设你有以下三个词汇：</p>
<ul>
<li>&ldquo;猫&rdquo;（cat）</li>
<li>&ldquo;狗&rdquo;（dog）</li>
<li>&ldquo;汽车&rdquo;（car）</li>
</ul>
<p>通过嵌入，这些词语会被映射为固定长度的向量，例如：</p>
<ul>
<li>&ldquo;猫&rdquo; → <code>[0.45, 0.87, 0.34, ...]</code></li>
<li>&ldquo;狗&rdquo; → <code>[0.42, 0.89, 0.31, ...]</code></li>
<li>&ldquo;汽车&rdquo; → <code>[0.21, 0.08, 0.76, ...]</code></li>
</ul>
<p>这些向量的维度（例如 300 维或 768 维）反映了嵌入空间的复杂度。模型通过训练来优化这些向量，使得语义相似的词在嵌入空间中距离更近，语义不同的词距离较远。</p>
<h3 id="向量vector">向量（Vector）
</h3><p><strong>向量</strong>是在数学和计算机科学中用来表示方向和大小的对象。每个词或符号被嵌入为一个<strong>向量</strong>，这个向量通常是一个浮动的数字数组。向量的每个元素都表示一个特定的特征维度。</p>
<p>在 NLP 中，词的向量通常有以下几个特点：</p>
<ul>
<li><strong>稠密表示</strong>：每个词的向量是一个低维的稠密向量，不像传统的“one-hot”编码（仅使用0和1来表示词汇）。稠密向量包含了丰富的语义信息。</li>
<li><strong>语义关系</strong>：通过训练，词向量可以捕捉到词汇之间的语义关系。例如，“king” 和 “queen” 可能有相似的向量，因为它们共享许多语义特征。</li>
</ul>
<p>例如，假设我们训练了一个模型，得到以下的词向量：</p>
<ul>
<li>&ldquo;苹果&rdquo; → <code>[0.5, -0.2, 0.1, 0.7]</code></li>
<li>&ldquo;香蕉&rdquo; → <code>[0.4, -0.1, 0.2, 0.6]</code></li>
</ul>
<p>这些向量的数值表示了每个词的特征和语义信息。在训练过程中，模型会通过调整这些向量，使得语义相似的词的向量在空间中彼此接近。</p>
<h3 id="为什么要使用嵌入">为什么要使用嵌入？
</h3><ol>
<li><strong>捕捉语义相似性</strong>：通过嵌入，模型可以理解哪些词是相似的，哪些是不同的。比如“猫”和“狗”虽然拼写不同，但它们都是“动物”，因此它们的向量会很接近。</li>
<li><strong>降维</strong>：将词语从“one-hot”编码的高维空间（例如，假设有 10,000 个不同的词，one-hot 向量就是 10,000 维的）映射到一个低维空间（如 300 维）。这样可以减少计算的复杂度和内存消耗。</li>
<li><strong>增强模型理解</strong>：通过将词转换为向量，模型可以更加有效地理解文本中的语义、句法关系和上下文信息。这对于复杂的任务（如文本分类、情感分析、翻译等）非常重要。</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">shape_list</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Deal with dynamic shape in tensorflow cleanly.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">static</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>  <span class="c1"># 获取静态形状</span>
</span></span><span class="line"><span class="cl">    <span class="n">dynamic</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 获取动态形状</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="p">[</span><span class="n">dynamic</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">s</span> <span class="n">is</span> <span class="n">None</span> <span class="k">else</span> <span class="n">s</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">enumerate</span><span class="p">(</span><span class="k">static</span><span class="p">)]</span>  <span class="c1"># 返回合并后的形状</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol>
<li>
<p><strong><code>static = x.shape.as_list()</code></strong>：</p>
<ul>
<li><code>x.shape</code> 是 TensorFlow 张量 <code>x</code> 的静态形状。</li>
<li><code>as_list()</code> 将这个形状从 <code>TensorShape</code> 对象转换为 Python 列表。静态形状的值如果是已知的，会直接作为数值存在。如果某个维度的值是 <code>None</code>（表示该维度在静态形状中不确定），那么会是 <code>None</code>。</li>
<li>例如，如果 <code>x</code> 的形状是 <code>[None, 32, 32, 3]</code>，则 <code>static</code> 会是 <code>[None, 32, 32, 3]</code>。</li>
</ul>
</li>
<li>
<p><strong><code>dynamic = tf.shape(x)</code></strong>：</p>
<ul>
<li><code>tf.shape(x)</code> 返回张量 <code>x</code> 的动态形状，它是一个 TensorFlow 张量，表示运行时该张量的形状。与静态形状不同，动态形状会根据实际运行时的输入数据进行计算。</li>
<li>返回值是一个形状为 <code>[d0, d1, ..., dn]</code> 的张量（<code>d0</code>，<code>d1</code> 等是张量的各个维度的动态大小）。</li>
</ul>
</li>
<li>
<p><strong><code>return [dynamic[i] if s is None else s for i, s in enumerate(static)]</code></strong>：</p>
<ul>
<li>这个列表推导式的目的是将静态形状和动态形状合并成一个形状列表。如果某个静态形状的维度是 <code>None</code>（即在静态形状中未指定），那么就使用对应的动态形状。</li>
<li><code>enumerate(static)</code> 会遍历静态形状中的每个维度，如果该维度是 <code>None</code>，就从动态形状中取对应的维度值；如果该维度不是 <code>None</code>，则保留静态形状中的值。</li>
</ul>
<p>例如：</p>
<ul>
<li>假设 <code>static = [None, 32, 32, 3]</code>（第一维度 <code>None</code>，表示它是动态的）和 <code>dynamic = [64, 32, 32, 3]</code>（运行时该张量的实际形状是 <code>[64, 32, 32, 3]</code>）。</li>
<li>那么，函数的返回值将是 <code>[64, 32, 32, 3]</code>。</li>
</ul>
</li>
<li>
<p>为什么需要这个函数？</p>
</li>
</ol>
<p>在 TensorFlow 中，许多操作要求处理的张量形状是已知的（静态形状），但有些情况下形状在执行时才会动态确定，特别是在处理输入数据的批量大小、图像尺寸等变量时。<code>shape_list</code> 函数就是用来统一处理这两种情况的，使得无论是在静态还是动态形状下，代码都能够正常运行而不会出错。</p>
<ol start="5">
<li>举个例子：</li>
</ol>
<p>假设我们有一个张量 <code>x</code>，它的形状是 <code>[None, 64, 64, 3]</code>（批量大小未知）：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">import tensorflow as tf
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">x = tf.placeholder(tf.float32, shape=[None, 64, 64, 3])  # 动态批量大小
</span></span><span class="line"><span class="cl">shape = shape_list(x)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">print(shape)  # 输出形状
</span></span></code></pre></td></tr></table>
</div>
</div><p>在这个例子中，如果你传递一个大小为 <code>[32, 64, 64, 3]</code> 的输入，<code>shape_list</code> 函数会返回 <code>[32, 64, 64, 3]</code>，即将 <code>None</code> 替换为实际的批量大小 <code>32</code>。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">def softmax(x, axis=-1): 
</span></span><span class="line"><span class="cl">    x = x - tf.reduce_max(x, axis=axis, keepdims=True)
</span></span><span class="line"><span class="cl">    ex = tf.exp(x)
</span></span><span class="line"><span class="cl">    return ex / tf.reduce_sum(ex, axis=axis, keepdims=True)
</span></span></code></pre></td></tr></table>
</div>
</div><p>这个函数实现了 Softmax 操作，将输入 <code>x</code> 转换为概率分布，常用于多分类模型的输出层。通过减去最大值避免指数计算中的数值溢出，确保计算稳定性。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">def gelu(x):
</span></span><span class="line"><span class="cl">    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>GELU</strong> 是一种平滑的、概率性的激活函数，能够更自然地通过高斯分布近似非线性激活。相比于 ReLU，GELU 在训练时通常能更好地保留梯度，并且能够减少死神经元的问题。</p>
<p>代码中使用了 <code>tf.tanh</code> 和 <code>tf.pow</code>（TensorFlow 的函数）与 NumPy 的常量进行计算，确保了在 TensorFlow 中的高效计算。</p>
<p>Layer Normalization 是一种在深度学习中常用的技术，旨在对每个样本的特征进行归一化，使得特征的均值为0，方差为1，从而加速训练并提高模型的性能。</p>
<p>代码解释：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scope</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Normalize to mean = 0, std = 1, then do a diagonal affine transform.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">n_state</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
</span></span><span class="line"><span class="cl">        <span class="n">g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">n_state</span><span class="p">],</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">n_state</span><span class="p">],</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol>
<li><strong><code>x</code></strong>: 输入张量，通常是经过激活函数后的某一层的输出。</li>
<li><strong><code>scope</code></strong>: 变量作用域，用于创建和管理变量。</li>
<li><strong><code>axis=-1</code></strong>: 归一化时的维度，通常在 Layer Normalization 中是最后一维（即特征维度）。<code>axis=-1</code> 表示归一化最后一维，通常是一个样本的所有特征。</li>
<li><strong><code>epsilon=1e-5</code></strong>: 为了避免在除法中出现除零错误，<code>epsilon</code> 是一个很小的常数（默认值为 1e−51e-51e−5）。</li>
<li><strong><code>n_state = x.shape[-1].value</code></strong>: 获取输入张量 <code>x</code> 在最后一维的大小，代表特征数目。</li>
</ol>
<p>接下来，定义了两个变量 <code>g</code> 和 <code>b</code>，分别用于对归一化后的结果进行线性变换：</p>
<ul>
<li><strong><code>g</code></strong> 是缩放因子（通常称为 Gamma）。</li>
<li><strong><code>b</code></strong> 是平移因子（通常称为 Beta）。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl">       <span class="n">g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">n_state</span><span class="p">],</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">n_state</span><span class="p">],</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><code>g</code> 和 <code>b</code> 都是与输入 <code>x</code> 的最后一维特征数目相同的向量。<code>g</code> 初始化为 1，<code>b</code> 初始化为 0。</li>
</ul>
<h3 id="归一化步骤">归一化步骤：
</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">        u = tf.reduce_mean(x, axis=axis, keepdims=True)
</span></span><span class="line"><span class="cl">        s = tf.reduce_mean(tf.square(x - u), axis=axis, keepdims=True)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong><code>u = tf.reduce_mean(x, axis=axis, keepdims=True)</code></strong>: 计算输入 <code>x</code> 在指定 <code>axis</code> 维度上的均值（平均值）。这里，<code>axis</code> 默认为 -1，即沿着最后一维计算均值。</li>
<li><strong><code>s = tf.reduce_mean(tf.square(x - u), axis=axis, keepdims=True)</code></strong>: 计算输入 <code>x</code> 与均值 <code>u</code> 的差的平方的平均值，即方差。<code>keepdims=True</code> 保证输出维度与输入相同，便于后续操作。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">        x = (x - u) * tf.rsqrt(s + epsilon)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<dl>
<dt><code>x = (x - u) * tf.rsqrt(s + epsilon)</code></dt>
<dd>
<p>对输入</p>
</dd>
</dl>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">x
</span></span></code></pre></td></tr></table>
</div>
</div><p>进行标准化（即归一化处理），使得均值为 0，方差为 1。</p>
<ul>
<li><code>x - u</code>：减去均值，使得每个元素的均值为 0。</li>
<li><code>tf.rsqrt(s + epsilon)</code>：计算标准差的倒数并进行缩放，<code>rsqrt</code> 是 <code>1 / sqrt(x)</code>。<code>epsilon</code> 用于防止除 0 错误。</li>
</ul>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">        x = x * g + b
</span></span><span class="line"><span class="cl">        return x
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong><code>x = x \* g + b</code></strong>: 最后，对标准化后的 <code>x</code> 进行线性变换，使用参数 <code>g</code>（缩放因子）和 <code>b</code>（平移因子）。这种变换使得归一化的结果可以恢复一定的表达能力，类似于 Batch Normalization 中的 affine 变换。</li>
<li><strong><code>return x</code></strong>: 返回归一化并经过变换的结果。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">def split_states(x, n):
</span></span><span class="line"><span class="cl">    &#34;&#34;&#34;Reshape the last dimension of x into [n, x.shape[-1]/n].&#34;&#34;&#34;
</span></span><span class="line"><span class="cl">    *start, m = shape_list(x)
</span></span><span class="line"><span class="cl">    return tf.reshape(x, start + [n, m//n])
</span></span></code></pre></td></tr></table>
</div>
</div><p>这个函数 <code>split_states</code> 的作用是将输入张量 <code>x</code> 的最后一维拆分成两个部分，其中一个部分的大小是 <code>n</code>，另一个部分的大小是 <code>m // n</code>（<code>m</code> 是输入张量的最后一维大小）。</p>
<p><strong><code>\*start, m = shape_list(x)</code></strong>：</p>
<ul>
<li><code>shape_list(x)</code> 会返回张量 <code>x</code> 的形状（作为一个列表）。<code>*start</code> 会将除了最后一维之外的所有维度（即张量的前几维）存入 <code>start</code> 变量中，<code>m</code> 则保存张量最后一维的大小。</li>
<li>例如，如果 <code>x</code> 的形状是 <code>[batch_size, time_steps, features]</code>，那么 <code>start</code> 将保存 <code>[batch_size, time_steps]</code>，<code>m</code> 将保存 <code>features</code>。</li>
</ul>
<p><strong><code>tf.reshape(x, start + [n, m // n])</code></strong>：</p>
<ul>
<li><code>start</code> 是 <code>x</code> 的前几个维度的列表，<code>n</code> 是传入的参数，表示你想将最后一维拆分成 <code>n</code> 部分，<code>m // n</code> 是每一部分的大小。</li>
<li><code>tf.reshape</code> 函数将输入张量 <code>x</code> 重新调整形状，形状变为 <code>[start, n, m // n]</code>。</li>
<li>例如，如果 <code>x</code> 的形状是 <code>[batch_size, time_steps, features]</code>，并且传入 <code>n = 2</code>，那么新的形状将是 <code>[batch_size, time_steps, 2, features // 2]</code>。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">def merge_states(x):
</span></span><span class="line"><span class="cl">    &#34;&#34;&#34;Smash the last two dimensions of x into a single dimension.&#34;&#34;&#34;
</span></span><span class="line"><span class="cl">    *start, a, b = shape_list(x)
</span></span><span class="line"><span class="cl">    return tf.reshape(x, start + [a*b])
</span></span></code></pre></td></tr></table>
</div>
</div><p>这个函数 <code>merge_states</code> 的作用是将输入张量 <code>x</code> 的最后两个维度合并成一个维度。也就是说，它通过将最后两个维度相乘，将它们“压扁”为一个新的维度。</p>
<p><strong><code>\*start, a, b = shape_list(x)</code></strong>:</p>
<ul>
<li><code>shape_list(x)</code> 返回张量 <code>x</code> 的形状，作为一个列表。</li>
<li><code>*start</code> 会将 <code>x</code> 的所有维度（除了最后两个维度）存入 <code>start</code>，<code>a</code> 和 <code>b</code> 分别保存 <code>x</code> 的倒数第二维和最后一维的大小。</li>
</ul>
<p>举个例子：</p>
<ul>
<li>假设 <code>x</code> 的形状是 <code>[batch_size, time_steps, features, channels]</code>，那么 <code>start = [batch_size, time_steps, features]</code>，<code>a = features</code>，<code>b = channels</code>。</li>
</ul>
<p><strong><code>tf.reshape(x, start + [a \* b])</code></strong>:</p>
<ul>
<li><code>tf.reshape(x, start + [a * b])</code> 会将 <code>x</code> 重新调整形状，新的形状由 <code>start</code>（原先的所有维度，除了最后两个）和 <code>a * b</code>（将最后两个维度相乘的结果）组成。</li>
<li><code>a * b</code> 是将原本的最后两个维度合并成一个新的维度。</li>
</ul>
<p>这个 <code>conv1d</code> 函数实现了一个 <strong>1D 卷积</strong> 操作。虽然它的名字和传统的 1D 卷积类似，但它实际上通过矩阵乘法和适当的形状变换来模拟 1D 卷积的操作。以下是代码逐行解释：</p>
<h3 id="代码解释">代码解释：
</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">conv1d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scope</span><span class="p">,</span> <span class="n">nf</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">w_init_stdev</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="o">*</span><span class="n">start</span><span class="p">,</span> <span class="n">nx</span> <span class="o">=</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">nx</span><span class="p">,</span> <span class="n">nf</span><span class="p">],</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal_initializer</span><span class="p">(</span><span class="n">stddev</span><span class="o">=</span><span class="n">w_init_stdev</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">nf</span><span class="p">],</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">nx</span><span class="p">]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">nf</span><span class="p">]))</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">start</span> <span class="o">+</span> <span class="p">[</span><span class="n">nf</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">c</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol>
<li><strong><code>\*start, nx = shape_list(x)</code></strong>:
<ul>
<li><code>shape_list(x)</code> 返回张量 <code>x</code> 的形状，作为一个列表。<code>*start</code> 会将除了最后一维之外的所有维度（即张量的前几维）存入 <code>start</code>，<code>nx</code> 保存 <code>x</code> 的最后一维大小。</li>
<li>比如，如果 <code>x</code> 的形状是 <code>[batch_size, length, in_channels]</code>，那么 <code>start</code> 将是 <code>[batch_size, length]</code>，<code>nx</code> 就是 <code>in_channels</code>。</li>
</ul>
</li>
<li><strong><code>w = tf.get_variable('w', [1, nx, nf], initializer=tf.random_normal_initializer(stddev=w_init_stdev))</code></strong>:
<ul>
<li>创建一个卷积核（权重） <code>w</code>，其形状为 <code>[1, nx, nf]</code>。这里的 <code>1</code> 是卷积核的大小（即卷积操作是 1D 的），<code>nx</code> 是输入的最后一维大小（通常是输入通道数），<code>nf</code> 是卷积操作后输出通道的数量。</li>
<li><code>initializer=tf.random_normal_initializer(stddev=w_init_stdev)</code> 初始化权重值为从正态分布中采样，标准差为 <code>w_init_stdev</code>，默认为 <code>0.02</code>。</li>
</ul>
</li>
<li><strong><code>b = tf.get_variable('b', [nf], initializer=tf.constant_initializer(0))</code></strong>:
<ul>
<li>创建偏置 <code>b</code>，其形状为 <code>[nf]</code>，即与输出通道数相同，初始化为零。</li>
</ul>
</li>
<li><strong><code>c = tf.reshape(tf.matmul(tf.reshape(x, [-1, nx]), tf.reshape(w, [-1, nf])) + b, start + [nf])</code></strong>:
<ul>
<li><strong><code>tf.reshape(x, [-1, nx])</code></strong>: 将输入张量 <code>x</code> 重塑为形状 <code>[-1, nx]</code>，即将所有前面的维度展平，保留最后一维 <code>nx</code>。这一步相当于将输入的多维张量展平成二维矩阵，每一行代表一个数据样本的输入通道。</li>
<li><strong><code>tf.reshape(w, [-1, nf])</code></strong>: 将卷积核 <code>w</code> 重塑为形状 <code>[-1, nf]</code>，这意味着卷积核的权重被展平为一个矩阵，其中每个输入通道的权重被分配到输出通道。</li>
<li><strong><code>tf.matmul(...)</code></strong>: 执行矩阵乘法。此处是将展平后的输入张量 <code>x</code> 与展平后的卷积核 <code>w</code> 相乘，类似于卷积操作中的加权求和过程。</li>
<li><strong><code>+ b</code></strong>: 将偏置加到结果中。</li>
<li><strong><code>tf.reshape(..., start + [nf])</code></strong>: 将矩阵乘法后的结果再重塑回原来的形状，保留除了最后一维以外的所有维度，最后一维变为 <code>nf</code>，即输出通道数。</li>
</ul>
</li>
<li><strong><code>return c</code></strong>:
<ul>
<li>返回卷积操作后的结果 <code>c</code>，它的形状是 <code>[batch_size, length, nf]</code>，即输出的批次大小、长度和输出通道数。</li>
</ul>
</li>
</ol>
<h3 id="总结">总结：
</h3><p>这个 <code>conv1d</code> 函数实现的是一种通过矩阵乘法模拟 1D 卷积操作的方式。传统的 1D 卷积通过滑动窗口对输入进行局部加权求和，而这个实现通过将输入展平成矩阵后与卷积核进行矩阵乘法，从而实现类似的效果。</p>
<h3 id="主要特点">主要特点：
</h3><ul>
<li><strong>权重形状</strong>：<code>[1, nx, nf]</code>，表示卷积核的大小为 <code>1xnx</code>，即卷积操作是对输入的每个位置进行加权求和，输出通道数为 <code>nf</code>。</li>
<li><strong>矩阵乘法实现卷积</strong>：通过 <code>tf.matmul</code> 将输入张量和卷积核做矩阵乘法，而不是传统的滑动窗口卷积。</li>
<li><strong>展平操作</strong>：输入张量和卷积核都通过 <code>tf.reshape</code> 进行了展平处理，以便进行矩阵乘法。</li>
</ul>
<p>这种方法虽然在实现上与传统的卷积不同，但效果是相同的，并且可以通过矩阵乘法的方式提高计算效率或适应某些特定的任务需求。</p>
<p>这段代码定义了一个函数 <code>attention_mask</code>，用于生成注意力掩码（attention mask）</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">attention_mask</span><span class="p">(</span><span class="n">nd</span><span class="p">,</span> <span class="n">ns</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;1&#39;s in the lower triangle, counting from the lower right corner.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn&#39;t produce garbage on TPUs.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">nd</span><span class="p">)[:,</span><span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">j</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">m</span> <span class="o">=</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">j</span> <span class="o">-</span> <span class="n">ns</span> <span class="o">+</span> <span class="n">nd</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这个函数实现了一个多头注意力（Multi-head Attention）机制：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scope</span><span class="p">,</span> <span class="n">n_state</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">past</span><span class="p">,</span> <span class="n">hparams</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="o">==</span> <span class="mi">3</span>  <span class="c1"># Should be [batch, sequence, features]</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="n">n_state</span> <span class="o">%</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_head</span> <span class="o">==</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">past</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="n">past</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="o">==</span> <span class="mi">5</span>  <span class="c1"># Should be [batch, 2, heads, sequence, features], where 2 is [k, v]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">split_heads</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># From [batch, sequence, features] to [batch, heads, sequence, features]</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">split_states</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_head</span><span class="p">),</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">merge_heads</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Reverse of split_heads</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">merge_states</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">mask_attn_weights</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">nd</span><span class="p">,</span> <span class="n">ns</span> <span class="o">=</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">b</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">(</span><span class="n">nd</span><span class="p">,</span> <span class="n">ns</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">w</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nd</span><span class="p">,</span> <span class="n">ns</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">*</span><span class="n">b</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="mf">1e10</span><span class="p">,</span> <span class="n">w</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">w</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">multihead_attn</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># q, k, v have shape [batch, heads, sequence, features]</span>
</span></span><span class="line"><span class="cl">        <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">w</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">w</span> <span class="o">=</span> <span class="n">mask_attn_weights</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">w</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">a</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">c</span> <span class="o">=</span> <span class="n">conv1d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;c_attn&#39;</span><span class="p">,</span> <span class="n">n_state</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">split_heads</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">present</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">past</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">pk</span><span class="p">,</span> <span class="n">pv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">past</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">k</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">pk</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">pv</span><span class="p">,</span> <span class="n">v</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">a</span> <span class="o">=</span> <span class="n">multihead_attn</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">a</span> <span class="o">=</span> <span class="n">merge_heads</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">a</span> <span class="o">=</span> <span class="n">conv1d</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="s1">&#39;c_proj&#39;</span><span class="p">,</span> <span class="n">n_state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">a</span><span class="p">,</span> <span class="n">present</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这段代码定义了一个多层感知机 (MLP) 模块，通常在深度学习模型中用于非线性变换：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">mlp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scope</span><span class="p">,</span> <span class="n">n_state</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">hparams</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">nx</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
</span></span><span class="line"><span class="cl">        <span class="n">h</span> <span class="o">=</span> <span class="n">gelu</span><span class="p">(</span><span class="n">conv1d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;c_fc&#39;</span><span class="p">,</span> <span class="n">n_state</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">h2</span> <span class="o">=</span> <span class="n">conv1d</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="s1">&#39;c_proj&#39;</span><span class="p">,</span> <span class="n">nx</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">h2</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这段代码实现了一个标准的 Transformer 块，其中包括以下步骤：</p>
<ol>
<li><strong>层归一化 + 自注意力机制 + 残差连接</strong>。</li>
<li><strong>层归一化 + 多层感知机（MLP） + 残差连接</strong>。</li>
<li>返回更新后的输出 <code>x</code> 和注意力层的缓存 <code>present</code>。</li>
</ol>
<p>这个设计符合 Transformer 模型的标准结构，适用于自然语言处理任务中的序列建模。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scope</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">past</span><span class="p">,</span> <span class="n">hparams</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">nx</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
</span></span><span class="line"><span class="cl">        <span class="n">a</span><span class="p">,</span> <span class="n">present</span> <span class="o">=</span> <span class="n">attn</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;ln_1&#39;</span><span class="p">),</span> <span class="s1">&#39;attn&#39;</span><span class="p">,</span> <span class="n">nx</span><span class="p">,</span> <span class="n">past</span><span class="o">=</span><span class="n">past</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">a</span>
</span></span><span class="line"><span class="cl">        <span class="n">m</span> <span class="o">=</span> <span class="n">mlp</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;ln_2&#39;</span><span class="p">),</span> <span class="s1">&#39;mlp&#39;</span><span class="p">,</span> <span class="n">nx</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">m</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">present</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong><code>past_shape</code></strong>: 定义缓存张量的形状，用于存储注意力的 Key 和 Value。</p>
<p><strong><code>expand_tile</code></strong>: 扩展输入张量的维度，并复制以适配批量处理。</p>
<p><strong><code>positions_for</code></strong>: 生成位置索引序列，并考虑历史时间步偏移。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">def past_shape(*, hparams, batch_size=None, sequence=None):
</span></span><span class="line"><span class="cl">    return [batch_size, hparams.n_layer, 2, hparams.n_head, sequence, hparams.n_embd // hparams.n_head]
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">def expand_tile(value, size):
</span></span><span class="line"><span class="cl">    &#34;&#34;&#34;Add a new axis of given size.&#34;&#34;&#34;
</span></span><span class="line"><span class="cl">    value = tf.convert_to_tensor(value, name=&#39;value&#39;)
</span></span><span class="line"><span class="cl">    ndims = value.shape.ndims
</span></span><span class="line"><span class="cl">    return tf.tile(tf.expand_dims(value, axis=0), [size] + [1]*ndims)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">def positions_for(tokens, past_length):
</span></span><span class="line"><span class="cl">    batch_size = tf.shape(tokens)[0]
</span></span><span class="line"><span class="cl">    nsteps = tf.shape(tokens)[1]
</span></span><span class="line"><span class="cl">    return expand_tile(past_length + tf.range(nsteps), batch_size)
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">hparams</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">past</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="n">reuse</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">        <span class="n">batch</span><span class="p">,</span> <span class="n">sequence</span> <span class="o">=</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">wpe</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;wpe&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span><span class="p">,</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_embd</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                             <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal_initializer</span><span class="p">(</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">wte</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;wte&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">hparams</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">,</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_embd</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                             <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal_initializer</span><span class="p">(</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.02</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">past_length</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">past</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">past</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">wte</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">wpe</span><span class="p">,</span> <span class="n">positions_for</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">past_length</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Transformer</span>
</span></span><span class="line"><span class="cl">        <span class="n">presents</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="n">pasts</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">past</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">past</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_layer</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">pasts</span><span class="p">)</span> <span class="o">==</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_layer</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">past</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pasts</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">h</span><span class="p">,</span> <span class="n">present</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">,</span> <span class="n">past</span><span class="o">=</span><span class="n">past</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">presents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">present</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">results</span><span class="p">[</span><span class="s1">&#39;present&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">presents</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">h</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="s1">&#39;ln_f&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Language model loss.  Do tokens &lt;n predict token n?</span>
</span></span><span class="line"><span class="cl">        <span class="n">h_flat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="p">[</span><span class="n">batch</span><span class="o">*</span><span class="n">sequence</span><span class="p">,</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_embd</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">h_flat</span><span class="p">,</span> <span class="n">wte</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">sequence</span><span class="p">,</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">results</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">logits</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">results</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这段代码定义了一个深度学习模型 <code>model</code>，它实现了一个基于 Transformer 的语言模型（如 GPT）。以下是代码的详细解释：</p>
<hr>
<h3 id="函数签名">函数签名
</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">hparams</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">past</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="参数">参数：
</h4><ul>
<li>
<p><strong><code>hparams</code></strong>: 超参数对象，包含模型的配置（如嵌入维度、上下文长度、词汇表大小等）。</p>
</li>
<li>
<p><strong><code>X</code></strong>: 输入张量，形状为 <code>[batch_size, sequence_length]</code>，表示输入的 token 序列（通常是词的索引）。</p>
</li>
<li>
<dl>
<dt><code>past</code></dt>
<dd>
<p>缓存张量，存储来自先前时间步的注意力状态（Key 和 Value）。形状为：</p>
</dd>
</dl>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">n_layer</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">past_length</span><span class="p">,</span> <span class="n">n_embd</span><span class="o">//</span><span class="n">n_head</span><span class="p">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>如果为空，则表示模型从头开始推理。</p>
</li>
<li>
<p><strong><code>scope</code></strong>: 变量作用域的名称。</p>
</li>
<li>
<p><strong><code>reuse</code></strong>: 是否重用作用域内的变量（用于变量共享）。</p>
</li>
</ul>
<h4 id="返回值">返回值：
</h4><p>一个字典 <code>results</code>，包含：</p>
<ul>
<li><strong><code>present</code></strong>: 当前层的注意力缓存状态。</li>
<li><strong><code>logits</code></strong>: 模型的输出（未归一化的概率分布）。</li>
</ul>
<hr>
<h3 id="模型实现">模型实现
</h3><h4 id="1-定义变量作用域">1. 定义变量作用域
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="n">reuse</span><span class="p">):</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>使用 TensorFlow 的变量作用域，确保变量命名唯一，并支持变量共享。</li>
</ul>
<h4 id="2-初始化变量">2. 初始化变量
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">batch</span><span class="p">,</span> <span class="n">sequence</span> <span class="o">=</span> <span class="n">shape_list</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>使用 <code>shape_list</code> 获取输入 <code>X</code> 的批次大小（<code>batch</code>）和序列长度（<code>sequence</code>）。</li>
</ul>
<h4 id="3-定义嵌入矩阵">3. 定义嵌入矩阵
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">wpe</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;wpe&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span><span class="p">,</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_embd</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal_initializer</span><span class="p">(</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">wte</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;wte&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">hparams</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">,</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_embd</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                      <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal_initializer</span><span class="p">(</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.02</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong><code>wpe</code></strong>: 位置嵌入矩阵，形状为 <code>[上下文长度, 嵌入维度]</code>。</li>
<li><strong><code>wte</code></strong>: 词嵌入矩阵，形状为 <code>[词汇表大小, 嵌入维度]</code>。</li>
<li>使用随机正态分布初始化权重。</li>
</ul>
<h4 id="4-计算位置偏移">4. 计算位置偏移
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">past_length</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">past</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">past</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">wte</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">wpe</span><span class="p">,</span> <span class="n">positions_for</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">past_length</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong><code>past_length</code></strong>: 如果没有缓存 <code>past</code>，则 <code>past_length=0</code>，否则为缓存的时间步长度。</li>
<li><strong><code>tf.gather(wte, X)</code></strong>: 通过索引 <code>X</code> 获取词嵌入。</li>
<li><strong><code>tf.gather(wpe, positions_for(X, past_length))</code></strong>: 获取位置嵌入（利用 <code>positions_for</code> 生成位置索引）。</li>
<li>将词嵌入和位置嵌入相加，得到初始的输入表示 <code>h</code>。</li>
</ul>
<hr>
<h4 id="5-transformer-层的前向计算">5. Transformer 层的前向计算
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">presents</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="n">pasts</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">past</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">past</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_layer</span>
</span></span><span class="line"><span class="cl"><span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">pasts</span><span class="p">)</span> <span class="o">==</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_layer</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong><code>presents</code></strong>: 存储当前层的注意力状态（Key 和 Value）。</li>
<li><strong><code>pasts</code></strong>: 如果存在缓存，则按层解包缓存张量；否则初始化为空。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">past</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pasts</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">h</span><span class="p">,</span> <span class="n">present</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="s1">&#39;h</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">,</span> <span class="n">past</span><span class="o">=</span><span class="n">past</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">presents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">present</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">results</span><span class="p">[</span><span class="s1">&#39;present&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">presents</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>遍历每一层的 Transformer 块 ：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">block
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>传入输入表示 <code>h</code> 和当前层的缓存状态 <code>past</code>。</li>
<li>计算输出 <code>h</code> 和当前层的注意力状态 <code>present</code>。</li>
</ul>
</li>
<li>
<p>将所有层的 <code>present</code> 堆叠，形状为 <code>[batch_size, n_layer, 2, n_head, sequence, n_embd//n_head]</code>，并存入结果字典。</p>
</li>
</ul>
<hr>
<h4 id="6-输出层归一化">6. 输出层归一化
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">h</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="s1">&#39;ln_f&#39;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>对最后一层的输出 <code>h</code> 进行层归一化（Layer Normalization）。</li>
</ul>
<hr>
<h4 id="7-输出层计算">7. 输出层计算
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">h_flat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="p">[</span><span class="n">batch</span><span class="o">*</span><span class="n">sequence</span><span class="p">,</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_embd</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">h_flat</span><span class="p">,</span> <span class="n">wte</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">sequence</span><span class="p">,</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">results</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">logits</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong><code>h_flat</code></strong>: 将 <code>h</code> 重塑为二维张量 <code>[batch*sequence, 嵌入维度]</code>，方便后续矩阵乘法操作。</li>
<li><code>logits</code>:
<ul>
<li>与词嵌入矩阵 <code>wte</code> 的转置相乘，计算每个 token 的得分（未归一化概率）。</li>
<li>将结果重塑为 <code>[batch, sequence, vocab_size]</code>。</li>
</ul>
</li>
<li>将 <code>logits</code> 存入结果字典。</li>
</ul>
<hr>
<h3 id="总结-1">总结
</h3><ul>
<li><strong>输入</strong>：词序列 <code>X</code> 和缓存状态 <code>past</code>。</li>
<li><strong>词和位置嵌入</strong>：通过词嵌入和位置嵌入初始化输入表示。</li>
<li>Transformer 层：
<ul>
<li>通过多层 Transformer 块（包含注意力机制和 MLP）计算表示。</li>
<li>保存当前时间步的注意力状态。</li>
</ul>
</li>
<li><strong>输出层</strong>：通过词嵌入矩阵的转置计算每个 token 的 logits。</li>
<li>返回值：
<ul>
<li><strong><code>present</code></strong>：当前层的注意力缓存。</li>
<li><strong><code>logits</code></strong>：预测下一个 token 的分布。</li>
</ul>
</li>
</ul>
<p>这是一个标准的基于 Transformer 的语言模型，常用于生成任务或语言建模任务中（如 GPT）。</p>
<h2 id="encoder">encoder
</h2><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;Byte pair encoding utilities&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">json</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">regex</span> <span class="k">as</span> <span class="nn">re</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">lru_cache</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@lru_cache</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">bytes_to_unicode</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Returns list of utf-8 byte and a corresponding list of unicode strings.
</span></span></span><span class="line"><span class="cl"><span class="s2">    The reversible bpe codes work on unicode strings.
</span></span></span><span class="line"><span class="cl"><span class="s2">    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.
</span></span></span><span class="line"><span class="cl"><span class="s2">    When you&#39;re at something like a 10B token dataset you end up needing around 5K for decent coverage.
</span></span></span><span class="line"><span class="cl"><span class="s2">    This is a signficant percentage of your normal, say, 32K bpe vocab.
</span></span></span><span class="line"><span class="cl"><span class="s2">    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.
</span></span></span><span class="line"><span class="cl"><span class="s2">    And avoids mapping to whitespace/control characters the bpe code barfs on.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">bs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&#34;!&#34;</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&#34;~&#34;</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">+</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&#34;¡&#34;</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&#34;¬&#34;</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">+</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&#34;®&#34;</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&#34;ÿ&#34;</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">cs</span> <span class="o">=</span> <span class="n">bs</span><span class="p">[:]</span>
</span></span><span class="line"><span class="cl">    <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">8</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">b</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">bs</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">bs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">cs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">8</span><span class="o">+</span><span class="n">n</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="n">cs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">chr</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">cs</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">cs</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Return set of symbol pairs in a word.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">    Word is represented as tuple of symbols (symbols being variable-length strings).
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">pairs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">prev_char</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">word</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
</span></span><span class="line"><span class="cl">        <span class="n">pairs</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">prev_char</span><span class="p">,</span> <span class="n">char</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">prev_char</span> <span class="o">=</span> <span class="n">char</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">pairs</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Encoder</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">bpe_merges</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;replace&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">errors</span> <span class="o">=</span> <span class="n">errors</span> <span class="c1"># how to handle errors in decoding</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span> <span class="o">=</span> <span class="n">bytes_to_unicode</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">))))</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">pat</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&#34;&#34;&#34;&#39;s|&#39;t|&#39;re|&#39;ve|&#39;m|&#39;ll|&#39;d| ?\p</span><span class="si">{L}</span><span class="s2">+| ?\p</span><span class="si">{N}</span><span class="s2">+| ?[^\s\p</span><span class="si">{L}</span><span class="s2">\p</span><span class="si">{N}</span><span class="s2">]+|\s+(?!\S)|\s+&#34;&#34;&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">bpe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="n">pairs</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">token</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">bigram</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">pair</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">pair</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">bigram</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">break</span>
</span></span><span class="line"><span class="cl">            <span class="n">first</span><span class="p">,</span> <span class="n">second</span> <span class="o">=</span> <span class="n">bigram</span>
</span></span><span class="line"><span class="cl">            <span class="n">new_word</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">            <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="n">j</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                    <span class="n">i</span> <span class="o">=</span> <span class="n">j</span>
</span></span><span class="line"><span class="cl">                <span class="k">except</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:])</span>
</span></span><span class="line"><span class="cl">                    <span class="k">break</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">first</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">second</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">first</span><span class="o">+</span><span class="n">second</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">                <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">            <span class="n">new_word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_word</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">word</span> <span class="o">=</span> <span class="n">new_word</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">break</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">word</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">word</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">bpe_tokens</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pat</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">token</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">token</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">bpe_tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="n">bpe_token</span><span class="p">]</span> <span class="k">for</span> <span class="n">bpe_token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe</span><span class="p">(</span><span class="n">token</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">bpe_tokens</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">text</span> <span class="o">=</span> <span class="nb">bytearray</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">errors</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">text</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_encoder</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">models_dir</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">models_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="s1">&#39;encoder.json&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">encoder</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">models_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="s1">&#39;vocab.bpe&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&#34;utf-8&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">bpe_data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">bpe_merges</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">merge_str</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">merge_str</span> <span class="ow">in</span> <span class="n">bpe_data</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">Encoder</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">bpe_merges</span><span class="o">=</span><span class="n">bpe_merges</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="def-bytes_to_unicode-主要功能">def bytes_to_unicode() <strong>主要功能</strong>
</h3><ul>
<li><strong>字节到 Unicode 的双向映射</strong>： 该函数实现了 <code>utf-8</code> 字节到 Unicode 字符的映射，确保：
<ol>
<li>所有常见字符都能直接映射。</li>
<li>额外的字节值（控制字符或空白字符等）映射到专用的 Unicode 字符（避免与常规字符冲突）。</li>
</ol>
</li>
<li><strong>应用场景</strong>：
<ul>
<li><strong>分词（Tokenization）</strong>： 在基于 BPE 的分词方法中，通常操作的是 Unicode 字符而不是字节。这个映射表允许在处理文本时，轻松地将字节表示与 Unicode 表示互相转换。</li>
<li><strong>减少未登录词（UNK）</strong>： 通过将所有字节映射到特定的 Unicode 字符，能够有效避免未登录词（UNK）的问题。</li>
</ul>
</li>
</ul>
<h3 id="def-get_pairsword主要功能">def get_pairs(word):<strong>主要功能</strong>
</h3><ul>
<li>符号对提取：
<ul>
<li>用于提取单词中相邻符号的所有可能组合（无重复）。</li>
<li>符号可以是单个字符，也可以是更大的单位（如字节或子词）。</li>
</ul>
</li>
<li>BPE 算法中的作用：
<ul>
<li>在 Byte Pair Encoding (BPE) 分词算法中：
<ul>
<li>通过提取符号对，可以统计每对符号出现的频率。</li>
<li>根据频率合并最常见的符号对，逐步生成新的子词。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Byte Pair Encoding (BPE)</strong> 是一种简单而高效的数据压缩算法，同时也是自然语言处理（NLP）领域中广泛使用的分词技术。它通过将低级单元（如字符或字节）合并成更大的单元（如子词）来实现压缩或分词。</p>
<hr>
<h4 id="bpe-的来源"><strong>BPE 的来源</strong>
</h4><ol>
<li><strong>数据压缩</strong>：
<ul>
<li>BPE 最初是用于压缩数据的一种算法（提出于 1994 年）。它通过不断将数据中出现频率最高的相邻字节对合并为新的单个字节来减少整体数据量。</li>
</ul>
</li>
<li><strong>自然语言处理中的应用</strong>：
<ul>
<li>在 NLP 中，BPE 被用作一种 <strong>子词（subword）分词方法</strong>。</li>
<li>传统的分词方法（如基于空格或词典分词）容易遇到未登录词（OOV, Out-Of-Vocabulary）问题。而 BPE 通过将单词分解成子词，可以有效减少未登录词的出现，同时提高模型的泛化能力。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="bpe-的基本思想"><strong>BPE 的基本思想</strong>
</h4><p>BPE 的核心思想是：<strong>找到并合并文本数据中出现频率最高的相邻符号对，直到达到预设的词汇表大小或其他停止条件</strong>。</p>
<p><strong>关键步骤</strong>：</p>
<ol>
<li><strong>初始化</strong>：
<ul>
<li>将文本中的每个单词拆分为基本符号（如字符或字节）。
<ul>
<li>示例：<code>&quot;word&quot;</code> → <code>['w', 'o', 'r', 'd']</code></li>
</ul>
</li>
</ul>
</li>
<li><strong>统计符号对</strong>：
<ul>
<li>找出所有相邻符号对，并统计它们的频率。
<ul>
<li>示例：<code>['w', 'o', 'r', 'd']</code> 中的符号对：<code>('w', 'o')</code>, <code>('o', 'r')</code>, <code>('r', 'd')</code></li>
</ul>
</li>
</ul>
</li>
<li><strong>合并最频繁的符号对</strong>：
<ul>
<li>找到频率最高的符号对，将其合并为新的符号。
<ul>
<li>示例：合并 <code>('o', 'r')</code> → <code>['w', 'or', 'd']</code></li>
</ul>
</li>
</ul>
</li>
<li><strong>重复步骤 2 和 3</strong>：
<ul>
<li>不断统计新的符号对并进行合并，直到满足预设条件（如词汇表大小达到限制）。
<ul>
<li>示例：继续合并 <code>('w', 'or')</code> → <code>['wor', 'd']</code></li>
<li>再合并 <code>('wor', 'd')</code> → <code>['word']</code></li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h4 id="bpe-的优点"><strong>BPE 的优点</strong>
</h4><ol>
<li><strong>减少未登录词（OOV）问题</strong>：
<ul>
<li>即使遇到从未见过的单词，也可以将其分解为子词或字符进行处理。
<ul>
<li>如单词 <code>unbelievable</code>，如果整个单词不在词汇表中，BPE 可能将其分解为 <code>[&quot;un&quot;, &quot;believ&quot;, &quot;able&quot;]</code>。</li>
</ul>
</li>
</ul>
</li>
<li><strong>提高模型效率</strong>：
<ul>
<li>子词分词可以显著减少词汇表大小，同时保留对罕见单词的处理能力。</li>
</ul>
</li>
<li><strong>适应多语言处理</strong>：
<ul>
<li>BPE 能够灵活地处理字符和子词，特别适用于多种语言的分词需求。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="bpe-的示例"><strong>BPE 的示例</strong>
</h4><p>以 <code>&quot;low lower lowest&quot;</code> 为例，假设目标是生成 BPE 词汇表。</p>
<ol>
<li>
<p><strong>初始状态</strong>：</p>
<ul>
<li>将单词拆解为字符：<code>['l', 'o', 'w']</code>, <code>['l', 'o', 'w', 'e', 'r']</code>, <code>['l', 'o', 'w', 'e', 's', 't']</code></li>
</ul>
</li>
<li>
<p><strong>统计符号对频率</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">(&#39;l&#39;, &#39;o&#39;): 3
</span></span><span class="line"><span class="cl">(&#39;o&#39;, &#39;w&#39;): 3
</span></span><span class="line"><span class="cl">(&#39;w&#39;, &#39;e&#39;): 2
</span></span><span class="line"><span class="cl">(&#39;e&#39;, &#39;r&#39;): 1
</span></span><span class="line"><span class="cl">(&#39;e&#39;, &#39;s&#39;): 1
</span></span><span class="line"><span class="cl">(&#39;s&#39;, &#39;t&#39;): 1
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p><strong>合并频率最高的符号对</strong>：</p>
<ul>
<li>
<p>合并</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">(&#39;l&#39;, &#39;o&#39;)
</span></span></code></pre></td></tr></table>
</div>
</div><p>→ 新的单词序列：</p>
<ul>
<li><code>['lo', 'w']</code>, <code>['lo', 'w', 'e', 'r']</code>, <code>['lo', 'w', 'e', 's', 't']</code></li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>重复统计与合并</strong>：</p>
<ul>
<li>
<p>再次统计符号对，并合并：</p>
<ul>
<li>
<p>合并</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">(&#39;lo&#39;, &#39;w&#39;)
</span></span></code></pre></td></tr></table>
</div>
</div><p>→ 新的单词序列：</p>
<ul>
<li><code>['low']</code>, <code>['low', 'e', 'r']</code>, <code>['low', 'e', 's', 't']</code></li>
</ul>
</li>
</ul>
</li>
<li>
<p>最终，可能得到：</p>
<ul>
<li><code>['low']</code>, <code>['lower']</code>, <code>['lowest']</code></li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h4 id="实际用途"><strong>实际用途</strong>
</h4><ol>
<li><strong>语言模型</strong>：
<ul>
<li>主流预训练语言模型（如 GPT、BERT）的分词方法往往基于 BPE 或类似方法（如 WordPiece）。</li>
<li>这些模型会基于大规模语料构建一个子词词汇表。</li>
</ul>
</li>
<li><strong>文本压缩</strong>：
<ul>
<li>BPE 可用于减少数据存储占用，如在数据传输和存储优化中。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="class-encoder">class Encoder:
</h3><p>这段代码定义了一个 <code>Encoder</code> 类，用于实现基于 <strong>Byte Pair Encoding (BPE)</strong> 的分词（tokenization）和解码（detokenization）过程。它在自然语言处理中非常有用，特别是在构建和使用基于子词的语言模型时。以下是代码的逐步解析：</p>
<hr>
<h4 id="1-__init__-方法初始化"><strong>1. <code>__init__</code> 方法：初始化</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">bpe_merges</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;replace&#39;</span><span class="p">):</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>参数</strong>：</p>
<ul>
<li><code>encoder</code>: 一个映射，将 BPE 子词（tokens）映射到唯一的整数 ID。</li>
<li><code>bpe_merges</code>: BPE 合并操作列表，表示哪些符号对应该被优先合并。</li>
<li><code>errors</code>: 在解码过程中如何处理错误，默认为 <code>'replace'</code>。</li>
</ul>
</li>
<li>
<p><strong>初始化内容</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
</span></span><span class="line"><span class="cl"><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><code>self.encoder</code>：用于编码文本（子词 → ID）。</li>
<li><code>self.decoder</code>：用于解码文本（ID → 子词），通过反转 <code>encoder</code> 构建。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span> <span class="o">=</span> <span class="n">bytes_to_unicode</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><code>self.byte_encoder</code>：字节到 Unicode 字符的映射表（使用之前定义的 <code>bytes_to_unicode()</code>）。</li>
<li><code>self.byte_decoder</code>：反向映射，用于将 Unicode 字符转换回字节。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">))))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>将 <code>bpe_merges</code> 转换为字典 <code>bpe_ranks</code>，用来快速查找符号对的优先级（频率越高，rank 越小）。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="p">{}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>缓存字典，用于存储已经计算过的 BPE 分词结果，避免重复计算。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="bp">self</span><span class="o">.</span><span class="n">pat</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&#34;&#34;&#34;&#39;s|&#39;t|&#39;re|&#39;ve|&#39;m|&#39;ll|&#39;d| ?\p</span><span class="si">{L}</span><span class="s2">+| ?\p</span><span class="si">{N}</span><span class="s2">+| ?[^\s\p</span><span class="si">{L}</span><span class="s2">\p</span><span class="si">{N}</span><span class="s2">]+|\s+(?!\S)|\s+&#34;&#34;&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>分词正则表达式：
<ul>
<li>匹配子词、数字、标点符号和空格。</li>
<li>例如，<code>&quot;I'm learning BPE.&quot;</code> 会被分成：<code>[&quot;I&quot;, &quot;'m&quot;, &quot;learning&quot;, &quot;BPE&quot;, &quot;.&quot;]</code>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="2-bpe-方法核心的-bpe-分词逻辑"><strong>2. <code>bpe</code> 方法：核心的 BPE 分词逻辑</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">bpe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>输入</strong>：一个字符串 <code>token</code>。</p>
</li>
<li>
<p><strong>功能</strong>：对输入的字符串执行 BPE 操作，将其分解为 BPE 子词。</p>
</li>
<li>
<p>步骤</p>
<p>：</p>
<ol>
<li>
<p><strong>缓存检查</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>如果 <code>token</code> 已经计算过，直接返回缓存结果。</p>
</li>
<li>
<p><strong>初始化</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>将 <code>token</code> 转换为元组（字符序列），例如：<code>&quot;low&quot;</code> → <code>('l', 'o', 'w')</code>。</li>
<li>调用 <code>get_pairs</code> 提取相邻字符对。</li>
</ul>
</li>
<li>
<p><strong>循环合并符号对</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">bigram</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">pair</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">pair</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">bigram</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">break</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>找出当前符号对中优先级（rank）最高的 <code>bigram</code>。</li>
<li>如果 <code>bigram</code> 不在 <code>bpe_ranks</code> 中，结束循环。</li>
</ul>
<p><strong>符号对合并逻辑</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">first</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">second</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">first</span><span class="o">+</span><span class="n">second</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">i</span> <span class="o">+=</span> <span class="mi">2</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>如果找到匹配的符号对，合并成一个新符号。</li>
</ul>
</li>
<li>
<p><strong>缓存结果</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
</span></span><span class="line"><span class="cl"><span class="k">return</span> <span class="n">word</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>将分词结果存入缓存并返回。</li>
</ul>
</li>
</ol>
</li>
</ul>
<hr>
<h4 id="3-encode-方法文本分词"><strong>3. <code>encode</code> 方法：文本分词</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>输入</strong>：字符串 <code>text</code>。</p>
</li>
<li>
<p><strong>功能</strong>：对输入文本执行分词，返回对应的 token ID 列表。</p>
</li>
<li>
<p>步骤</p>
<p>：</p>
<ol>
<li>
<p><strong>正则匹配</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pat</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>使用 <code>self.pat</code> 对文本进行分词。</p>
</li>
<li>
<p><strong>字节编码</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">token</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">token</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>将每个分词转换为 UTF-8 字节，然后通过 <code>byte_encoder</code> 映射为 Unicode 字符。</p>
</li>
<li>
<p><strong>BPE 分词</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">bpe_tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="n">bpe_token</span><span class="p">]</span> <span class="k">for</span> <span class="n">bpe_token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe</span><span class="p">(</span><span class="n">token</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>调用 <code>bpe</code> 方法对子词执行 BPE 操作。</li>
<li>将结果映射为 token ID。</li>
</ul>
</li>
<li>
<p><strong>返回结果</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">return</span> <span class="n">bpe_tokens</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>返回所有 token ID 的列表。</p>
</li>
</ol>
</li>
</ul>
<hr>
<h4 id="4-decode-方法id-解码"><strong>4. <code>decode</code> 方法：ID 解码</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>输入</strong>：整数列表 <code>tokens</code>（token IDs）。</p>
</li>
<li>
<p><strong>功能</strong>：将 token ID 解码为原始文本。</p>
</li>
<li>
<p>步骤</p>
<p>：</p>
<ol>
<li>
<p><strong>子词还原</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>使用 <code>self.decoder</code> 将 token ID 映射回子词。</p>
</li>
<li>
<p><strong>字节解码</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">text</span> <span class="o">=</span> <span class="nb">bytearray</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">errors</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>使用 <code>byte_decoder</code> 将 Unicode 字符转换回字节。</li>
<li>将字节解码为 UTF-8 文本。</li>
</ul>
</li>
<li>
<p><strong>返回结果</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">return</span> <span class="n">text</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
</li>
</ul>
<hr>
<h3 id="def-get_encodermodel_name-models_dir">def get_encoder(model_name, models_dir)
</h3><p>这段代码定义了一个函数 <code>get_encoder</code>，它用于加载和初始化一个 <code>Encoder</code> 实例，通常用于自然语言处理任务（例如基于 BPE 的分词器）。下面是具体的功能和步骤解析：</p>
<hr>
<h4 id="1-函数签名"><strong>1. 函数签名</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_encoder</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">models_dir</span><span class="p">):</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>参数</p>
<p>：</p>
<ul>
<li><code>model_name</code>: 模型的名称（字符串），表示特定模型文件所在的子目录名称。</li>
<li><code>models_dir</code>: 存储模型文件的主目录路径。</li>
</ul>
</li>
<li>
<p>返回值</p>
<p>：</p>
<ul>
<li>返回一个 <code>Encoder</code> 对象，用于分词和解码。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="2-加载-encoderjson-文件"><strong>2. 加载 <code>encoder.json</code> 文件</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">models_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="s1">&#39;encoder.json&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">encoder</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>功能</p>
<p>：</p>
<ul>
<li>打开模型目录中的 <code>encoder.json</code> 文件。</li>
<li>使用 <code>json.load</code> 解析 JSON 文件内容，加载编码器（<code>encoder</code>）。</li>
</ul>
</li>
<li>
<p><code>encoder.json</code> 的作用</p>
<p>：</p>
<ul>
<li>
<p>是一个 <strong>映射文件</strong>，将每个子词（BPE token）映射到唯一的整数 ID。</p>
</li>
<li>
<p>格式示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-json" data-lang="json"><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&#34;hello&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&#34;world&#34;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&#34;h&#34;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&#34;ello&#34;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="err">...</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
</li>
</ul>
<hr>
<h4 id="3-加载-vocabbpe-文件"><strong>3. 加载 <code>vocab.bpe</code> 文件</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">models_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="s1">&#39;vocab.bpe&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&#34;utf-8&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">bpe_data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>功能</p>
<p>：</p>
<ul>
<li>打开模型目录中的 <code>vocab.bpe</code> 文件（UTF-8 编码）。</li>
<li>使用 <code>f.read()</code> 读取整个文件内容到字符串 <code>bpe_data</code> 中。</li>
</ul>
</li>
<li>
<p><code>vocab.bpe</code> 的作用</p>
<p>：</p>
<ul>
<li>
<p>是一个 <strong>BPE 合并规则文件</strong>，定义了所有符号对的合并顺序。</p>
</li>
<li>
<p>格式示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">#version: 0.2
</span></span><span class="line"><span class="cl">h e
</span></span><span class="line"><span class="cl">he llo
</span></span><span class="line"><span class="cl">lo w
</span></span><span class="line"><span class="cl">...
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>每行表示一个符号对（例如 <code>h e</code>）。</li>
<li>第一行是注释，通常表示文件版本。</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="4-提取合并规则"><strong>4. 提取合并规则</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">bpe_merges</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">merge_str</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">merge_str</span> <span class="ow">in</span> <span class="n">bpe_data</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong>功能</strong>：
<ul>
<li>从 <code>bpe_data</code> 中提取 BPE 合并规则，跳过第一行注释（<code>[1:]</code>）。</li>
<li>使用 <code>split()</code> 将每行内容分割成符号对（元组）。</li>
<li>例如：
<ul>
<li>输入：<code>&quot;h e\nhe llo\nlo w\n&quot;</code></li>
<li>结果：<code>[('h', 'e'), ('he', 'llo'), ('lo', 'w')]</code></li>
</ul>
</li>
</ul>
</li>
<li><strong><code>bpe_merges</code> 的作用</strong>：
<ul>
<li>定义了符号对合并的优先顺序，用于 BPE 分词。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="5-创建-encoder-实例"><strong>5. 创建 <code>Encoder</code> 实例</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">return</span> <span class="n">Encoder</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">bpe_merges</span><span class="o">=</span><span class="n">bpe_merges</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong>功能</strong>：
<ul>
<li>使用 <code>encoder</code> 和 <code>bpe_merges</code> 创建一个 <code>Encoder</code> 对象。</li>
<li>将 <code>Encoder</code> 返回，以便调用者可以使用其 <code>encode</code> 和 <code>decode</code> 方法进行分词和解码。</li>
</ul>
</li>
<li><strong>参数传递到 <code>Encoder</code> 的内容</strong>：
<ul>
<li><code>encoder</code>: 将子词映射到整数 ID 的字典。</li>
<li><code>bpe_merges</code>: BPE 合并规则（优先级按列表顺序定义）。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="代码整体作用总结"><strong>代码整体作用总结</strong>
</h4><ul>
<li>输入：
<ul>
<li>模型名称（<code>model_name</code>）和模型文件所在目录（<code>models_dir</code>）。</li>
</ul>
</li>
<li>功能：
<ul>
<li>从指定目录中加载：
<ol>
<li>子词到整数 ID 的映射文件（<code>encoder.json</code>）。</li>
<li>BPE 合并规则文件（<code>vocab.bpe</code>）。</li>
</ol>
</li>
<li>初始化一个 <code>Encoder</code> 对象，具备分词和解码功能。</li>
</ul>
</li>
<li>输出：
<ul>
<li>一个可以直接用于分词和解码的 <code>Encoder</code> 实例。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="应用场景"><strong>应用场景</strong>
</h4><ul>
<li>
<p>模型分词初始化：</p>
<ul>
<li>在基于子词（如 GPT、BERT）训练的语言模型中，<code>get_encoder</code> 通常用于加载与模型对应的分词器。</li>
</ul>
</li>
<li>
<p>分词和解码：</p>
<ul>
<li>
<p>加载完成后，</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Encoder
</span></span></code></pre></td></tr></table>
</div>
</div><p>对象可以用来：</p>
<ul>
<li><strong>分词</strong>：将文本转为 token ID。</li>
<li><strong>解码</strong>：将 token ID 还原为文本。</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="示例调用"><strong>示例调用</strong>
</h4><p>假设模型目录为 <code>&quot;models/&quot;</code>，模型名称为 <code>&quot;gpt2&quot;</code>，文件结构如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">models/
</span></span><span class="line"><span class="cl">├── gpt2/
</span></span><span class="line"><span class="cl">│   ├── encoder.json
</span></span><span class="line"><span class="cl">│   ├── vocab.bpe
</span></span></code></pre></td></tr></table>
</div>
</div><p>调用代码：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">encoder</span> <span class="o">=</span> <span class="n">get_encoder</span><span class="p">(</span><span class="s1">&#39;gpt2&#39;</span><span class="p">,</span> <span class="s1">&#39;models/&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">text</span> <span class="o">=</span> <span class="s2">&#34;Hello, world!&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">tokens</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>  <span class="c1"># 输出分词后的 token ID 列表</span>
</span></span><span class="line"><span class="cl"><span class="n">decoded_text</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">decoded_text</span><span class="p">)</span>  <span class="c1"># 输出解码后的原始文本</span>
</span></span></code></pre></td></tr></table>
</div>
</div><hr>
<h2 id="sample">sample
</h2><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span><span class="lnt">88
</span><span class="lnt">89
</span><span class="lnt">90
</span><span class="lnt">91
</span><span class="lnt">92
</span><span class="lnt">93
</span><span class="lnt">94
</span><span class="lnt">95
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">top_k_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># no truncation</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">logits</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">_top_k</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">values</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">min_values</span> <span class="o">=</span> <span class="n">values</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">logits</span> <span class="o">&lt;</span> <span class="n">min_values</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">logits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">logits</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">       <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">       <span class="k">lambda</span><span class="p">:</span> <span class="n">logits</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">       <span class="k">lambda</span><span class="p">:</span> <span class="n">_top_k</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">top_p_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Nucleus sampling&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">sorted_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s1">&#39;DESCENDING&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">cumulative_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">sorted_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">        <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># number of indices to include</span>
</span></span><span class="line"><span class="cl">        <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">cumulative_probs</span> <span class="o">&lt;=</span> <span class="n">p</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">min_values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">sorted_logits</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">logits</span> <span class="o">&lt;</span> <span class="n">min_values</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">logits</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">sample_sequence</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">hparams</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">start_token</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">start_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="n">context</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Specify exactly one of start_token and context!&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="n">context</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Specify exactly one of start_token and context!&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="n">context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">start_token</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="n">hparams</span><span class="p">,</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">past</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">lm_output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">tokens</span><span class="p">,</span> <span class="n">past</span><span class="o">=</span><span class="n">past</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">AUTO_REUSE</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">logits</span> <span class="o">=</span> <span class="n">lm_output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">][:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">hparams</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">presents</span> <span class="o">=</span> <span class="n">lm_output</span><span class="p">[</span><span class="s1">&#39;present&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">presents</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">past_shape</span><span class="p">(</span><span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;logits&#39;</span><span class="p">:</span> <span class="n">logits</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s1">&#39;presents&#39;</span><span class="p">:</span> <span class="n">presents</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;sample_sequence&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">body</span><span class="p">(</span><span class="n">past</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">next_outputs</span> <span class="o">=</span> <span class="n">step</span><span class="p">(</span><span class="n">hparams</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">past</span><span class="o">=</span><span class="n">past</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">logits</span> <span class="o">=</span> <span class="n">next_outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>  <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">temperature</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">logits</span> <span class="o">=</span> <span class="n">top_k_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">top_k</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">logits</span> <span class="o">=</span> <span class="n">top_p_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">top_p</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">samples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">                <span class="n">next_outputs</span><span class="p">[</span><span class="s1">&#39;presents&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">past</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">past</span><span class="p">,</span> <span class="n">next_outputs</span><span class="p">[</span><span class="s1">&#39;presents&#39;</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                <span class="n">samples</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">output</span><span class="p">,</span> <span class="n">samples</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">past</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="n">body</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">cond</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">cond</span><span class="o">=</span><span class="n">cond</span><span class="p">,</span> <span class="n">body</span><span class="o">=</span><span class="n">body</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">loop_vars</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">                <span class="n">past</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">prev</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">output</span>
</span></span><span class="line"><span class="cl">            <span class="p">],</span>
</span></span><span class="line"><span class="cl">            <span class="n">shape_invariants</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">                <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">past_shape</span><span class="p">(</span><span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)),</span>
</span></span><span class="line"><span class="cl">                <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
</span></span><span class="line"><span class="cl">                <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
</span></span><span class="line"><span class="cl">            <span class="p">],</span>
</span></span><span class="line"><span class="cl">            <span class="n">back_prop</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">tokens</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这段代码定义了一个函数 <code>top_k_logits</code>，用于对 logits（模型的输出分布）进行 <strong>Top-K 限制</strong>。Top-K 策略是一种在生成任务（如文本生成）中常用的解码方法，用于限制候选输出的范围。下面是代码的详细解释。</p>
<hr>
<h4 id="1-函数签名-1"><strong>1. 函数签名</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">top_k_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong>输入参数</strong>：
<ul>
<li><code>logits</code>: 张量（Tensor），通常是语言模型输出的未归一化分布（对每个词汇的分数）。</li>
<li><code>k</code>: 整数，表示要保留分数最高的 <code>k</code> 个候选项。</li>
</ul>
</li>
<li><strong>返回值</strong>：
<ul>
<li>一个经过 Top-K 过滤的 logits 张量，分数低于前 <code>k</code> 名的项被屏蔽为非常小的值（<code>-1e10</code>）。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="2-特殊情况k0"><strong>2. 特殊情况：k=0</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># no truncation</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">logits</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>含义</p>
<p>：</p>
<ul>
<li>如果 <code>k=0</code>，表示不进行任何截断操作，直接返回原始 <code>logits</code>。</li>
<li>通常在解码时使用 <code>k=0</code> 的情况很少。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="3-内部函数-_top_k"><strong>3. 内部函数 <code>_top_k</code></strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_top_k</span><span class="p">():</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>这个内部函数定义了具体的 <strong>Top-K 截断操作</strong>。</li>
<li><strong>核心步骤</strong>：</li>
</ul>
<h4 id="step-1-获取-top-k-候选项的分数"><strong>Step 1: 获取 Top-K 候选项的分数</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">values</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">min_values</span> <span class="o">=</span> <span class="n">values</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>使用 <code>tf.nn.top_k(logits, k=k)</code>：
<ul>
<li>返回 <code>logits</code> 中每一行的前 <code>k</code> 个最大值及其对应索引。</li>
<li><code>values</code> 是每一行的 Top-K 候选分数。</li>
<li><code>values[:, -1]</code> 是每一行中第 <code>k</code> 小的分数（即 Top-K 的最小值）。</li>
</ul>
</li>
<li><strong><code>min_values</code> 的作用</strong>：
<ul>
<li>将 <code>min_values</code> 扩展维度（添加 <code>tf.newaxis</code>），使其形状与 <code>logits</code> 兼容，方便后续比较。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="step-2-屏蔽低于-top-k-的分数"><strong>Step 2: 屏蔽低于 Top-K 的分数</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">logits</span> <span class="o">&lt;</span> <span class="n">min_values</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">logits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">logits</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong><code>tf.where</code> 的功能</strong>：
<ul>
<li>如果 <code>logits</code> 小于 <code>min_values</code>（不在 Top-K 中），将其替换为 <code>-1e10</code>。</li>
<li>否则保留原始分数。</li>
</ul>
</li>
<li><strong>屏蔽分数为 <code>-1e10</code> 的作用</strong>：
<ul>
<li>在随后的 Softmax 操作中，这些值将被归一化为接近 <code>0</code> 的概率，从而忽略这些候选项。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="4-条件执行"><strong>4. 条件执行</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">   <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">   <span class="k">lambda</span><span class="p">:</span> <span class="n">logits</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">   <span class="k">lambda</span><span class="p">:</span> <span class="n">_top_k</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong><code>tf.cond</code> 的功能</strong>：
<ul>
<li>根据条件执行不同的分支。</li>
<li>如果 <code>k=0</code>，直接返回 <code>logits</code>。</li>
<li>如果 <code>k&gt;0</code>，调用 <code>_top_k()</code> 进行 Top-K 截断。</li>
</ul>
</li>
<li><strong>为何使用 <code>tf.cond</code> 而不是简单的 <code>if-else</code></strong>？
<ul>
<li>在 TensorFlow 中，动态计算图需要明确定义执行逻辑，<code>tf.cond</code> 是条件分支的标准操作。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="5-工作原理总结"><strong>5. 工作原理总结</strong>
</h4><ol>
<li>
<p>如果 <code>k=0</code>，直接返回原始 <code>logits</code>。</p>
</li>
<li>
<p>如果 ：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">k&gt;0
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>找出每行 <code>logits</code> 中的前 <code>k</code> 个最大值。</li>
<li>将不在 Top-K 中的分数替换为 <code>-1e10</code>。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="代码运行示例"><strong>代码运行示例</strong>
</h4><p>假设输入如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">k</span> <span class="o">=</span> <span class="mi">2</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>执行步骤</strong>：</p>
<ol>
<li>第一行 logits：
<ul>
<li>Top-2 候选项为 <code>[2.0, 1.0]</code>。</li>
<li>其余值屏蔽为 <code>-1e10</code>。</li>
<li>结果为 <code>[2.0, 1.0, -1e10, -1e10]</code>。</li>
</ul>
</li>
<li>第二行 logits：
<ul>
<li>Top-2 候选项为 <code>[3.0, 2.5]</code>。</li>
<li>结果为 <code>[-1e10, 3.0, 2.5, -1e10]</code>。</li>
</ul>
</li>
</ol>
</li>
<li>
<p><strong>最终输出</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="p">[[</span> <span class="mf">2.0</span><span class="p">,</span>  <span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e10</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e10</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"> <span class="p">[</span><span class="o">-</span><span class="mf">1e10</span><span class="p">,</span>  <span class="mf">3.0</span><span class="p">,</span>  <span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e10</span><span class="p">]]</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
<hr>
<h4 id="应用场景-1"><strong>应用场景</strong>
</h4><ul>
<li><strong>生成任务（如文本生成、机器翻译）</strong>：
<ul>
<li>用于控制解码时的多样性，限制模型在每一步生成的候选项数量。</li>
<li>和 <strong>Top-P (nucleus) 截断</strong> 一起常用于生成优化。</li>
</ul>
</li>
<li><strong>降低计算复杂度</strong>：
<ul>
<li>对候选项进行截断，减少后续计算量。</li>
</ul>
</li>
</ul>
<hr>
<p>这段代码实现了 <strong>Top-p 截断（Nucleus Sampling）</strong>，它是一种生成任务中的采样方法，确保生成的分布仅包含累积概率不超过 <code>p</code> 的候选项，从而控制生成多样性。以下是对代码的详细解释：</p>
<hr>
<h4 id="1-函数签名-2"><strong>1. 函数签名</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">top_p_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Nucleus sampling&#34;&#34;&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong>输入参数</strong>：
<ul>
<li><code>logits</code>：模型输出的未归一化分布（对每个词汇的分数），形状为 <code>[batch_size, vocab_size]</code>。</li>
<li><code>p</code>：浮点数，累积概率阈值，范围为 <code>[0, 1]</code>。例如，<code>p=0.9</code> 意味着仅保留累积概率小于等于 <code>0.9</code> 的候选项。</li>
</ul>
</li>
<li><strong>返回值</strong>：
<ul>
<li>一个经过 Top-p 截断的 <code>logits</code> 张量，分数低于累积概率阈值 <code>p</code> 的候选项被屏蔽（赋值为 <code>-1e10</code>）。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="2-获取输入维度"><strong>2. 获取输入维度</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">batch</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>功能：
<ul>
<li>获取 <code>logits</code> 的形状，<code>batch</code> 是批量大小，<code>_</code> 是词汇表的大小（<code>vocab_size</code>）。</li>
<li>假设输入 <code>logits</code> 形状为 <code>[batch_size, vocab_size]</code>。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="3-对-logits-按分数降序排序"><strong>3. 对 logits 按分数降序排序</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">sorted_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s1">&#39;DESCENDING&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>功能：
<ul>
<li>按 <code>logits</code> 的分数降序排序（在最后一维，即词汇维度上）。</li>
<li><code>sorted_logits</code> 是按分数从大到小排列的张量，与 <code>logits</code> 的形状相同。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="4-计算累积概率"><strong>4. 计算累积概率</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">cumulative_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">sorted_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>步骤</strong>：</p>
<ol>
<li>
<p>使用 <code>tf.nn.softmax</code> 对 <code>sorted_logits</code> 进行归一化，得到概率分布。</p>
</li>
<li>
<p>使用</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tf.cumsum
</span></span></code></pre></td></tr></table>
</div>
</div><p>计算累积概率（在最后一维上）。</p>
<ul>
<li><strong>累积概率</strong>：对于每个词，表示该词及之前所有词的总概率。</li>
</ul>
</li>
</ol>
</li>
<li>
<p><strong>示例</strong>： 假设 <code>sorted_logits</code> 对应的 Softmax 概率为 <code>[0.4, 0.3, 0.2, 0.1]</code>，累积概率为 <code>[0.4, 0.7, 0.9, 1.0]</code>。</p>
</li>
</ul>
<hr>
<h4 id="5-找到超过阈值-p-的最小索引"><strong>5. 找到超过阈值 <code>p</code> 的最小索引</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">cumulative_probs</span> <span class="o">&lt;=</span> <span class="n">p</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl"><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="分步解释"><strong>分步解释</strong>：
</h4><ol>
<li>
<p><strong>判断累积概率是否小于等于 <code>p</code></strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">cumulative_probs</span> <span class="o">&lt;=</span> <span class="n">p</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>对 <code>cumulative_probs</code> 的每个值，判断是否小于等于 <code>p</code>。</li>
<li>结果是一个布尔值矩阵，转化为 <code>0</code>（False）或 <code>1</code>（True）。</li>
</ul>
</li>
<li>
<p><strong>统计满足条件的个数</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>对每一行（词汇维度）统计满足 <code>cumulative_probs &lt;= p</code> 的词的个数。</li>
<li>结果是一个形状为 <code>[batch_size]</code> 的张量，每个值表示该行中满足条件的词的数量。</li>
</ul>
</li>
<li>
<p><strong>找到累积概率超过 <code>p</code> 的最小索引</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="o">...</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>累积概率刚超过 <code>p</code> 的词的索引应该是 <code>条件个数 - 1</code>。</li>
<li>如果没有词满足条件（防止索引为负数），用 <code>tf.maximum</code> 将索引下限设为 <code>0</code>。</li>
</ul>
</li>
<li>
<p><strong>组合成二维索引</strong>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch</span><span class="p">),</span> <span class="o">...</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>创建每个批次的行索引（<code>tf.range(0, batch)</code>）和列索引（<code>条件个数 - 1</code>）。</li>
<li><code>indices</code> 是一个形状为 <code>[batch_size, 2]</code> 的张量，每个元素表示需要保留的最大分数位置。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="6-找到累积概率阈值对应的最小分数"><strong>6. 找到累积概率阈值对应的最小分数</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">min_values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">sorted_logits</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>功能：
<ul>
<li>使用 <code>indices</code> 从 <code>sorted_logits</code> 中提取累积概率刚超过 <code>p</code> 的最小分数（阈值分数）。</li>
<li><code>min_values</code> 是一个形状为 <code>[batch_size]</code> 的张量，每个值表示该批次对应的分数阈值。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="7-屏蔽分数低于阈值的-logits"><strong>7. 屏蔽分数低于阈值的 logits</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">logits</span> <span class="o">&lt;</span> <span class="n">min_values</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">logits</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong><code>tf.where</code> 的功能</strong>：
<ul>
<li>如果 <code>logits</code> 小于 <code>min_values</code>，将其替换为 <code>-1e10</code>（非常小的值）。</li>
<li>否则保留原始分数。</li>
</ul>
</li>
<li><strong>效果</strong>：
<ul>
<li>低于分数阈值的词汇几乎不会被选中（后续的 Softmax 会将其概率归一化为接近 0）。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="代码总结"><strong>代码总结</strong>
</h4><p>这段代码实现了 <strong>Top-p 截断（Nucleus Sampling）</strong>，步骤如下：</p>
<ol>
<li>对 logits 按分数降序排序。</li>
<li>计算每个词的累积概率。</li>
<li>找到刚好满足累积概率 <code>≤ p</code> 的分数阈值。</li>
<li>将分数低于阈值的候选项屏蔽为 <code>-1e10</code>。</li>
</ol>
<hr>
<h4 id="代码运行示例-1"><strong>代码运行示例</strong>
</h4><p>假设输入如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">p</span> <span class="o">=</span> <span class="mf">0.8</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="执行过程"><strong>执行过程</strong>：
</h4><ol>
<li>
<p>对 logits 排序，得到：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">[[2.0, 1.0, 0.5, 0.1],
</span></span><span class="line"><span class="cl"> [1.5, 1.0, 0.3, 0.2]]
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>计算累积概率（Softmax + cumsum），例如：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">[[0.6, 0.9, 0.99, 1.0],
</span></span><span class="line"><span class="cl"> [0.5, 0.85, 0.98, 1.0]]
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>阈值对应分数为：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">[1.0, 1.0]
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>屏蔽分数低于阈值的项：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">[[2.0, 1.0, -1e10, -1e10],
</span></span><span class="line"><span class="cl"> [1.5, 1.0, -1e10, -1e10]]
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<hr>
<h4 id="应用场景-2"><strong>应用场景</strong>
</h4><ul>
<li>文本生成任务：
<ul>
<li>限制生成范围，仅保留累积概率满足 <code>p</code> 的候选项，避免低概率词导致的无意义生成。</li>
</ul>
</li>
<li>生成控制：
<ul>
<li>Top-p 能根据概率动态调整候选项数量，比 Top-k 更灵活。</li>
</ul>
</li>
</ul>
<p>这段代码定义了一个函数 <code>sample_sequence</code>，用于在基于语言模型（如 GPT-2）的文本生成任务中，逐步生成固定长度的序列。以下是对代码的详细解析。</p>
<hr>
<h3 id="def-sample_sequence">def sample_sequence
</h3><h4 id="1-函数签名和输入参数"><strong>1. 函数签名和输入参数</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">sample_sequence</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">hparams</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">start_token</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>输入参数：</p>
<ol>
<li><strong><code>hparams</code></strong>：模型的超参数，包含词汇大小（<code>n_vocab</code>）、隐藏层大小等配置。</li>
<li><strong><code>length</code></strong>：生成的序列长度（最大迭代次数）。</li>
<li><strong><code>start_token</code></strong>：文本生成的起始 token（一个整数表示词汇 ID）。</li>
<li><strong><code>batch_size</code></strong>：批量大小，决定了同时生成多少条序列。</li>
<li><strong><code>context</code></strong>：输入上下文序列，形状为 <code>[batch_size, sequence_length]</code>，可选。和 <code>start_token</code> 互斥。</li>
<li><strong><code>temperature</code></strong>：控制采样的随机性。值越低，生成的文本越确定；值越高，生成的文本越随机。</li>
<li><strong><code>top_k</code></strong>：Top-k 截断，保留概率分布中分数最高的 k 个词。</li>
<li><strong><code>top_p</code></strong>：Top-p 截断（核采样），保留累积概率小于等于 <code>p</code> 的词。</li>
</ol>
</li>
</ul>
<hr>
<h4 id="2-参数验证和初始上下文设置"><strong>2. 参数验证和初始上下文设置</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">start_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="n">context</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Specify exactly one of start_token and context!&#39;</span>
</span></span><span class="line"><span class="cl"><span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="n">context</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Specify exactly one of start_token and context!&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="n">context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">start_token</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>通过</p>
<p><code>start_token</code> 或 <code>context</code></p>
<p>指定生成的起始条件：</p>
<ol>
<li>如果 <code>start_token</code> 被指定，则初始化 <code>context</code> 为 <code>[batch_size, 1]</code> 的张量，值全为 <code>start_token</code>。</li>
<li>如果没有提供 <code>start_token</code>，则需要提供 <code>context</code>。</li>
<li>二者不能同时存在。</li>
</ol>
</li>
</ul>
<hr>
<h4 id="3-定义生成单步的函数-step"><strong>3. 定义生成单步的函数 <code>step</code></strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="n">hparams</span><span class="p">,</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">past</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">lm_output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">tokens</span><span class="p">,</span> <span class="n">past</span><span class="o">=</span><span class="n">past</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">AUTO_REUSE</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">logits</span> <span class="o">=</span> <span class="n">lm_output</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">][:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">hparams</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">presents</span> <span class="o">=</span> <span class="n">lm_output</span><span class="p">[</span><span class="s1">&#39;present&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">presents</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">past_shape</span><span class="p">(</span><span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;logits&#39;</span><span class="p">:</span> <span class="n">logits</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;presents&#39;</span><span class="p">:</span> <span class="n">presents</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>功能</strong>：</p>
<ul>
<li>
<p>调用语言模型（</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">model.model
</span></span></code></pre></td></tr></table>
</div>
</div><p>），根据当前输入的 tokens 和历史上下文（</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">past
</span></span></code></pre></td></tr></table>
</div>
</div><p>）生成：</p>
<ol>
<li><strong><code>logits</code></strong>：模型对当前 tokens 的预测分数（未归一化）。</li>
<li><strong><code>presents</code></strong>：当前生成步骤的注意力层状态，用于缓存历史上下文以提高生成效率。</li>
</ol>
</li>
</ul>
</li>
<li>
<p><strong>关键点</strong>：</p>
<ol>
<li><strong><code>past</code></strong>：表示历史生成步骤的缓存状态，用于加速自回归模型的生成。</li>
<li><strong><code>reuse=tf.AUTO_REUSE</code></strong>：允许在 TensorFlow 中重用模型权重。</li>
</ol>
</li>
</ul>
<hr>
<h4 id="4-定义生成循环的-body-函数"><strong>4. 定义生成循环的 <code>body</code> 函数</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">body</span><span class="p">(</span><span class="n">past</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">next_outputs</span> <span class="o">=</span> <span class="n">step</span><span class="p">(</span><span class="n">hparams</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">past</span><span class="o">=</span><span class="n">past</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">logits</span> <span class="o">=</span> <span class="n">next_outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">][:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>  <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">temperature</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">logits</span> <span class="o">=</span> <span class="n">top_k_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">top_k</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">logits</span> <span class="o">=</span> <span class="n">top_p_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">top_p</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">samples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="n">next_outputs</span><span class="p">[</span><span class="s1">&#39;presents&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">past</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">past</span><span class="p">,</span> <span class="n">next_outputs</span><span class="p">[</span><span class="s1">&#39;presents&#39;</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">samples</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">output</span><span class="p">,</span> <span class="n">samples</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>输入参数</strong>：</p>
<ol>
<li><strong><code>past</code></strong>：缓存的历史上下文，用于加速生成。</li>
<li><strong><code>prev</code></strong>：上一步生成的 tokens。</li>
<li><strong><code>output</code></strong>：当前生成的完整序列。</li>
</ol>
</li>
<li>
<p><strong>功能分解</strong>：</p>
<ol>
<li>
<p>调用 <code>step</code> 获取当前步的 <code>logits</code> 和 <code>presents</code>。</p>
</li>
<li>
<p>对</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">logits
</span></span></code></pre></td></tr></table>
</div>
</div><p>进行采样策略：</p>
<ul>
<li>调整分布随机性（<code>temperature</code>）。</li>
<li>使用 Top-k 和 Top-p 策略限制候选项。</li>
<li>调用 <code>tf.multinomial</code> 从调整后的分布中采样下一个 token。</li>
</ul>
</li>
<li>
<p>更新</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">past
</span></span></code></pre></td></tr></table>
</div>
</div><p>和</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">output
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>拼接当前步生成的 <code>presents</code> 到 <code>past</code>。</li>
</ul>
</li>
</ol>
<ul>
<li>拼接新生成的 token 到 <code>output</code>。</li>
</ul>
</li>
<li>
<p><strong>返回值</strong>：</p>
<ul>
<li>新的 <code>past</code>、当前步的生成 token、新的生成序列 <code>output</code>。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="5-初始化第一步"><strong>5. 初始化第一步</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">past</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="n">body</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>执行 <code>body</code>，使用 <code>context</code> 初始化生成序列，并获取第一个生成结果。</li>
</ul>
<hr>
<h4 id="6-定义循环条件和主体"><strong>6. 定义循环条件和主体</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">cond</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="kc">True</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>循环条件函数 <code>cond</code> 总是返回 <code>True</code>，表示按固定步数执行循环（由 <code>maximum_iterations</code> 限制）。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">cond</span><span class="o">=</span><span class="n">cond</span><span class="p">,</span> <span class="n">body</span><span class="o">=</span><span class="n">body</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">loop_vars</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="n">past</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">prev</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span>
</span></span><span class="line"><span class="cl">    <span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">shape_invariants</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">past_shape</span><span class="p">(</span><span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)),</span>
</span></span><span class="line"><span class="cl">        <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
</span></span><span class="line"><span class="cl">        <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
</span></span><span class="line"><span class="cl">    <span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">back_prop</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>循环控制：</p>
<ol>
<li><strong><code>cond</code></strong>：始终为 <code>True</code>，循环到达 <code>maximum_iterations</code> 为止。</li>
<li><strong><code>body</code></strong>：调用上述 <code>body</code> 函数逐步生成序列。</li>
<li><strong><code>loop_vars</code></strong>：循环的变量，包括 <code>past</code>、<code>prev</code>、<code>output</code>。</li>
<li><strong><code>shape_invariants</code></strong>：指定循环变量的形状变化规则，支持动态长度。</li>
</ol>
</li>
</ul>
<hr>
<h4 id="7-返回生成的序列"><strong>7. 返回生成的序列</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">return</span> <span class="n">tokens</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>最终返回生成的完整序列 <code>tokens</code>。</li>
</ul>
<hr>
<h4 id="工作流程总结"><strong>工作流程总结</strong>
</h4><ol>
<li>
<p>初始化上下文（<code>context</code> 或 <code>start_token</code>）。</p>
</li>
<li>
<p>在</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tf.while_loop
</span></span></code></pre></td></tr></table>
</div>
</div><p>中：</p>
<ul>
<li>逐步调用模型生成下一个 token。</li>
<li>使用采样策略（Top-k 或 Top-p）筛选候选词。</li>
<li>更新历史上下文和生成序列。</li>
</ul>
</li>
<li>
<p>循环执行至生成长度达到指定值，返回生成的 token 序列。</p>
</li>
</ol>
<hr>
<h4 id="应用场景-3"><strong>应用场景</strong>
</h4><ol>
<li>文本生成：
<ul>
<li>GPT 系列模型中的文本补全、对话生成等。</li>
</ul>
</li>
<li>定制采样策略：
<ul>
<li>根据任务调整 <code>temperature</code>、<code>top_k</code> 和 <code>top_p</code> 参数，生成风格化或更合理的文本。</li>
</ul>
</li>
</ol>
<p>如果有具体问题或想运行代码测试，我可以协助进一步分析！</p>
<h2 id="generate_unconditional_samples">generate_unconditional_samples
</h2><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="ch">#!/usr/bin/env python3</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">fire</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">json</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">model</span><span class="o">,</span> <span class="nn">sample</span><span class="o">,</span> <span class="nn">encoder</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">sample_model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;124M&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">nsamples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">top_p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">models_dir</span><span class="o">=</span><span class="s1">&#39;models&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Run the sample_model
</span></span></span><span class="line"><span class="cl"><span class="s2">    :model_name=124M : String, which model to use
</span></span></span><span class="line"><span class="cl"><span class="s2">    :seed=None : Integer seed for random number generators, fix seed to
</span></span></span><span class="line"><span class="cl"><span class="s2">     reproduce results
</span></span></span><span class="line"><span class="cl"><span class="s2">    :nsamples=0 : Number of samples to return, if 0, continues to
</span></span></span><span class="line"><span class="cl"><span class="s2">     generate samples indefinately.
</span></span></span><span class="line"><span class="cl"><span class="s2">    :batch_size=1 : Number of batches (only affects speed/memory).
</span></span></span><span class="line"><span class="cl"><span class="s2">    :length=None : Number of tokens in generated text, if None (default), is
</span></span></span><span class="line"><span class="cl"><span class="s2">     determined by model hyperparameters
</span></span></span><span class="line"><span class="cl"><span class="s2">    :temperature=1 : Float value controlling randomness in boltzmann
</span></span></span><span class="line"><span class="cl"><span class="s2">     distribution. Lower temperature results in less random completions. As the
</span></span></span><span class="line"><span class="cl"><span class="s2">     temperature approaches zero, the model will become deterministic and
</span></span></span><span class="line"><span class="cl"><span class="s2">     repetitive. Higher temperature results in more random completions.
</span></span></span><span class="line"><span class="cl"><span class="s2">    :top_k=0 : Integer value controlling diversity. 1 means only 1 word is
</span></span></span><span class="line"><span class="cl"><span class="s2">     considered for each step (token), resulting in deterministic completions,
</span></span></span><span class="line"><span class="cl"><span class="s2">     while 40 means 40 words are considered at each step. 0 (default) is a
</span></span></span><span class="line"><span class="cl"><span class="s2">     special setting meaning no restrictions. 40 generally is a good value.
</span></span></span><span class="line"><span class="cl"><span class="s2">     :models_dir : path to parent folder containing model subfolders
</span></span></span><span class="line"><span class="cl"><span class="s2">     (i.e. contains the &lt;model_name&gt; folder)
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">models_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expandvars</span><span class="p">(</span><span class="n">models_dir</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">enc</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">get_encoder</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">models_dir</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">hparams</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">default_hparams</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">models_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="s1">&#39;hparams.json&#39;</span><span class="p">))</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">hparams</span><span class="o">.</span><span class="n">override_from_dict</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">length</span> <span class="o">=</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span>
</span></span><span class="line"><span class="cl">    <span class="k">elif</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&#34;Can&#39;t get samples longer than window size: </span><span class="si">%s</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">())</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">sample_sequence</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">length</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">start_token</span><span class="o">=</span><span class="n">enc</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span>
</span></span><span class="line"><span class="cl">        <span class="p">)[:,</span> <span class="mi">1</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">models_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ckpt</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">generated</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="n">nsamples</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">generated</span> <span class="o">&lt;</span> <span class="n">nsamples</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">out</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">generated</span> <span class="o">+=</span> <span class="n">batch_size</span>
</span></span><span class="line"><span class="cl">                <span class="n">text</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;=&#34;</span> <span class="o">*</span> <span class="mi">40</span> <span class="o">+</span> <span class="s2">&#34; SAMPLE &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">generated</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34; &#34;</span> <span class="o">+</span> <span class="s2">&#34;=&#34;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">fire</span><span class="o">.</span><span class="n">Fire</span><span class="p">(</span><span class="n">sample_model</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这段代码是一个用于生成文本样本的 Python 脚本，基于 TensorFlow 实现，使用了 GPT 模型（例如 GPT-2）。以下是对代码的逐步解释：</p>
<hr>
<h3 id="1-头部代码">1. <strong>头部代码</strong>
</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="ch">#!/usr/bin/env python3</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这是一个 shebang，用于指定运行脚本的 Python 解释器。</p>
<hr>
<h3 id="2-引入依赖库">2. <strong>引入依赖库</strong>
</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">fire</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">json</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">model</span><span class="o">,</span> <span class="nn">sample</span><span class="o">,</span> <span class="nn">encoder</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong><code>fire</code></strong>: 用于解析命令行参数，可以轻松地将函数暴露为命令行工具。</li>
<li><strong><code>json</code></strong> 和 <strong><code>os</code></strong>: 用于读取和处理模型的配置文件和路径。</li>
<li><strong><code>numpy</code></strong>: 用于随机数种子设定。</li>
<li><strong><code>tensorflow</code></strong>: 用于加载和运行 TensorFlow 模型。</li>
<li><strong><code>model</code>, <code>sample</code>, <code>encoder</code></strong>: 自定义模块，分别包含模型定义、采样逻辑和文本编码器。</li>
</ul>
<hr>
<h3 id="3-sample_model-函数">3. <strong><code>sample_model</code> 函数</strong>
</h3><p>这是生成文本的核心函数，支持多种参数控制生成行为。</p>
<h4 id="参数说明"><strong>参数说明</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">sample_model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;124M&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">nsamples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">top_p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">models_dir</span><span class="o">=</span><span class="s1">&#39;models&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong><code>model_name</code></strong>: 模型的名称，例如 <code>'124M'</code>。</li>
<li><strong><code>seed</code></strong>: 随机数种子，固定种子以获得可重复结果。</li>
<li><strong><code>nsamples</code></strong>: 要生成的样本数量。如果为 <code>0</code>，则持续生成直到中断。</li>
<li><strong><code>batch_size</code></strong>: 每批次生成的样本数量。</li>
<li><strong><code>length</code></strong>: 生成的文本长度（以 token 为单位）。如果不指定，则默认使用模型的最大长度。</li>
<li><strong><code>temperature</code></strong>: 控制生成文本的随机性。较低值会更确定性，较高值会更随机。</li>
<li><strong><code>top_k</code></strong>: 限制生成时的候选 token 数量。<code>0</code> 表示不限制。</li>
<li><strong><code>top_p</code></strong>: 控制 nucleus sampling（核采样）的参数，限制生成时累计概率的阈值。</li>
<li><strong><code>models_dir</code></strong>: 模型文件所在的根目录。</li>
</ul>
<hr>
<p><strong>主要逻辑</strong></p>
<ol>
<li><strong>加载模型和超参数</strong></li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">models_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expandvars</span><span class="p">(</span><span class="n">models_dir</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">enc</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">get_encoder</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">models_dir</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">hparams</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">default_hparams</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">models_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="s1">&#39;hparams.json&#39;</span><span class="p">))</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">hparams</span><span class="o">.</span><span class="n">override_from_dict</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>解析 <code>models_dir</code> 路径，加载编码器和模型的超参数。</li>
<li>超参数（如上下文长度 <code>n_ctx</code>）存储在 <code>hparams.json</code> 文件中。</li>
</ul>
<ol>
<li><strong>验证文本长度</strong></li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">length</span> <span class="o">=</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span>
</span></span><span class="line"><span class="cl"><span class="k">elif</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&#34;Can&#39;t get samples longer than window size: </span><span class="si">%s</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>如果未指定长度，则使用模型的默认长度（即上下文窗口的大小）。</li>
<li>如果指定的长度超过模型支持的窗口大小，则抛出错误。</li>
</ul>
<ol>
<li><strong>创建 TensorFlow 会话</strong></li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">())</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>在 TensorFlow 图中运行会话。</li>
<li>设置随机种子以确保生成结果的可重复性。</li>
</ul>
<ol>
<li><strong>定义采样过程</strong></li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">output</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">sample_sequence</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">length</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">start_token</span><span class="o">=</span><span class="n">enc</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span>
</span></span><span class="line"><span class="cl"><span class="p">)[:,</span> <span class="mi">1</span><span class="p">:]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>调用 <code>sample_sequence</code> 方法，基于指定参数生成文本序列。</li>
<li>起始 token 为 <code>'&lt;|endoftext|&gt;'</code>，用于指示生成无条件文本。</li>
</ul>
<ol>
<li><strong>加载模型权重</strong></li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">models_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ckpt</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>使用 TensorFlow 的 <code>Saver</code> 对象加载模型的权重文件。</li>
<li>自动寻找最新的检查点文件（<code>.ckpt</code>）。</li>
</ul>
<ol>
<li><strong>生成文本样本</strong></li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">generated</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="k">while</span> <span class="n">nsamples</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">generated</span> <span class="o">&lt;</span> <span class="n">nsamples</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">out</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">generated</span> <span class="o">+=</span> <span class="n">batch_size</span>
</span></span><span class="line"><span class="cl">        <span class="n">text</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;=&#34;</span> <span class="o">*</span> <span class="mi">40</span> <span class="o">+</span> <span class="s2">&#34; SAMPLE &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">generated</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34; &#34;</span> <span class="o">+</span> <span class="s2">&#34;=&#34;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>通过 <code>sess.run(output)</code> 执行采样操作。</li>
<li>使用编码器的 <code>decode</code> 方法将生成的 token 序列转换为人类可读的文本。</li>
<li>打印生成的样本。</li>
</ul>
<hr>
<h3 id="4-主函数">4. <strong>主函数</strong>
</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">fire</span><span class="o">.</span><span class="n">Fire</span><span class="p">(</span><span class="n">sample_model</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>使用 <code>fire.Fire</code> 将 <code>sample_model</code> 函数暴露为命令行接口，允许通过命令行传递参数调用。</li>
</ul>
<hr>
<h4 id="运行方式"><strong>运行方式</strong>
</h4><p>假设文件名为 <code>generate_samples.py</code>，在命令行中可以运行：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">python generate_samples.py --model_name 124M --nsamples <span class="m">5</span> --length <span class="m">50</span> --temperature 0.7 --top_k <span class="m">40</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>生成 5 个长度为 50 的样本，使用 <code>124M</code> 模型，采样参数为 <code>temperature=0.7</code> 和 <code>top_k=40</code>。</p>
<hr>
<h4 id="核心模块"><strong>核心模块</strong>
</h4><ol>
<li><strong><code>model</code></strong>: 定义 GPT 模型的架构。</li>
<li><strong><code>sample</code></strong>: 实现采样逻辑。</li>
<li><strong><code>encoder</code></strong>: 实现文本编码（字符到 token 的映射）和解码（token 到文本的映射）。</li>
</ol>
<hr>
<h4 id="总结-2"><strong>总结</strong>
</h4><p>这段代码是一个典型的无条件文本生成脚本，允许用户通过调整参数生成高质量的自然语言文本。它展示了如何加载预训练模型、配置超参数并执行采样操作。</p>
<p>“shebang” 是一个英语词，它的中文意思是指脚本文件开头的那一行 <code>#!/usr/bin/env python3</code>，也叫作**“解释器指令”<strong>或</strong>“魔法行”**。</p>
<p>具体含义是：</p>
<ul>
<li><strong><code>#!</code></strong>：表示这是一个特殊的指令行，告诉操作系统用哪个程序来运行这个脚本。</li>
<li><strong><code>/usr/bin/env python3</code></strong>：表示使用环境中找到的 <code>python3</code> 解释器来执行这段代码。</li>
</ul>
<p>简而言之，这行代码的作用是：<strong>让脚本在 Linux 或 macOS 系统中可以直接运行，而无需手动调用 Python。</strong></p>
<p>比如，如果一个文件叫 <code>script.py</code>，包含这一行，你可以直接运行：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">./script.py
</span></span></code></pre></td></tr></table>
</div>
</div><p>而不需要输入：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">python3 script.py
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="interactive_conditional_samples">interactive_conditional_samples
</h2><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span><span class="lnt">88
</span><span class="lnt">89
</span><span class="lnt">90
</span><span class="lnt">91
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="ch">#!/usr/bin/env python3</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">fire</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">json</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">model</span><span class="o">,</span> <span class="nn">sample</span><span class="o">,</span> <span class="nn">encoder</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">interact_model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;124M&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">nsamples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">top_p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">models_dir</span><span class="o">=</span><span class="s1">&#39;models&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Interactively run the model
</span></span></span><span class="line"><span class="cl"><span class="s2">    :model_name=124M : String, which model to use
</span></span></span><span class="line"><span class="cl"><span class="s2">    :seed=None : Integer seed for random number generators, fix seed to reproduce
</span></span></span><span class="line"><span class="cl"><span class="s2">     results
</span></span></span><span class="line"><span class="cl"><span class="s2">    :nsamples=1 : Number of samples to return total
</span></span></span><span class="line"><span class="cl"><span class="s2">    :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples.
</span></span></span><span class="line"><span class="cl"><span class="s2">    :length=None : Number of tokens in generated text, if None (default), is
</span></span></span><span class="line"><span class="cl"><span class="s2">     determined by model hyperparameters
</span></span></span><span class="line"><span class="cl"><span class="s2">    :temperature=1 : Float value controlling randomness in boltzmann
</span></span></span><span class="line"><span class="cl"><span class="s2">     distribution. Lower temperature results in less random completions. As the
</span></span></span><span class="line"><span class="cl"><span class="s2">     temperature approaches zero, the model will become deterministic and
</span></span></span><span class="line"><span class="cl"><span class="s2">     repetitive. Higher temperature results in more random completions.
</span></span></span><span class="line"><span class="cl"><span class="s2">    :top_k=0 : Integer value controlling diversity. 1 means only 1 word is
</span></span></span><span class="line"><span class="cl"><span class="s2">     considered for each step (token), resulting in deterministic completions,
</span></span></span><span class="line"><span class="cl"><span class="s2">     while 40 means 40 words are considered at each step. 0 (default) is a
</span></span></span><span class="line"><span class="cl"><span class="s2">     special setting meaning no restrictions. 40 generally is a good value.
</span></span></span><span class="line"><span class="cl"><span class="s2">     :models_dir : path to parent folder containing model subfolders
</span></span></span><span class="line"><span class="cl"><span class="s2">     (i.e. contains the &lt;model_name&gt; folder)
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">models_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expandvars</span><span class="p">(</span><span class="n">models_dir</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="n">nsamples</span> <span class="o">%</span> <span class="n">batch_size</span> <span class="o">==</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">enc</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">get_encoder</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">models_dir</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">hparams</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">default_hparams</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">models_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="s1">&#39;hparams.json&#39;</span><span class="p">))</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">hparams</span><span class="o">.</span><span class="n">override_from_dict</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">length</span> <span class="o">=</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span> <span class="o">//</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">    <span class="k">elif</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&#34;Can&#39;t get samples longer than window size: </span><span class="si">%s</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">())</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">sample_sequence</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">length</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">models_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ckpt</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">raw_text</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&#34;Model prompt &gt;&gt;&gt; &#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">while</span> <span class="ow">not</span> <span class="n">raw_text</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Prompt should not be empty!&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">raw_text</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&#34;Model prompt &gt;&gt;&gt; &#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">context_tokens</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">generated</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamples</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">out</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">                    <span class="n">context</span><span class="p">:</span> <span class="p">[</span><span class="n">context_tokens</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">                <span class="p">})[:,</span> <span class="nb">len</span><span class="p">(</span><span class="n">context_tokens</span><span class="p">):]</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                    <span class="n">generated</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">                    <span class="n">text</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;=&#34;</span> <span class="o">*</span> <span class="mi">40</span> <span class="o">+</span> <span class="s2">&#34; SAMPLE &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">generated</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34; &#34;</span> <span class="o">+</span> <span class="s2">&#34;=&#34;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;=&#34;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">fire</span><span class="o">.</span><span class="n">Fire</span><span class="p">(</span><span class="n">interact_model</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这段代码是一个交互式脚本，允许用户使用预训练的 GPT 模型生成基于用户输入的文本。它提供了一种对话式的方式来与语言模型交互，以下是详细的逐步解析：</p>
<h3 id="1-头部部分"><strong>1. 头部部分</strong>
</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="ch">#!/usr/bin/env python3</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong>作用</strong>: 指定使用 <code>python3</code> 作为脚本的解释器，方便在类 UNIX 系统中直接运行脚本。</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">fire</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">json</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">model</span><span class="o">,</span> <span class="nn">sample</span><span class="o">,</span> <span class="nn">encoder</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong><code>fire</code></strong>: 将 Python 函数转化为命令行工具，用于解析参数。</li>
<li><strong><code>json</code></strong> 和 <strong><code>os</code></strong>: 用于读取模型配置文件和处理路径。</li>
<li><strong><code>numpy</code></strong>: 用于随机数种子设定。</li>
<li><strong><code>tensorflow</code></strong>: 用于加载和运行模型。</li>
<li><strong><code>model</code>, <code>sample</code>, <code>encoder</code></strong>: 自定义模块，分别包含 GPT 模型定义、采样逻辑和编码器。</li>
</ul>
<hr>
<h3 id="2-interact_model-函数"><strong>2. <code>interact_model</code> 函数</strong>
</h3><p>该函数是脚本的核心，用于加载模型、处理用户输入并生成文本。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">interact_model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;124M&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">nsamples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">top_p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">models_dir</span><span class="o">=</span><span class="s1">&#39;models&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>参数说明</strong></p>
<ul>
<li><strong><code>model_name</code></strong>: 模型的名称，例如 <code>'124M'</code>。</li>
<li><strong><code>seed</code></strong>: 随机数种子，固定后可重复生成相同的文本。</li>
<li><strong><code>nsamples</code></strong>: 要生成的样本总数。</li>
<li><strong><code>batch_size</code></strong>: 每次批量生成的样本数，<code>nsamples</code> 必须是 <code>batch_size</code> 的倍数。</li>
<li><strong><code>length</code></strong>: 每个生成样本的 token 数。如果不指定，默认值为上下文窗口长度的一半。</li>
<li><strong><code>temperature</code></strong>: 控制生成文本的随机性，值越高生成结果越多样化。</li>
<li><strong><code>top_k</code></strong>: 限制每步生成时候选 token 的数量，<code>0</code> 表示不限制。</li>
<li><strong><code>top_p</code></strong>: 控制 nucleus sampling（核采样）的累积概率阈值。</li>
<li><strong><code>models_dir</code></strong>: 模型存储目录。</li>
</ul>
<hr>
<h3 id="3-核心逻辑"><strong>3. 核心逻辑</strong>
</h3><ol>
<li><strong>模型和超参数加载</strong></li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">models_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expandvars</span><span class="p">(</span><span class="n">models_dir</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="k">assert</span> <span class="n">nsamples</span> <span class="o">%</span> <span class="n">batch_size</span> <span class="o">==</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">enc</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">get_encoder</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">models_dir</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">hparams</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">default_hparams</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">models_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="s1">&#39;hparams.json&#39;</span><span class="p">))</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">hparams</span><span class="o">.</span><span class="n">override_from_dict</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>解析模型目录路径并加载编码器。</li>
<li>加载模型的超参数（例如上下文窗口大小 <code>n_ctx</code>）。</li>
</ul>
<hr>
<ol>
<li><strong>验证和设置生成长度</strong></li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">length</span> <span class="o">=</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span> <span class="o">//</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="k">elif</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&#34;Can&#39;t get samples longer than window size: </span><span class="si">%s</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">hparams</span><span class="o">.</span><span class="n">n_ctx</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>如果未指定生成文本的长度，默认使用模型上下文长度的一半。</li>
<li>如果指定长度超出上下文窗口大小，则抛出错误。</li>
</ul>
<hr>
<ol>
<li><strong>创建 TensorFlow 会话</strong></li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">())</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">output</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">sample_sequence</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">length</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>创建一个新的 TensorFlow 图和会话。</li>
<li>定义占位符 <code>context</code>，表示用户输入的 token。</li>
<li>调用 <code>sample_sequence</code> 函数，根据上下文生成序列。</li>
</ul>
<hr>
<ol>
<li><strong>加载模型权重</strong></li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">models_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ckpt</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>使用 <code>Saver</code> 对象加载模型权重。</li>
<li>自动找到最新的检查点文件（<code>.ckpt</code>）。</li>
</ul>
<hr>
<ol>
<li><strong>交互式输入与文本生成</strong></li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">raw_text</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&#34;Model prompt &gt;&gt;&gt; &#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">while</span> <span class="ow">not</span> <span class="n">raw_text</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Prompt should not be empty!&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">raw_text</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&#34;Model prompt &gt;&gt;&gt; &#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">context_tokens</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">generated</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamples</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">out</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">context</span><span class="p">:</span> <span class="p">[</span><span class="n">context_tokens</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">        <span class="p">})[:,</span> <span class="nb">len</span><span class="p">(</span><span class="n">context_tokens</span><span class="p">):]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">generated</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">            <span class="n">text</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;=&#34;</span> <span class="o">*</span> <span class="mi">40</span> <span class="o">+</span> <span class="s2">&#34; SAMPLE &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">generated</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34; &#34;</span> <span class="o">+</span> <span class="s2">&#34;=&#34;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;=&#34;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong>输入部分</strong>:
<ul>
<li>用户输入 <code>raw_text</code>（模型的上下文或提示词）。</li>
<li>输入不能为空。</li>
</ul>
</li>
<li><strong>文本生成部分</strong>:
<ul>
<li>将输入的文本编码成 token，存储在 <code>context_tokens</code> 中。</li>
<li>使用 <code>sess.run(output)</code> 调用模型生成 token 序列，跳过输入的 token，仅解码生成的部分。</li>
<li>使用编码器解码 token 序列，转换成可读文本。</li>
</ul>
</li>
<li><strong>输出部分</strong>:
<ul>
<li>每生成一个样本，会用分隔线显示样本编号和内容。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="6-主函数部分"><strong>6. 主函数部分</strong>
</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">fire</span><span class="o">.</span><span class="n">Fire</span><span class="p">(</span><span class="n">interact_model</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>使用 <code>fire</code> 将 <code>interact_model</code> 函数转化为命令行工具。</li>
</ul>
<hr>
<h4 id="运行方式-1"><strong>运行方式</strong>
</h4><p>假设脚本名为 <code>interact.py</code>，可以运行：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">python interact.py --model_name 124M --temperature 0.8 --top_k <span class="m">40</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>然后，输入提示词：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Model prompt &gt;&gt;&gt; Once upon a time,
</span></span></code></pre></td></tr></table>
</div>
</div><p>模型会根据提示生成若干样本。</p>
<hr>
<h3 id="总结-3"><strong>总结</strong>
</h3><p>这段代码实现了一个交互式的文本生成工具，基于 GPT 模型。用户提供输入提示，模型生成后续文本。通过调整 <code>temperature</code>、<code>top_k</code> 和 <code>top_p</code> 等参数，可以控制生成结果的随机性和多样性。</p>

</section>


    <footer class="article-footer">
    

    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI&#43;WdtXRGWt2kTvGFasHpSy3SV"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG&#43;vnGctmUb0ZY0l8"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>
    
</article>

    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">相关文章</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="has-image">
    <a href="/p/%E8%B0%83%E7%A0%94%E8%AE%BA%E6%96%87%E9%80%9F%E8%A7%882/">
        
        
            <div class="article-image">
                <img src="/p/%E8%B0%83%E7%A0%94%E8%AE%BA%E6%96%87%E9%80%9F%E8%A7%882/tree-3358468_1280.ae81e858c2a81b65047cc34d6475b0d8_hu12492293271762252736.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post 调研论文速览2"
                        
                        data-hash="md5-roHoWMKoG2UEfMNNZHWw2A==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">调研论文速览2</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/%E7%AC%AC4%E5%91%A8%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/">
        
        
            <div class="article-image">
                <img src="/p/%E7%AC%AC4%E5%91%A8%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/colorful-2609978_1280.ff7347a9469275bbba133b27dec52763_hu9757057660502133537.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post 第4周工作总结"
                        
                        data-hash="md5-/3NHqUaSdbu6Ezsn3sUnYw==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">第4周工作总结</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/transformermodelbase/">
        
        
            <div class="article-image">
                <img src="/p/transformermodelbase/house-7497002_1280.db5d8d10c07a318d1548ccc1c8785778_hu3374130842880547652.png" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post transformer模型架构"
                        data-key="transformerModelbase" 
                        data-hash="md5-212NEMB6MY0VSMzByHhXeA==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">transformer模型架构</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/third-week/">
        
        
            <div class="article-image">
                <img src="/p/third-week/cards-8594729_640.6d4d362b955a08c1ac2883a31f793424_hu4843113531480180974.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post 第3周工作总结"
                        data-key="third-week" 
                        data-hash="md5-bU02K5VaCMGsKIOjH3k0JA==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">第3周工作总结</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/second-week/">
        
        
            <div class="article-image">
                <img src="/p/second-week/leaves-6729056_640.d8f540d517d89998772f4150b9222cbc_hu11404399883202129121.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post 第2周工作总结"
                        data-key="second-week" 
                        data-hash="md5-2PVA1RfYmZh3L0FQuSIsvA==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">第2周工作总结</h2>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2024 - 
        
        2025 Zion Blaze
    </section>
    
    <section class="powerby">
        使用 <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> 构建 <br />
        主题 <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.29.0">Stack</a></b> 由 <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a> 设计
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>
<div id="particles-js"></div>

<script src=https://JiangZhiyu-1024.github.io/background/particles.min.js></script>
<script>
  particlesJS.load('particles-js', "https://JiangZhiyu-1024.github.io/background/particlesjs-config.json", function () {
    console.log('particles.js loaded - callback');
  });
</script>
<style>
  #particles-js {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    z-index: -1;
  }
</style>

<style>
  @font-face {
    font-family: 'PL';
    src: url(https://JiangZhiyu-1024.github.io/font/PL.ttf) format('truetype');
  }

  :root {
    --base-font-family: 'PL';
    --code-font-family: 'PL';
  }
</style>
    </body>
</html>
