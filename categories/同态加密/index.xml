<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>同态加密 on Zion Blaze</title>
        <link>https://JiangZhiyu-1024.github.io/categories/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86/</link>
        <description>Recent content in 同态加密 on Zion Blaze</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>Zion Blaze</copyright>
        <lastBuildDate>Thu, 14 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://JiangZhiyu-1024.github.io/categories/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>使用同态加密和联邦学习的隐私保护机器学习</title>
        <link>https://JiangZhiyu-1024.github.io/p/%E4%BD%BF%E7%94%A8%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86%E5%92%8C%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
        <pubDate>Thu, 14 Nov 2024 00:00:00 +0000</pubDate>
        
        <guid>https://JiangZhiyu-1024.github.io/p/%E4%BD%BF%E7%94%A8%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86%E5%92%8C%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid>
        <description>&lt;img src="https://JiangZhiyu-1024.github.io/p/%E4%BD%BF%E7%94%A8%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86%E5%92%8C%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/forest-6818683_1280.jpg" alt="Featured image of post 使用同态加密和联邦学习的隐私保护机器学习" /&gt;&lt;h1 id=&#34;使用同态加密和联邦学习的隐私保护机器学习&#34;&gt;使用同态加密和联邦学习的隐私保护机器学习
&lt;/h1&gt;&lt;p&gt;Haokun Fang 和 Quan Qian 是在隐私保护机器学习、同态加密、联邦学习等领域具有一定研究成果的学者。以下是他们的简要介绍：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Haokun Fang&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Haokun Fang 是一位专注于机器学习和加密技术的研究者。他的研究兴趣涵盖了隐私保护机器学习、联邦学习、同态加密等前沿技术。尤其是在如何通过加密技术保障数据隐私的研究领域，Fang 通过提出和改进各种算法，推动了隐私计算技术的发展。他也致力于如何在不暴露数据的情况下进行分布式计算和机器学习。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Quan Qian&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Quan Qian 是另一位活跃在机器学习与信息安全领域的学者，专注于隐私保护技术和加密算法。他的研究方向包括同态加密、联邦学习、数据隐私保护以及分布式学习等。他是隐私保护机器学习的领域内的知名学者之一，并在多个高影响力的会议和期刊上发表了相关研究成果。Qian 对于如何将加密技术与机器学习结合，以实现在保护隐私的前提下有效的数据分析，做出了重要贡献。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;两位学者的共同研究方向是将同态加密和联邦学习结合，探索如何在确保数据隐私的情况下，进行高效且可扩展的机器学习模型训练和推理。他们的工作对于推动隐私保护技术的发展具有重要意义。&lt;/p&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要：
&lt;/h2&gt;&lt;p&gt;随着机器学习的巨大成功，隐私保护成为了一个重要的关注点。本文提出了一种基于部分同态加密和联邦学习的多方隐私保护机器学习框架，命名为PFMLP。其核心思想是所有学习方仅通过同态加密传输加密的梯度。通过实验，PFMLP训练出的模型在准确率上几乎没有差异，偏差小于1%。考虑到同态加密的计算开销，本文采用了一种改进的Paillier算法，能够加速训练过程25%-28%。此外，本文还详细讨论了加密密钥长度、学习网络结构、学习客户端数量等方面的比较。&lt;/p&gt;
&lt;p&gt;关键词：多方机器学习；隐私保护机器学习；同态加密&lt;/p&gt;
&lt;h2 id=&#34;引言&#34;&gt;引言
&lt;/h2&gt;&lt;p&gt;在大数据时代，数据隐私已成为最重要的问题之一。迄今为止，已经存在许多安全策略和加密算法，旨在确保敏感数据不会受到泄露。此外，其中大多数安全策略假设只有拥有密钥的人才能访问机密数据。然而，随着机器学习，尤其是集中式机器学习的广泛应用，为了训练有效的模型，数据需要被收集并传输到一个中央点。因此，对于那些私人和敏感数据，它将不可避免地面临数据泄露的风险。因此，如何在没有数据泄露的情况下对私有数据集进行机器学习，是共享智能的关键问题。基于隐私保护，具有多方隐私保护的机器学习可以帮助各方用户在确保自身数据安全的前提下，共同学习彼此的数据[1-3]。其中，联邦学习[4,5]是一个典型的例子，它能够在多方计算的背景下解决隐私问题。本文提出了一种基于同态加密的隐私保护机器学习算法，命名为PFMLP。基本上，该模型通过多方隐私保护下的梯度学习共同训练。在每次迭代中，模型通过梯度下降进行优化，并通过传输梯度从其他用户的数据中学习。然而，正如[6]中提到的成员推断攻击，训练中的恶意用户可能会使用明文梯度训练一个影像模型，从而危及其他用户的数据安全。因此，我们引入了同态加密来防御这一攻击，允许在不解密的情况下对加密数据进行计算。此外，同态操作后的解密结果等价于对明文数据的操作[7]。由于在整个同态操作过程中无法识别操作的数据，因此可以保证隐私数据的安全。本文提出的基于同态加密的多方隐私保护机器学习在实际应用中具有广泛的场景。此外，本文的主要贡献如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提供了一种结合同态加密和联邦学习的多方隐私保护机器学习框架，在模型训练过程中实现数据和模型的安全保护。此外，所提出的框架能够在多方联合学习时保持隐私数据的安全。&lt;/li&gt;
&lt;li&gt;验证了通过我们提出的算法训练的模型与传统方法训练的模型在准确率上相似。从MNIST和金属疲劳数据集的实验结果来看，准确率偏差不超过1%。&lt;/li&gt;
&lt;li&gt;关于同态加密的时间开销，分析了不同密钥长度和网络结构的影响，发现随着密钥长度的增加或结构的复杂化，时间开销会增加。性能与安全性水平之间的权衡需要更多关注。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文其余部分的组织结构如下：第2节简要总结了相关工作；第3节从安全性、交互性和网络结构的角度详细讨论了联邦网络算法和Paillier联邦网络算法；第4节展示了实验结果，第5节总结了全文。&lt;/p&gt;
&lt;h2 id=&#34;相关工作&#34;&gt;相关工作
&lt;/h2&gt;&lt;h3 id=&#34;分布式机器学习&#34;&gt;分布式机器学习
&lt;/h3&gt;&lt;p&gt;分布式机器学习是一种多节点的机器学习，旨在提高性能、增加准确性，并轻松扩展数据到大规模。2013年在NIPS会议上提出了一种分布式机器学习框架[8]，该框架提出了一种状态同步并行模型，解决了普通同步或在海量数据和模型尺寸下训练的问题。2015年，Xing等人提出了一个通用框架，系统地解决了大规模机器学习中的数据和模型并行挑战[9]。Xie等人提出了一种有效的因子广播（SFB）计算模型，在分布式学习大矩阵参数化模型中既有效又高效[10]。Wei等人通过最大化机器间在给定网络带宽下的通信效率，最小化并行误差，同时确保大规模数据并行机器学习应用的理论融合[11]。Kim等人提出了一个分布式框架STRADS，优化了经典分布式机器学习算法的吞吐量[12]。在分布式深度学习中，2012年Jeffrey等人提出了谷歌的第一代深度学习系统Disbelief，并将模型拆分到32个节点进行计算[13]。2013年，分布式机器学习中的数据和模型并行性被引入到深度学习中，并在InfiniBand网络中实现[14]。2014年，Seide等人从理论上比较了分布式SGD（随机梯度下降）训练在模型和数据并行中的效率，并指出增加小批量的大小可以提高数据训练的效率[15,16]。&lt;/p&gt;
&lt;h3 id=&#34;安全多方计算与同态加密&#34;&gt;安全多方计算与同态加密
&lt;/h3&gt;&lt;p&gt;由于分布式机器学习基于中心任务调度，数据对系统是透明的，因此数据隐私无法得到有效保护。一般来说，分布式学习涉及多方计算，通常将复杂或未知的计算过程交给第三方。1986年，Yao提出了基于百万富翁问题的Garbred电路方法，可以用于解决一般问题，包括几乎所有的双方密码问题[17]。此后，1998年，Goldreich提出了安全多方计算（SMPC）的概念[18]。至今，SMPC被视为密码学的一个子领域，能够使分布式各方在不透露自己私有输入和输出的情况下共同计算任意功能。目前，同态加密已成为SMPC中常用的方法。1978年，Rivest等人提出了同态加密的概念，应用于银行业务[19]。作为第一个公钥加密系统，著名的RSA（Rivest-Shamir-Adleman）具有乘法同态性[20,21]。1999年，Paillier算法被发明[22]，由于Paillier满足加法同态性，它已广泛应用于云加密检索、数字拍卖、数字选举及其他隐私保护应用中。2009年，Craig Gentry首次提出了一种基于理想格的全同态加密（FHE）算法，满足加法同态性和乘法同态性[23]。由于FHE具有极高的安全性，它已被广泛应用[24–26]。尤其是在云计算中，同态加密为隐私保护作出了巨大贡献[27]。此外，差分隐私也是一种通过向样本中添加噪声来防止隐私泄漏的隐私保障技术[28–30]。由于引入噪声，当数据量较小时，噪声的影响不可避免地会影响模型训练。如何减少这种影响是一个大挑战。&lt;/p&gt;
&lt;h3 id=&#34;联邦学习&#34;&gt;联邦学习
&lt;/h3&gt;&lt;p&gt;针对数据隐私保护和多方联合学习，2016年谷歌提出了一种机器学习方法，命名为联邦学习[31]。作为一种多方协作的机器学习方法，联邦学习逐渐引起了研究界和工业界的广泛关注[32,33]。最初，联邦学习的目的是帮助Android用户解决本地更新模型的问题。此外，联邦学习可以应用于机器学习的各个领域。2019年，谷歌科学家提到，他们基于TensorFlow构建了一个用于移动设备领域联合学习的可扩展生产系统[34]。此外，2019年还提出了更多相关工作。Wang关注了在数据分布在多个边缘节点时，如何学习模型参数而无需将原始数据发送到中央节点的问题[35]。也有一些工作专注于联邦迁移学习，例如[36]中设计的框架，可以灵活地应用于各种安全多方机器学习。关于性能，[37]提出了一个框架SecureBoost，准确率几乎与五种隐私保护方法相当。联邦学习已广泛应用于各个领域。例如，谷歌设计的Gboard系统实现了键盘输入预测，同时保护隐私并帮助用户提高输入效率[38,39]。在医疗领域，患者的医疗数据是敏感的，因此联邦学习非常有用[40,41]。此外，联邦学习还可应用于自然语言处理[42]和推荐系统[43]等领域。此外，近年来，在隐私保护机器学习方面也有许多值得关注的工作。Zhou等人提出了使用差分隐私保护机器学习中的隐私，并使用SMC减少差分隐私引起的噪声[44,45]。2020年，Zhang等人提出了一种batchcrypt算法，该算法基于FATE框架的优化[46]，它将一批量的量化梯度编码为长整型，然后一次性加密，从而通过减少计算量提高了加密和解密效率。Wei Ou等人提出了一个基于同态加密的贝叶斯机器学习垂直联邦学习系统，该系统能够达到单一联合服务器训练模型的90%的性能[47]。&lt;/p&gt;
&lt;h2 id=&#34;方法与算法&#34;&gt;方法与算法
&lt;/h2&gt;&lt;h3 id=&#34;基于联邦思想的多样本协同学习&#34;&gt;基于联邦思想的多样本协同学习
&lt;/h3&gt;&lt;p&gt;联邦学习的思想是，在数据孤立的情况下，通过在训练过程中中间变量的交互，利用其他方的数据来优化自己的模型，如图1所示。从数据划分的角度，联邦学习可以分为两类：水平联邦学习（样本扩展）和垂直联邦学习（特征扩展）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;水平联邦学习&lt;/strong&gt;：水平联邦学习是通过样本扩展进行的机器学习。假设 \( D \) 表示数据，\( X \) 表示特征，\( Y \) 表示样本，\( I \) 表示数据索引。水平联邦学习可以表示为：&lt;/p&gt;
$$X_i = X_j, Y_i = Y_j, I_i \neq I_j, \forall D_i, D_j, i \neq j \tag{1}$$&lt;p&gt;这表示不同的用户有不同的数据，这些数据可能有交集也可能没有交集。水平联邦学习的主要思想是帮助多个用户使用自己的数据共同训练一个可靠的模型，同时确保数据的隐私和安全。然而，对于样本扩展，所有方的数据需要先对齐，以确保所有参与训练的方具有相同的特征域。这有助于所有方构建相同的模型架构并同步迭代。类似地，对于垂直联邦学习，所有参与者都有不同特征的样本。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;联邦网络算法&#34;&gt;联邦网络算法
&lt;/h3&gt;&lt;p&gt;本文提出的联邦学习网络的主要目标是通过在训练过程中传递中间变量，帮助所有方共同训练相同的模型。考虑到大多数神经网络是通过梯度下降进行训练的，这里我们选择梯度作为其中间变量。尽管梯度不能直接表示所有数据，但它可以表示模型与数据之间的关系，有助于模型的训练。联邦学习网络的架构如图2所示，包含一个计算服务器和多个学习客户端。&lt;/p&gt;
&lt;h4 id=&#34;学习客户端&#34;&gt;学习客户端
&lt;/h4&gt;&lt;p&gt;对于学习客户端，它们拥有自己的私有数据，并且假设所有数据已对齐，它们与其他学习参与者的数据量化维度一致。学习客户端的主要功能包括：与其他客户端初始化相同的初始模型、在本地训练数据、在训练过程中提取梯度、与计算服务器计算梯度、收集服务器的响应、传递结果、更新模型，并反复迭代，直到模型收敛。&lt;/p&gt;
&lt;h4 id=&#34;计算服务器&#34;&gt;计算服务器
&lt;/h4&gt;&lt;p&gt;计算服务器是学习过程中的一个中介平台。其主要功能包括：接收来自多个学习客户端的梯度信息、对梯度进行计算、整合多个模型学到的信息，并将结果分别传输给每个学习客户端。&lt;/p&gt;
&lt;h3 id=&#34;联邦多层感知机算法&#34;&gt;联邦多层感知机算法
&lt;/h3&gt;&lt;p&gt;在这里，我们提出了一种基于传统多层感知机的联邦多层感知机算法（FMLP）。FMLP可以通过共享梯度，在多方数据隔离环境中为每个客户端训练一个简单的模型。多层感知机，也称为深度前馈网络，是一种典型的深度学习模型。其架构示例如图3所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/%E4%BD%BF%E7%94%A8%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86%E5%92%8C%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20241114205904687.png&#34;
	width=&#34;616&#34;
	height=&#34;358&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/%E4%BD%BF%E7%94%A8%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86%E5%92%8C%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20241114205904687_hu16887854498636176068.png 480w, https://JiangZhiyu-1024.github.io/p/%E4%BD%BF%E7%94%A8%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86%E5%92%8C%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20241114205904687_hu9960055567494880987.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241114205904687&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;172&#34;
		data-flex-basis=&#34;412px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;所有涉及算法的参数及其含义如表1所示。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表1. PFMLP算法中的参数及描述&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;参数&lt;/th&gt;
          &lt;th&gt;说明&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;$x$：数据集中的样本&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2&lt;/td&gt;
          &lt;td&gt;$\theta$：模型的参数&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;3&lt;/td&gt;
          &lt;td&gt;$f_p$：前馈过程&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;4&lt;/td&gt;
          &lt;td&gt;$out$：每次迭代的输出&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;5&lt;/td&gt;
          &lt;td&gt;$f^*$：激活函数&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;6&lt;/td&gt;
          &lt;td&gt;$loss$：损失函数&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;7&lt;/td&gt;
          &lt;td&gt;$c$：通过损失函数计算的损失&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;8&lt;/td&gt;
          &lt;td&gt;$e$：最小误差&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;9&lt;/td&gt;
          &lt;td&gt;$bp$：反向传播过程&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;10&lt;/td&gt;
          &lt;td&gt;$grad$：反向传播过程计算的梯度&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;11&lt;/td&gt;
          &lt;td&gt;$lr$：学习率&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;假设模型的参数为 $\theta = {\omega_1, \cdots, \omega_n, b_1, \cdots, b_n}$，训练的学习率为 $lr$。数据集可以表示为 $x = {x_1, \cdots, x_n}$。模型的目标是逼近一个分布 $f^*$。网络的前馈过程是计算训练输出，定义为：&lt;/p&gt;
$$
out = f_p(x, \theta)
$$&lt;p&gt;计算输出与理想值之间距离的损失函数可以定义为：&lt;/p&gt;
$$
c = loss(f^*(x), out) \tag{3}
$$&lt;p&gt;反向传播的功能是计算梯度，并将其从损失函数向后传播，帮助网络根据梯度调整参数，从而减少输出值与理想值之间的误差。反向传播过程可以定义为：&lt;/p&gt;
$$
grad = bp(x, \theta, c) \tag{4}
$$&lt;p&gt;模型更新过程是根据反向传播得到的梯度调整网络参数，可以表示为：&lt;/p&gt;
$$
\theta&#39; = \theta - lr \cdot grad \tag{5}
$$&lt;p&gt;通过联邦网络实现的多层感知机（MLP），我们可以得到一个联邦多层感知机（FMLP）。然后，MLP 模型的副本存储在每个学习客户端的本地内存中。它包含一个输入层，具有 $x$ 个单元，$n$ 个隐藏层，每个隐藏层有 $y$ 个单元，以及一个输出层，具有 $z$ 个单元。$x$ 的大小取决于输入数据的特征维度，$z$ 的大小取决于网络所需的输出，具体依赖于实际应用的目标输出。&lt;/p&gt;
&lt;p&gt;计算服务器的主要功能是融合梯度数据，帮助模型加速梯度下降，同时学习来自每个客户端的数据。在模型更新之前，每个学习客户端将梯度传递给计算服务器进行模型训练。此外，计算服务器整合所有客户端的梯度数据，并返回计算得到的新梯度给每个客户端用于模型更新。最后，当每个客户端的损失小于 $e$ 时，模型收敛。此外，所有客户端都可以获得相同的联邦模型。FMLP的具体步骤见算法1。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;算法 1 联邦多层感知机&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;输入：数据集 $x$&lt;br&gt;
输出：模型 $\theta_{final}$&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始化模型参数 $\theta$&lt;/li&gt;
&lt;li&gt;对于每次迭代 $i$，执行以下步骤：&lt;br&gt;
3. 前馈传播：$out_i = f_p(x_i, \theta_i)$&lt;br&gt;
4. 计算损失：$c_i = loss(f^*(x_i), out_i)$&lt;br&gt;
5. 如果 $c_i &amp;lt; e$，则&lt;br&gt;
6. 跳出循环&lt;br&gt;
7. 否则&lt;br&gt;
8. 反向传播：$grad_i = bp(x_i, \theta_i, c_i)$&lt;br&gt;
9. 将梯度发送给计算服务器并获取新梯度&lt;br&gt;
10. 更新：$\theta_{i+1} = \theta_i - lr \cdot grad_{new}$&lt;br&gt;
11. 结束&lt;/li&gt;
&lt;li&gt;结束循环&lt;/li&gt;
&lt;li&gt;返回带有参数 $\theta_{final}$ 的模型&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;paillier-联邦网络&#34;&gt;Paillier 联邦网络
&lt;/h3&gt;&lt;p&gt;本文提出的联邦网络允许多个方在数据孤立的情况下进行协同机器学习。然而，在实际情况中，攻击者所需要的不仅仅是参与者提供的数据，还有多个方训练的最终模型。根据Shokri等人在2017年提出的成员推断攻击，攻击者可以入侵服务器，并从服务器中的数据推断出若干个影子模型。基于集成学习的思想，攻击者可以最终通过这些影子模型得到一个与实际合作训练的模型相似的预测。换句话说，在这种情况下，联邦模型只能解决数据安全问题，而不能解决模型安全问题。因此，为了保证模型的安全性，可以将同态加密引入联邦学习中。&lt;/p&gt;
&lt;p&gt;此外，同态加密的核心思想是，在对明文 $a$ 进行加密得到密文 $c$ 后，在密文空间内对 $c$ 执行某些操作的结果，相当于在明文空间内对 $a$ 执行相同操作的结果。加密操作可以表示为：&lt;/p&gt;
$$
E(a) \oplus E(b) = E(a \otimes b) \tag{6}
$$&lt;p&gt;在公式 (6) 中，$E$ 表示加密算法，$a$ 和 $b$ 表示两个不同的明文，$\oplus$ 和 $\otimes$ 表示操作符。如果操作是乘法操作，那么同态加密满足乘法同态性，例如 RSA 算法 [20]。如果操作是加法操作，那么同态加密算法满足加法同态性。Paillier 算法是最著名的一种 [22]。此外，如果算法同时满足加法和乘法同态性，那么该加密算法满足完全同态性 [23]。由于在多层感知机（MLP）中我们需要对梯度数据进行求和，因此可以使用 Paillier 算法进行同态加密。&lt;/p&gt;
&lt;h4 id=&#34;paillier-算法&#34;&gt;&lt;strong&gt;Paillier 算法&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;如上所述，Paillier 加密是一种部分同态加密，满足加法同态性。它可以分为三部分：密钥生成、加密和解密。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;密钥生成&lt;/strong&gt;：首先，选择两个足够大的素数 $p$ 和 $q$，它们的长度相等，并且满足 $\text{gcd}(p \cdot q, (p - 1) \cdot (q - 1)) = 1$。然后，计算 $n$ 和 $\lambda$，如下所示：&lt;/li&gt;
&lt;/ul&gt;
$$
n = p \cdot q \tag{7}
$$$$
\lambda = \text{lcm}(p - 1, q - 1) \tag{8}
$$&lt;p&gt;接着，随机选择一个整数 $g$，使得 $g \in Z^*_{n^2}$，从而使得 $n$ 能够整除 $g$ 的阶。然后，定义 $L(x)$ 来计算 $\mu$，如下所示：&lt;/p&gt;
$$
L(x) = \frac{x - 1}{n} \tag{9}
$$$$
\mu = (L(g^\lambda \mod n^2))^{-1} \mod n \tag{10}
$$&lt;p&gt;到此为止，我们可以得到公钥为 $(n, g)$，私钥为 $(\lambda, \mu)$。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;加密&lt;/strong&gt;：假设明文为 $m$，密文为 $c$，使用公钥进行加密的过程可以表示为：&lt;/li&gt;
&lt;/ul&gt;
$$
c = g^m \cdot r^n \mod n^2 \tag{11}
$$&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;解密&lt;/strong&gt;：使用私钥解密密文 $c$，得到明文 $m$ 的过程为：&lt;/li&gt;
&lt;/ul&gt;
$$
m = L(c^\lambda \mod n^2) \cdot \mu \mod n \tag{12}
$$&lt;h4 id=&#34;改进的-paillier-算法&#34;&gt;&lt;strong&gt;改进的 Paillier 算法&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;然而，由于 Paillier 算法在进行加密和解密时的高复杂度，这将影响网络训练的效率。因此，我们使用了改进版本的 Paillier，并且在 [48] 中详细证明了优化的正确性和效率。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;密钥生成&lt;/strong&gt;：使用 $\alpha$ 作为除数，如果 $\lambda$ 替换了私钥中的 $\lambda$ 位置，我们可以修改公钥中的 $g$，并确保 $g$ 的阶为 $\alpha n$。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;加密&lt;/strong&gt;：假设明文为 $m$，密文为 $c$，$r$ 为随机正整数，并且满足 $r &amp;lt; \alpha$。改进的加密过程可以表示为：&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
$$
c = g^m \cdot (g^n)^r \mod n^2 \tag{13}
$$&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;解密&lt;/strong&gt;：解密过程可以表示为：&lt;/li&gt;
&lt;/ul&gt;
$$
m = L(c^\alpha \mod n^2) \cdot L(g^\alpha \mod n^2)^{-1} \mod n \tag{14}
$$&lt;p&gt;从上述算法可以看出，使用 $\alpha$ 代替 $\lambda$ 的最大优势在于解密过程中。幂运算的次数从 $2 \cdot \lambda$ 次减少为 $2 \cdot \alpha$ 次。由于 $\alpha$ 是 $\lambda$ 的除数，时间开销显著减少。原生 Paillier 算法的计算复杂度为 $O(|n|^3)$，而改进后的 Paillier 算法的计算复杂度为 $O(|n|^2|\alpha|)$ [49]。&lt;/p&gt;
&lt;h4 id=&#34;paillier-联邦网络的架构&#34;&gt;&lt;strong&gt;Paillier 联邦网络的架构&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;在这里，我们使用 Paillier 加密来保护梯度数据。因此，即使攻击者破坏了计算服务器，他们也无法从每个学习客户端获取梯度数据的具体信息。此外，攻击者无法利用这些加密的梯度数据来训练影子模型。由于 Paillier 加密需要密钥对，为了生成和管理密钥对，我们在算法中加入了一个密钥管理中心（KMC）。Paillier 联邦网络的架构如图 4 所示，它包括 KMC、计算服务器和多个学习客户端。&lt;/p&gt;
&lt;h3 id=&#34;paillier-联邦多层感知机-pfmlp&#34;&gt;&lt;strong&gt;Paillier 联邦多层感知机 (PFMLP)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;PFMLP 的基本结构与 FMLP 非常相似。由于 PFMLP 需要与 KMC 进行交互，学习客户端在训练开始之前应该向 KMC 发送请求。KMC 确认每个参与者都在线，然后生成密钥对并将其返回给学习客户端。收到密钥对后，每个学习客户端基于加密数据进行多方机器学习。PFMLP 的流程图如图 5 所示。与 FMLP 相比，PFMLP 增加了三个部分：(1) 学习客户端的加密和解密操作；(2) 计算服务器的同态操作；(3) 密钥管理中心（KMC）中的密钥对生成和分发。在 PFMLP 中，包含学习客户端、计算服务器和 KMC。学习客户端的算法如下所示：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;算法 2：学习客户端中的 PFMLP&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;输入：数据集 x&lt;br&gt;
输出：模型 θ_f inal&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;向 KMC 请求密钥对&lt;/li&gt;
&lt;li&gt;初始化模型参数 θ&lt;/li&gt;
&lt;li&gt;对于每次迭代 i:
&lt;ol&gt;
&lt;li&gt;前向传播：$out_i = f_p(x_i, \theta_i)$&lt;/li&gt;
&lt;li&gt;计算损失：$c_i = loss(f^*(x_i), out_i)$&lt;/li&gt;
&lt;li&gt;如果 $c_i &amp;lt; e$，则
&lt;ol&gt;
&lt;li&gt;退出&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;否则：
&lt;ol&gt;
&lt;li&gt;反向传播：$grad_i = bp(x_i, \theta_i, c_i)$&lt;/li&gt;
&lt;li&gt;使用客户端 i 的公钥加密梯度：$Enc(grad_i) = EncPaillier(Publickey, grad_i)$&lt;/li&gt;
&lt;li&gt;将加密的梯度 $Enc(grad_i)$ 发送给计算服务器并接收：$Enc(grad_i^{new})$&lt;/li&gt;
&lt;li&gt;使用客户端 i 的私钥解密梯度：$grad_i = DecPaillier(Privatekey, Enc(grad_i))$&lt;/li&gt;
&lt;li&gt;更新：$\theta_{i+1} = \theta_i - lr \cdot grad_{new}$&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;结束&lt;/li&gt;
&lt;li&gt;返回具有参数 θ_f inal 的模型&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;学习客户端在每次学习迭代计算完梯度后，并不会立即更新本地模型。它会对梯度数据进行同态加密，并将其传输给计算服务器，随后等待服务器在进行同态操作后返回新的加密梯度数据。在解密阶段，一旦客户端解密了新的加密梯度数据，它就可以使用新的梯度更新每个学习客户端的本地模型。因此，新的梯度隐式地包含了其他客户端的私有数据，从而间接保护了数据隐私。&lt;/p&gt;
&lt;p&gt;由于 PFMLP 对梯度数据执行 Paillier 加密，即使计算服务器被黑客攻破，泄露的数据也仅显示加密后的梯度数据 $Enc(grad)$。因此，可以避免推理攻击的威胁。KMC 的算法如算法 3 所示。此外，KMC 的主要功能是生成和分发密钥对。也就是说，当它收到来自学习客户端的请求时，它会生成一个密钥对并将其分发给客户端。&lt;/p&gt;
&lt;p&gt;算法 3 KMC 中的 PFMLP&lt;br&gt;
输入：请求&lt;br&gt;
输出：密钥对&lt;/p&gt;
&lt;p&gt;1: 在监听客户端请求时循环&lt;br&gt;
2: 如果收到来自客户端的请求，则&lt;br&gt;
3: 生成一个密钥对；&lt;br&gt;
4: 将密钥对返回给学习客户端；&lt;br&gt;
5: 结束条件&lt;br&gt;
6: 结束循环&lt;/p&gt;
&lt;p&gt;算法 4 计算服务器中的 PFMLP&lt;br&gt;
输入：请求&lt;br&gt;
输出：梯度数据&lt;/p&gt;
&lt;p&gt;1: 在监听来自客户端的请求时循环&lt;br&gt;
2: 初始化梯度数据；&lt;br&gt;
3: 如果收到请求，则&lt;br&gt;
4: 将加密数据 Enc(data) 推送到队列；&lt;br&gt;
5: 如果请求的数量 == 学习客户端的数量，则&lt;br&gt;
6: 对于每个学习客户端的请求：&lt;br&gt;
7: 将梯度数据更新为：GradientData = GradientData ⊕ Enc(datai)；&lt;br&gt;
8: 结束循环&lt;br&gt;
9: 将梯度数据返回给每个客户端；&lt;br&gt;
10: 退出循环；&lt;br&gt;
11: 结束条件&lt;br&gt;
12: 结束条件&lt;br&gt;
13: 结束循环&lt;/p&gt;
&lt;h3 id=&#34;算法安全性分析&#34;&gt;算法安全性分析
&lt;/h3&gt;&lt;p&gt;在 PFMLP 中，密钥管理中心仅负责密钥生成，并且不能访问任何数据。对于密钥管理中心，它甚至不知道客户端用密钥加密了哪些数据，因此它无法与其他方串通非法访问数据。计算服务器接收到的数据是客户端加密的密文，所有操作都是同态操作，没有解密过程。这意味着，在计算服务器上，所有数据都是加密格式的，因此即使服务器被攻破，也无法获得明文数据。学习客户端从密钥管理中心获取密钥对，然后将加密的梯度数据发送到计算服务器；计算服务器计算完成后，将仍然是加密格式的结果返回给客户端。在整个过程中，客户端无法访问其他客户端的数据。参与的唯一数据是上传的数据和返回的结果，它们都是加密格式的，这可以确保数据的安全性。如果攻击者想通过攻击计算服务器或通信通道来获取数据，他/她只能得到密文。由于我们可以在每次迭代中更换密钥对，即使攻击者足够幸运能够破解几轮训练结果，他/她也无法获得最终结果。即使攻击者是参与者，由于上述的客户端安全分析，他/她也无法从其他客户端获取数据。&lt;/p&gt;
&lt;h2 id=&#34;实验与结果分析&#34;&gt;实验与结果分析
&lt;/h2&gt;&lt;h2 id=&#34;实验数据集与环境&#34;&gt;实验数据集与环境
&lt;/h2&gt;&lt;p&gt;本实验使用了两个数据集进行验证：MNIST数据集和金属疲劳强度数据集。对于MNIST手写数字数据集[50]，它包含60,000个训练样本和10,000个测试样本。此外，神经网络模型包括784个输入层单元、两个默认64个单元的隐藏层和一个包含10个输出单元的输出层。关于金属疲劳数据，它只有437条记录，来自NIMS MatNavi开放数据集[51]。MatNavi是全球最大的材料数据库之一，涵盖了聚合物、陶瓷、合金、超导材料、复合材料和扩散数据库等。这里，我们从MatNavi中选择了437条金属疲劳强度数据，用于建立回归模型，测试不同金属（如碳钢、低合金钢、渗碳钢和弹簧钢）在不同测试条件下（如不同组件、轧制产品特性和后续热处理）下的表现。每条金属疲劳数据包含15维特征和1维标签。根据疲劳数据集，我们将其分为四类，如表2所示。实验中使用的模型结构包括一个15个单元（15维）的输入层、三个64单元的隐藏层和一个包含四个单元的输出层。PFMLP的网络结构如表3所示。&lt;/p&gt;
&lt;p&gt;表2. 用于多分类任务的疲劳数据集。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;数据集&lt;/th&gt;
          &lt;th&gt;数据范围&lt;/th&gt;
          &lt;th&gt;数据量&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;疲劳&lt;/td&gt;
          &lt;td&gt;[200, 400)&lt;/td&gt;
          &lt;td&gt;56&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;[400, 500)&lt;/td&gt;
          &lt;td&gt;147&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;[500, 600)&lt;/td&gt;
          &lt;td&gt;148&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;[600, ∞)&lt;/td&gt;
          &lt;td&gt;86&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;表3. PFMLP的网络结构。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;数据集&lt;/th&gt;
          &lt;th&gt;输入层&lt;/th&gt;
          &lt;th&gt;隐藏层&lt;/th&gt;
          &lt;th&gt;输出层&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;MNIST&lt;/td&gt;
          &lt;td&gt;784（单位）&lt;/td&gt;
          &lt;td&gt;2（层）· 64（单位）&lt;/td&gt;
          &lt;td&gt;10（单位）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;疲劳&lt;/td&gt;
          &lt;td&gt;15（单位）&lt;/td&gt;
          &lt;td&gt;3（层）· 64（单位）&lt;/td&gt;
          &lt;td&gt;4（单位）&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这里，$D^{Dataset}_n$ 表示数据集的第 n 个数据。为了评估 PFMLP 算法及其优化方法，设计了几组对比实验，从三个角度进行比较：(1) 联邦多层感知器与单节点多层感知器的预测准确性；(2) 使用不同密钥长度进行模型训练的时间消耗；(3) 使用不同大小的隐藏层单元进行模型训练的时间消耗；(4) 不同数量的学习客户端对模型性能的影响。实验环境为 Windows 10，Python 3.6，scikit-learn 0.21.3 和 phe 1.4.0。我们在局域网中部署了计算服务器、KMC 和多个客户端，并通过 Socket 建立了机器之间的通信。具体的网络部署如图6所示。&lt;/p&gt;
&lt;h3 id=&#34;精度比较&#34;&gt;精度比较
&lt;/h3&gt;&lt;p&gt;为了进行比较，PFMLP 和 MLP 算法在相同的网络结构下进行模型训练，并使用相同的数据集进行学习。假设有两个学习客户端，我们将每个数据集分成两个子集，并将它们分配给两个学习客户端。对于 MNIST 数据集，我们选择前 4000 个数据作为训练集 Dmnist，然后将这 4000 个数据分别分为两个部分：Dmnist I = {Dmnist 1, · · · , Dmnist 200}，Dmnist II = {Dmnist 201, · · · , Dmnist 400}。测试数据使用 MNIST 提供的 10,000 个测试集。同时，我们从金属疲劳强度数据集中选择 400 个数据，并将它们分为两个相等的子集进行模型训练。假设原始数据为 DFatigue，将原始数据随机化，记为 DFatigue′ = random(DFatigue)。两个子数据集为 DFatigue′ I = {DFatigue′ 1, · · · , DFatigue′ 200}，DFatigue′ II = {DFatigue′ 201, · · · , DFatigue′ 400}。此外，我们将 70% 作为训练集，剩余的 30% 作为测试集。实验结果如表 4 所示。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表 4. MLP 和 PFMLP 在两个数据集上的预测精度比较结果&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;数据集&lt;/th&gt;
          &lt;th&gt;数据子集&lt;/th&gt;
          &lt;th&gt;算法&lt;/th&gt;
          &lt;th&gt;精度&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;MNIST&lt;/td&gt;
          &lt;td&gt;Dmnist 1&lt;/td&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;0.8333&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;Dmnist 2&lt;/td&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;0.9033&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;Dmnist&lt;/td&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;0.9245&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;Dmnist 1&lt;/td&gt;
          &lt;td&gt;PFMLP&lt;/td&gt;
          &lt;td&gt;0.9252&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;Dmnist 2&lt;/td&gt;
          &lt;td&gt;PFMLP&lt;/td&gt;
          &lt;td&gt;0.9252&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Fatigue&lt;/td&gt;
          &lt;td&gt;DFatigue′ 1&lt;/td&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;0.9013&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;DFatigue′ 2&lt;/td&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;0.7833&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;DFatigue′&lt;/td&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;0.8583&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;DFatigue′ 1&lt;/td&gt;
          &lt;td&gt;PFMLP&lt;/td&gt;
          &lt;td&gt;0.8833&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;DFatigue′ 2&lt;/td&gt;
          &lt;td&gt;PFMLP&lt;/td&gt;
          &lt;td&gt;0.8167&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;DFatigue′&lt;/td&gt;
          &lt;td&gt;PFMLP&lt;/td&gt;
          &lt;td&gt;0.8500&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;从表 4 可以看出，PFMLP 训练的模型比本地 MLP 的模型更准确。PFMLP 训练的最终模型几乎等于或甚至优于使用每个客户端所有数据训练的 MLP 模型。在 MNIST 数据集上的实验表明，PFMLP 训练的模型在测试集上的准确率为 0.9252，而使用所有训练集数据的 MLP 训练的模型准确率为 0.9245，PFMLP 的准确率比 MLP 高出 0.007。&lt;/p&gt;
&lt;p&gt;对于金属疲劳强度数据集，由于每个客户端上的模型都是从相同的 PFMLP 中学习的，我们可以根据测试集的数量对两个实验的结果进行加权平均，从而得到最终的预测精度为 0.85。与学习了所有数据的 MLP 模型精度为 0.858 相比，精度仅下降了 0.008。因此，从两个数据集的实验结果来看，PFMLP 算法能够训练出一个与 MLP 在多个客户端上的所有数据上几乎相同精度的模型。详细结果如图 7 所示。&lt;/p&gt;
&lt;h3 id=&#34;不同密钥长度下模型训练时间对比&#34;&gt;不同密钥长度下模型训练时间对比
&lt;/h3&gt;&lt;p&gt;由于成员推断攻击的威胁，明文传输梯度数据可能被恶意用户利用来训练自己的影子模型，从而侵犯其他客户端的隐私数据安全。为此，PFMLP 使用了 Paillier 同态加密。此外，在梯度数据传输过程中执行加密，并且在计算服务器中进行同态操作，确保即使服务器存在安全漏洞，加密的梯度数据也不会泄露。&lt;/p&gt;
&lt;p&gt;在 Paillier 中，密钥长度是影响安全级别的一个重要因素。通常，密钥长度越长，安全性越高。然而，使用较长的密钥也会增加生成密文的时间开销。对于 MNIST 和金属疲劳数据集，进行了三次对比实验。模型结构固定，不同的密钥长度是模型训练时间开销的核心因素。表 5 显示了详细信息。&lt;/p&gt;
&lt;p&gt;从表 5 中可以看出，在两个数据集中，Paillier 密钥长度的影响与时间消耗成正比。同时，如图 8 和图 9 所示，这是 PFMLP 在两个数据集上每轮学习训练时间的折线图。由于在每轮中都需要对梯度数据进行加密和解密，并将加密后的梯度数据传输到计算服务器进行进一步操作，因此，随着密钥长度的增加，每轮训练的时间开销也增加，这一现象是合理的。因此，我们可以选择一个适当的密钥长度，作为安全性和时间性能之间的折衷。此外，为了提高安全级别，我们可以在每轮训练中更新密钥。这样，即使某一轮的密钥被破解，也不会影响整体训练过程的安全性，从而实现更高的数据安全级别。&lt;/p&gt;
&lt;p&gt;从上述实验中可以看出，在相同模型和相同密钥长度下，4000 条数据每轮需要 358.14 秒，8000 条数据需要 733.69 秒，12000 条数据需要 1284.06 秒。因此，时间开销与加密数据的数量呈正相关。我们使用改进的 Paillier 算法在 MNIST 数据集上进行实验，并比较了相同梯度数据在相同轮次中的加密和解密时间开销，结果如表 6 所示。&lt;/p&gt;
&lt;p&gt;表 6. 不同密钥长度对每轮迭代时间的影响&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;算法&lt;/th&gt;
          &lt;th&gt;密钥长度（位）&lt;/th&gt;
          &lt;th&gt;时间（秒）&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;Paillier&lt;/td&gt;
          &lt;td&gt;128&lt;/td&gt;
          &lt;td&gt;1068.38&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;256&lt;/td&gt;
          &lt;td&gt;6411.23&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;512&lt;/td&gt;
          &lt;td&gt;35,930.83&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;改进版 Paillier&lt;/td&gt;
          &lt;td&gt;128&lt;/td&gt;
          &lt;td&gt;779.37&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;256&lt;/td&gt;
          &lt;td&gt;4716.37&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;512&lt;/td&gt;
          &lt;td&gt;26,148.56&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;从表 6 可以看出，与原版 Paillier 算法相比，改进版 Paillier 在加密和解密性能上显著提高，提升幅度接近 25% 至 28%。&lt;/p&gt;
&lt;h3 id=&#34;隐藏层大小对训练性能的影响比较&#34;&gt;隐藏层大小对训练性能的影响比较
&lt;/h3&gt;&lt;p&gt;对于神经网络，每一层的大小会影响前向传播和反向传播的时间性能。一般来说，网络大小与训练时间呈正相关。在这里，我们设计了几组关于两个数据集的比较实验，结果如表 7 所示。具体的每轮训练时间开销如图 10 和图 11 所示。&lt;/p&gt;
&lt;p&gt;表 7. 不同隐藏层大小对总训练时间的影响&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;数据集&lt;/th&gt;
          &lt;th&gt;隐藏层大小（单元数）&lt;/th&gt;
          &lt;th&gt;时间（秒）&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;MNIST&lt;/td&gt;
          &lt;td&gt;2 · 64&lt;/td&gt;
          &lt;td&gt;12,033.25&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;2 · 128&lt;/td&gt;
          &lt;td&gt;23,981.02&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;2 · 256&lt;/td&gt;
          &lt;td&gt;47,702.87&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Fatigue&lt;/td&gt;
          &lt;td&gt;3 · 64&lt;/td&gt;
          &lt;td&gt;2615.42&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;3 · 128&lt;/td&gt;
          &lt;td&gt;6941.04&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;3 · 256&lt;/td&gt;
          &lt;td&gt;21,782.07&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;因此，由于算法需要对梯度矩阵进行加密，并且隐藏层单元数越多，时间开销会成比例增加。此外，随着隐藏层单元数的增加，网络中需要传输的数据量也会增加。为了减少 PFMLP 算法的时间开销，在保证准确性的前提下，应尽可能减少隐藏层的数量和每个隐藏层的单元数。&lt;/p&gt;
&lt;h3 id=&#34;不同数量学习客户端对训练准确度和时间开销的影响&#34;&gt;不同数量学习客户端对训练准确度和时间开销的影响
&lt;/h3&gt;&lt;p&gt;PFMLP 支持多方机器学习。此外，理论上，随着客户端数量的增加，学习算法应该保证在模型训练过程中获得相似的准确度，并且减少时间开销。在此，我们设计了一项比较实验，分别在单节点（MLP）、两个客户端（2-Client-PFMLP）和四个客户端（4-Client-PFMLP）上对金属疲劳强度数据集进行实验。实验结果如表 8 所示。这里，本地准确度是指模型在本地测试数据集上的预测准确率；逻辑准确度是指每个客户端上的平均准确率。详细结果见图 12。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表 8. 不同学习客户端数量下，PFMLP 在金属疲劳数据集上的准确度&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;算法&lt;/th&gt;
          &lt;th&gt;数据集&lt;/th&gt;
          &lt;th&gt;本地准确度&lt;/th&gt;
          &lt;th&gt;逻辑准确度&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;DFatigue′ 0−400&lt;/td&gt;
          &lt;td&gt;0.858&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;DFatigue′ 0−200&lt;/td&gt;
          &lt;td&gt;0.833&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;DFatigue′ 200−400&lt;/td&gt;
          &lt;td&gt;0.783&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2-Client-PFMLP&lt;/td&gt;
          &lt;td&gt;DFatigue′ 0−200&lt;/td&gt;
          &lt;td&gt;0.867&lt;/td&gt;
          &lt;td&gt;0.850&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2-Client-PFMLP&lt;/td&gt;
          &lt;td&gt;DFatigue′ 200−400&lt;/td&gt;
          &lt;td&gt;0.833&lt;/td&gt;
          &lt;td&gt;0.850&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;DFatigue′ 0−100&lt;/td&gt;
          &lt;td&gt;0.767&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;DFatigue′ 100−200&lt;/td&gt;
          &lt;td&gt;0.933&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;DFatigue′ 200−300&lt;/td&gt;
          &lt;td&gt;0.800&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;MLP&lt;/td&gt;
          &lt;td&gt;DFatigue′ 300−400&lt;/td&gt;
          &lt;td&gt;0.600&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;4-Client-PFMLP&lt;/td&gt;
          &lt;td&gt;DFatigue′ 0−100&lt;/td&gt;
          &lt;td&gt;0.833&lt;/td&gt;
          &lt;td&gt;0.850&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;4-Client-PFMLP&lt;/td&gt;
          &lt;td&gt;DFatigue′ 100−200&lt;/td&gt;
          &lt;td&gt;0.967&lt;/td&gt;
          &lt;td&gt;0.850&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;4-Client-PFMLP&lt;/td&gt;
          &lt;td&gt;DFatigue′ 200−300&lt;/td&gt;
          &lt;td&gt;0.867&lt;/td&gt;
          &lt;td&gt;0.850&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;4-Client-PFMLP&lt;/td&gt;
          &lt;td&gt;DFatigue′ 300−400&lt;/td&gt;
          &lt;td&gt;0.733&lt;/td&gt;
          &lt;td&gt;0.850&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;从图 12 可以看出，多客户端 PFMLP 算法显著提高了预测准确度。两种和四种学习客户端的逻辑准确率几乎相同。与划分数据后的本地训练相比，PFMLP 训练的本地准确率有所提高，尤其在极端情况下，准确度得到了放大。例如，在一个 4-Client-PFMLP 实验中，最后一个学习客户端显然有离群数据，而 PFMLP 的准确率比 MLP 高出 13.3%。第二个学习客户端的本地准确率达到了 93.3%，而使用 PFMLP 后仍提高了 3.4%。&lt;/p&gt;
&lt;p&gt;此外，从表 8 可以看出，客户端数量对 PFMLP 训练模型的性能几乎没有影响。这些模型的性能接近于通过收集所有参与者数据的单一 MLP 训练的模型。同时，由于 N-Client-PFMLP 的核心思想是基于批次扩展，一旦每个客户端的数据量较少，他们每轮学习的批次大小也会更小。因此，训练过程的时间开销将会减少。&lt;/p&gt;
&lt;h2 id=&#34;结论与未来工作&#34;&gt;结论与未来工作
&lt;/h2&gt;&lt;p&gt;本文提出的多方隐私保护机器学习方法，通过结合同态加密和联邦学习，能够帮助多个用户在不泄露自己私密数据的情况下进行机器学习。特别是在隐私数据保护方面，该算法能够在数据孤立的情况下训练通用模型。PFMLP 算法的实验结果表明，使用 PFMLP 训练的模型效果与在单台机器上使用所有数据训练的模型相似。所有参与方只需传输梯度数据，梯度融合则在中央计算服务器上通过同态操作完成。学习模型会根据经过同态操作后的新梯度数据进行更新。然而，同态加密不可避免地会引发一些性能问题，例如加密和解密过程的额外开销，这将大大影响训练效率。此外，网络结构、加密/解密密钥长度和密钥替换频率等因素也会影响最终的性能。&lt;/p&gt;
&lt;p&gt;关于未来的工作，首先，应考虑更加强大和可扩展的联邦学习方法，例如将特征分配到不同客户端的纵向联邦学习算法。其次，高效的同态加密算法将加速学习性能。最后，应该更加关注更加稳健的隐私保护学习算法，包括混合算法、防恶意攻击客户端算法等。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
