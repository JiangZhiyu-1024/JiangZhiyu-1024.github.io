<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>隐私推理 on Zion Blaze</title>
        <link>https://JiangZhiyu-1024.github.io/categories/%E9%9A%90%E7%A7%81%E6%8E%A8%E7%90%86/</link>
        <description>Recent content in 隐私推理 on Zion Blaze</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>Zion Blaze</copyright>
        <lastBuildDate>Thu, 02 Jan 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://JiangZhiyu-1024.github.io/categories/%E9%9A%90%E7%A7%81%E6%8E%A8%E7%90%86/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>MOFHEI Model Optimizing Framework for Fast  and Efficient Homomorphically Encrypted Neural  Network Inference</title>
        <link>https://JiangZhiyu-1024.github.io/p/mofhei-model-optimizing-framework-for-fast-and-efficient-homomorphically-encrypted-neural-network-inference/</link>
        <pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate>
        
        <guid>https://JiangZhiyu-1024.github.io/p/mofhei-model-optimizing-framework-for-fast-and-efficient-homomorphically-encrypted-neural-network-inference/</guid>
        <description>&lt;img src="https://JiangZhiyu-1024.github.io/p/mofhei-model-optimizing-framework-for-fast-and-efficient-homomorphically-encrypted-neural-network-inference/sunset-7133867_1280.jpg" alt="Featured image of post MOFHEI Model Optimizing Framework for Fast  and Efficient Homomorphically Encrypted Neural  Network Inference" /&gt;&lt;h1 id=&#34;mofhei-model-optimizing-framework-for-fast--and-efficient-homomorphically-encrypted-neural--network-inference&#34;&gt;MOFHEI Model Optimizing Framework for Fast  and Efficient Homomorphically Encrypted Neural  Network Inference
&lt;/h1&gt;&lt;p&gt;MOFHEI：用于快速高效同态加密神经网络推理的模型优化框架&lt;/p&gt;
&lt;p&gt;摘要：由于机器学习（ML）在广泛领域中的广泛应用以及数据隐私的重要性，隐私保护机器学习（PPML）解决方案近年来受到广泛关注。其中一种方法基于同态加密（HE），它使我们能够在加密数据上执行机器学习任务。然而，即使使用最先进的HE方案，与明文操作相比，HE操作仍然显著更慢，并且需要大量内存。因此，我们提出了MOFHEI，这是一种优化模型的框架，用于实现基于HE的神经网络推理（称为私有推理，PI）的快速高效化。首先，我们提出了一种基于学习的方法，能够自动将预训练的ML模型转换为兼容HE操作的版本，称为HE友好版本。然后，我们的迭代块剪枝方法根据数据打包方法，以可配置的块形状剪枝模型参数。这使我们能够减少大量高成本的HE操作，从而降低延迟和内存消耗，同时保持模型性能。我们通过对不同模型和各种数据集的广泛实验评估了我们的框架。我们的方法在LeNet上实现了高达98%的剪枝率，减少了高达93%的PI所需HE操作，将延迟和内存需求分别降低了9.63倍和4.04倍，同时几乎没有精度损失。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键词&lt;/strong&gt;：隐私保护机器学习，同态加密，私有推理，模型优化，块剪枝&lt;/p&gt;
&lt;h2 id=&#34;i-引言&#34;&gt;&lt;strong&gt;I. 引言&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;由于机器学习（ML）解决方案的卓越性能，它们已被广泛应用于众多领域，以利用其从海量数据中提取复杂模式和洞见的能力 [47]。然而，训练高效的ML模型需要大量的数据集、可观的计算能力以及ML专业知识。为了解决这些问题，云服务提供商提供了机器学习即服务（MLaaS），通过提供精心训练的模型和计算能力，减轻了用户从零开始训练复杂模型的负担。用户只需将数据发送到云服务器，即可享受这种服务 [52]。&lt;/p&gt;
&lt;p&gt;然而，将医疗或财务记录等敏感数据外包给云服务器会引发新的数据隐私问题，并且可能不符合《通用数据保护条例》（GDPR）[1] 和《健康保险可携性与责任法案》（HIPAA）[42] 等法规的要求。隐私保护机器学习（PPML）技术通过采用差分隐私 [54]、联邦学习 [40]、安全多方计算（SMC）[55] 或同态加密（HE）[23] 等技术来解决这一隐私问题。其中，HE允许不可信的第三方直接对加密数据执行某些操作，从而保护数据的机密性。&lt;/p&gt;
&lt;p&gt;与PPML文献中的许多工作 [20]、[28]、[29]、[32]、[3] 一样，我们专注于基于HE的ML模型推理，这些模型是在明文数据上训练的，我们将其称为私有推理（PI）。许多PI解决方案依赖于HE和/或安全多方计算（SMC）协议，如混淆电路（GC）[9]、不可知传输（OT）[13] 或秘密共享（SS）[49]。需要客户端参与的方案称为交互式方案 [29]、[32]，而无需客户端协助的则称为非交互式方案，这类方案通常仅使用HE [39]、[4]、[15]、[3]、[28]。&lt;/p&gt;
&lt;p&gt;交互式方案需要客户端参与部分计算，例如HE无法评估的非多项式函数。这些方案能够在客户端的帮助下执行更广泛的功能，并达到与明文ML模型相当的精度，但它们要求客户端始终在线，并在计算过程中与云端进行多轮通信，导致高通信成本和长运行时间 [29]。此外，这些方案可能容易受到模型提取攻击 [37]。为此，我们专注于非交互式PI，其中所有计算均在加密状态下完成，无需客户端参与；然而，我们的方法同样适用于交互式解决方案。&lt;/p&gt;
&lt;p&gt;由于非交互式解决方案受限于HE支持的操作（通常为加法和乘法），它们只能评估多项式函数。因此，ML模型中涉及非多项式计算的层（如激活层或池化层）需要用可以通过HE操作评估的近似多项式函数代替。在这一模型转换之后，我们称其为HE友好模型。MOFHEI通过我们基于学习的方法自动执行这一步骤，并对给定的训练模型进行相应优化，以保持其性能。&lt;/p&gt;
&lt;p&gt;尽管在过去十年中同态加密（HE）方案在理论和实现方面都有所进步，HE操作依然比其明文操作慢数个数量级，并且需要大量的内存 [5]。随着模型深度和规模的增长，这种明文与HE计算之间的性能差距显著扩大。为了缩小这一差距，我们需要对已训练的模型进行优化。在明文领域中，为了最小化计算开销，一种实用的解决方案是减少模型的冗余参数 [26], [10]。机器学习模型可能存在过参数化，其中包含一些并不直接影响模型性能的参数 [41], [38]。多个研究 [26], [22], [31], [56] 表明，可以通过“剪枝”这些冗余参数实现更高效的计算，而不会显著降低模型精度。&lt;/p&gt;
&lt;p&gt;在机器学习领域，模型剪枝指的是基于特定指标选择一组参数，例如将值小于某个阈值的参数设置为零，然后对剪枝后的模型进行微调以恢复精度损失 [27]。然而，最近的研究 [4], [15] 表明，将传统剪枝方法应用于加密领域几乎无法有效减少HE计算的开销。其根本原因在于这些方法未考虑HE领域的操作方式。&lt;/p&gt;
&lt;p&gt;大多数HE方案（如Cheon-Kim-Kim-Song (CKKS) [17] 和 Brakerski/Fan-Vercauteren (BFV) [50]）支持单指令多数据（SIMD）[51]技术，通过将一组值打包到一个密文/明文的“槽”中来降低HE计算成本。当进行某项操作时，该操作会同时作用于所有槽中的值，而不会增加额外开销。然而，现有的剪枝方法并未考虑SIMD打包的要求，通常会在权重矩阵中任意位置剪枝模型参数。这种随机剪枝无法显著减少高延迟和高内存需求的HE操作数量。原因在于，只要非零元素仍存在于HE操作的打包操作数中，相应的HE操作就无法被跳过，因此无法减少HE操作的开销 [15], [4]。&lt;/p&gt;
&lt;p&gt;例如，对于一个包含加密输入数据的密文和一个向量化权重值的明文之间的HE乘法操作，只有当明文包中的所有元素均为零（即被剪枝）时，该操作才能在私有推理（PI）中被跳过。为了解决这一问题，我们提出了一种与数据打包方法对齐的迭代块剪枝方法。该方法显著减少了HE操作的数量，从而实现了更快、更高效的PI。需要注意的是，虽然我们使用了批量打包方法 [20]，但我们提出的剪枝方法具有通用性，也可应用于其他数据打包技术。&lt;/p&gt;
&lt;p&gt;在本文中，我们的贡献如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;我们提出了一种基于学习的方法，将给定的预训练模型转换为HE友好版本。该方法通过迭代方式：（1）学习替代激活层的近似多项式函数的系数，(2) 将最大池化层替换为HE兼容的平均池化层，并微调模型以保持其性能。&lt;/li&gt;
&lt;li&gt;我们引入了一种迭代块剪枝方法，该方法考虑加密领域中的数据打包方式，并据此对模型进行剪枝，显著减少所需的HE操作数量，从而实现更快、更经济的PI。&lt;/li&gt;
&lt;li&gt;我们通过对各种模型架构（如LeNet、自编码器）在MNIST [35]、CIFAR-10 [33]、Chest X-Ray [53] 和电网稳定性模拟（EGSS）[8] 数据集上的综合实验，评估了我们剪枝技术在PI中的效率。实验结果表明，即使在高剪枝率下，我们的方法不仅减少了PI的延迟和内存占用，还能在几乎无精度损失或仅有轻微精度损失的情况下完成。&lt;/li&gt;
&lt;li&gt;我们提供了MOFHEI，一个模型优化框架，能够自动将模型转换为HE友好版本，并对其执行迭代剪枝方法，从而在PI中具有更高的实际应用性。源代码可在 &lt;a class=&#34;link&#34; href=&#34;https://github.com/inspire-lab/MOFHEI&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/inspire-lab/MOFHEI&lt;/a&gt; 获取。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文其余部分组织如下：第二部分讨论了高效PI的最新实践。第三部分介绍了HE的相关背景信息、HE中的打包方法及我们的威胁模型。第四部分详细解释了我们提出的框架。第五部分描述了我们的实验、数据集、超参数、安全措施及实验中使用的资源。第六部分评估了实验结果，与最先进的方案进行了比较，并讨论了优缺点以及未来方向。第七部分总结全文。&lt;/p&gt;
&lt;h2 id=&#34;ii-相关研究&#34;&gt;&lt;strong&gt;II. 相关研究&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;在隐私保护机器学习（PPML）领域中，为了使私有推理（PI）更加高效和实用，研究者们采用了多种技术。Downlin等人 [20] 提出了CryptoNets，这是早期使非交互式PI实用化的研究之一。CryptoNets通过用缩放平均池化替代最大池化，并用平方函数替代激活函数，使模型具有HE友好性，同时通过合并连续的线性层来减少网络深度。他们还提出了批量打包方法（batch packing），该方法被本研究所采用（详见III-B部分）。&lt;/p&gt;
&lt;p&gt;Hesamifard等人 [28] 开发了一个类似于CryptoNets的系统CryptoDL，通过使用Chebyshev多项式 [46] 改进激活函数的低阶多项式近似，并采用BGV完全同态加密（FHE）[11]方案及常数缩放因子来解决中间值过大的问题。&lt;/p&gt;
&lt;p&gt;另一条研究路径是神经架构搜索（NAS），其目标是寻找优化的PPML架构，综合考虑加密操作，减少复杂函数（如ReLU）的使用。尽管我们的研究方法与NAS研究方向互为补充，两者均试图减少模型计算所需的加密操作数。Ghodsi等人 [24] 提出了CryptoNAS，旨在为PI任务定义一个ReLU预算，并在给定预算内识别最有效的网络。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;量化&lt;/strong&gt;是另一个用于提高PI模型计算效率的技术。与通过删除权重和连接来优化模型的剪枝不同，量化对权重施加特定值限制。Jacob等人 [30] 提出了一种量化方法，用于设备端推理，该方法使用仅基于整数的计算，比浮点推理更高效。他们还开发了一种在量化后保持模型精度的方法。在Faster CryptoNets中，Chou等人 [19] 通过采用 [25] 提出的剪枝个别权重的方法，最小化网络中的乘法数量，并对剩余权重进行量化以提高权重多项式编码的稀疏性。通过将权重值限制为2的幂，作者能够采用更高效的乘法算法 [6]。Podschwadt等人 [44] 提出了一种动态加载和缓存机制，用于卷积神经网络（CNN）中重复结构的值，从而降低内存成本。&lt;/p&gt;
&lt;p&gt;最近一些研究提出了结合HE数据打包的剪枝方法，以提升PI效率。Cai等人 [15] 提出的Hunter通过剪枝以明文向量形式打包的对角权重值，跳过点积函数中计算中间乘法结果所需的排列操作。他们采用了GAZELLE [32]（一种基于SMC的PI解决方案）的打包方法，并将激活函数的计算委托给客户端。然而，我们的工作不依赖客户端，而是使用我们提出的基于学习的方法对激活层进行近似。因此，我们可以在服务器端加密下评估激活函数。此外，Hunter在MNIST数据集上的LeNet剪枝耗时超过1小时，而我们的方法即使在90%以上的剪枝率下也仅需几分钟。&lt;/p&gt;
&lt;p&gt;Ran等人 [45] 提出了一种CNN推理框架，该框架引入了HE组卷积以及组交错编码，通过优化密文内的通道位置，并迭代地剪枝“子块”对应的权重集合，减少了耗时的HE旋转操作的数量，从而降低总体延迟。然而，他们的分组方法、相关编码方式以及卷积组内的特定稀疏模式仅适用于多通道卷积层，且未探讨其他模型层的适用性。我们的剪枝方法更加通用，并且在全连接层和卷积层中均表现良好，无需依赖特定编码方式。&lt;/p&gt;
&lt;p&gt;Aharoni等人 [4] 提出了HE-PEx，按tile-packing方法 [2] 对模型进行剪枝。首先，随机剪枝模型权重，然后通过排列操作将剩余权重重新分布到更少的包中，从而生成更多的全零包，以便剪枝，减少所需的HE操作数量。接着，通过扩展步骤，扩展剩余包中的权重值，以最大限度地利用这些权重来保持模型性能。由于剪枝过程中网络结构的变化，其方法需要在输入和输出数据上执行两次转换操作，这增加了额外的计算成本。然而，我们的方法不需要在输入和输出数据上执行这两个额外的转换操作，也不需要剪枝后的排列和扩展步骤。&lt;/p&gt;
&lt;h2 id=&#34;iii-背景&#34;&gt;III. 背景
&lt;/h2&gt;&lt;p&gt;本节介绍了同态加密（Homomorphic Encryption, HE）、HE 中的打包方法，特别是批量打包（batch packing），以及 HE 方案，并以假定的威胁模型作为总结。&lt;/p&gt;
&lt;h3 id=&#34;a-同态加密&#34;&gt;A. 同态加密
&lt;/h3&gt;&lt;p&gt;同态加密（HE）是一种特殊的加密方式，它允许在加密数据上进行特定的计算。在计算过程中，数据始终保持加密状态，计算结果也是加密的。解密后，基于加密数据计算得到的结果，与在明文数据上进行计算的结果相同。这使 HE 非常适合将计算任务外包给不可信的第三方。&lt;/p&gt;
&lt;p&gt;根据特性（如消息空间、支持的操作和可评估的函数），HE 方案可以分为不同的类别 [7]。功能最强大的 HE 方案是完全同态加密（FHE, Fully Homomorphic Encryption）方案。FHE 方案通过引导（bootstrapping）支持无限制的加法和乘法操作 [23]，但在可评估的函数类型方面仍然受到限制。例如，无法用多项式表达的函数（如比较操作）必须通过近似实现，且通常计算成本较高。&lt;/p&gt;
&lt;p&gt;此外，加密会引入噪声以隐藏数据，这些噪声在解密时会被移除。然而，在加密数据上执行操作会增加噪声水平，当噪声超过某个阈值时，正确的解密将变得不可能。由于乘法引起的噪声增长远高于加法，乘法的次数成为限制因素。在密文上连续可评估的乘法次数称为&lt;strong&gt;乘法深度&lt;/strong&gt;（multiplicative depth）。因此，乘法深度也限制了可评估的函数。&lt;/p&gt;
&lt;p&gt;虽然引导（bootstrapping）可以通过刷新噪声水平来解决此问题，但其计算成本较高。使用分层完全同态加密（leveled FHE）方案可以避免这一问题。这些方案的乘法深度可以通过加密参数进行配置。当函数的乘法深度在计算前已知时，分层 FHE 方案非常有用。&lt;/p&gt;
&lt;h3 id=&#34;b-同态加密中的数据打包&#34;&gt;B. 同态加密中的数据打包
&lt;/h3&gt;&lt;p&gt;大多数同态加密（HE）方案提供单指令多数据（SIMD, Single Instruction Multiple Data）[51] 操作，以缓解 HE 计算对资源的高需求。通过 SIMD，可以将多个值打包到一个密文或明文中。每个打包中的值的数量取决于加密参数，通常在 2¹⁰ 到 2¹⁶ 之间。我们可以将 SIMD 明文/密文视为值的向量。所有 SIMD 明文/密文之间的操作都会逐槽（slot-wise）应用于底层的值，且不会产生额外的开销。这种技术可以优化某些函数的执行。例如，Brutzkus 等人 [14] 和 Lee 等人 [36] 提出了用于高效卷积的 SIMD 打包技术。Aharoni 等人 [2] 提出了一种名为“tile tensor”的数据结构，用于以固定大小的“tile”为单位，在任意形状的张量中进行 SIMD 打包，并对其进行 HE 密文/明文编码，同时展示了基于该方法的二维卷积算法。&lt;/p&gt;
&lt;p&gt;Dowlin 等人 [20] 提出了另一种技术——批处理（batching）或批量打包（batch packing）。在批量打包中，数据被分组为多个实例的批次，并将每个实例的相同特征打包到一个密文中。这意味着密文的数量等于特征的数量。假设有一个包含 n 个实例的批次数据 $X_1, X_2, \dots, X_n$，每个实例 $X_i$; $\forall i \in [1, n]$ 包含 m 个特征 $X_i = [x_{i,1}, x_{i,2}, \dots, x_{i,m}]$。那么，批量打包会生成 m 个密文 $c_1, c_2, \dots, c_m$，其中每个 $C_i = [x_{1,i}, x_{2,i}, \dots, x_{n,i}]$; $\forall i \in [1, m]$。&lt;/p&gt;
&lt;p&gt;尽管这种技术需要更多的密文（因此占用更多内存），并增加了延迟，但它提供了更高的吞吐量。此外，它避免了代价高昂的旋转操作。需要注意的是，我们必须将明文值编码为明文格式。这种编码是必要的，因为只能在密文与密文或密文与明文之间执行操作。在我们的工作中，我们采用了这种打包方法。&lt;/p&gt;
&lt;h3 id=&#34;c-同态加密方案&#34;&gt;C. 同态加密方案
&lt;/h3&gt;&lt;p&gt;大多数现代同态加密（HE）方案基于环学习带错误（Ring Learning With Errors, RLWE）问题的难解性。尽管 BGV [12] 和 BFV [21] 仅支持整数运算，TFHE [18] 仅支持单个位和二进制门运算，但我们在此使用的 CKKS 或 HEAAN [17] 方案支持对实数的近似计算。由于计算是近似的，明文和加密数据的结果会有所不同。然而，这种近似首先出现在最低有效位，并且可以通过加密参数进行控制。可以接受的近似误差大小取决于具体应用场景。&lt;/p&gt;
&lt;h3 id=&#34;d-威胁模型&#34;&gt;D. 威胁模型
&lt;/h3&gt;&lt;p&gt;我们的威胁模型包含三个实体：模型所有者 (O)、云服务器 (S) 和客户端 (C)。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;O&lt;/strong&gt; 拥有训练好的模型，即模型的结构和所有训练参数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;S&lt;/strong&gt; 使用加密数据对训练模型执行推理计算（PI）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;C&lt;/strong&gt; 拥有私有数据，将其加密后发送到云服务器以进行推理计算。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;O 可以以加密或明文的形式将模型发送给 S；如果以加密形式发送，S 不应了解模型的任何信息，除了其架构。C 也不应了解模型的任何信息。在我们的场景中，S 知道模型的参数。我们假设 S 和 C 都是“诚实但好奇”的实体，即：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;C&lt;/strong&gt; 试图通过推理结果提取模型参数；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;S&lt;/strong&gt; 按照 C 的请求计算函数，不偏离预定行为，但也对 C 的机密数据感兴趣。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;iv-提出的框架&#34;&gt;IV. 提出的框架
&lt;/h2&gt;&lt;p&gt;我们假设“原始模型”是一个使用明文数据训练的模型，可能包含以下层：二维卷积（有无填充均可）、二维池化（最大池化、平均池化或最小池化——无填充）、批量归一化、全连接层、激活层和/或 dropout 层。
我们的框架包含两个步骤，用于创建与原始模型具有可比精度的 HE 友好版本（步骤 1 和步骤 2）。最后，在步骤 3 中，我们在该版本的模型上执行推理计算（PI）。以下是对这些步骤的详细说明：&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;a-第一步基于学习的方法将原始预训练模型转换为-he-友好模型&#34;&gt;A. 第一步：基于学习的方法将原始预训练模型转换为 HE 友好模型
&lt;/h3&gt;&lt;p&gt;在这一步中，我们将所有最大池化层逐一转换为与其对应的平均池化层，保持相同的窗口大小和步幅，从最新的池化层（即最靠近输出的）开始。修改较后层的准确性衰减比修改较前层的更容易恢复。因为修改较后层产生的误差会传递到更少的后续层，统计上，它在输出层中产生的传播误差会比修改较前层产生的传播误差低。&lt;/p&gt;
&lt;p&gt;每转换一个池化层，我们仅对后续层进行少量轮次的训练。然后，我们以相对较小的学习率对整个模型进行微调。接下来，与池化层类似，我们转换激活层。从最新的激活层开始，我们将其逐一替换为可训练的多项式（具有预定义的阶数）或不可训练的平方函数。在多项式的情况下，为了获得激活函数的近似多项式，我们首先将多项式系数作为模型的可训练参数，并进行少量轮次的训练，初始权重较小，学习率较低，以避免产生较大的损失值。随后，我们以小学习率对整个模型进行微调。而在平方函数的情况下，仅需执行微调步骤即可。&lt;/p&gt;
&lt;p&gt;需要注意的是，使用相对较小的学习率进行微调是为了避免过拟合。
第一步的输出是一个 HE 友好模型，且其精度$A_{\text{hef}}$ 与原始模型精度 $A_{\text{org}}$ 近似相等。&lt;/p&gt;
&lt;h3 id=&#34;b-第二步迭代块剪枝&#34;&gt;B. 第二步：迭代块剪枝
&lt;/h3&gt;&lt;p&gt;如我们在第一节讨论的，针对 HE 的有效剪枝需要考虑数据的打包方式。我们需要将同一个数据包中的所有值置零，从而跳过该包的计算。这里，我们提出了一种可配置的迭代块剪枝方法，该方法能够以任意块形状对模型权重进行剪枝，以匹配权重值在明文/密文中打包的方式。&lt;/p&gt;
&lt;p&gt;Zhu 等人 [56] 提出了一种过训练剪枝方法，通过使用二值掩码逐渐将低幅值的权重置零，直到达到预定义的目标稀疏度。我们扩展了该方法，定义了一个边界约束，将权重矩阵按照预定义形状（高度和宽度）的块进行划分。如有必要，我们对权重矩阵进行零填充。为了剪枝每一层，我们不是直接使用与权重矩阵大小和形状一致的二值掩码，而是构建与权重矩阵上的块大小一致的二值块掩码。二值块掩码决定了哪些权重块参与前向传播。&lt;/p&gt;
&lt;p&gt;我们定义了一个剪枝计划，从初始稀疏度 sis_i（通常为 0）逐步达到最终稀疏度 sfs_f，整个过程分为 nn 个剪枝步骤，从训练步骤 t0t_0 开始，并以剪枝频率 Δt\Delta t 进行。在每次剪枝步骤中，我们根据每个块权重绝对值的平均值对块进行排序，并将最小的块掩盖为零，直到达到该剪枝步骤所需的稀疏度水平。一旦模型达到目标稀疏度 sfs_f，块掩码将不再更新。&lt;/p&gt;
&lt;p&gt;在反向传播中，前向传播中被掩盖的块内权重会从可训练参数列表中排除，不会被更新。在每轮块掩码更新（剪枝步骤）之间的训练步骤中，模型会通过训练恢复因剪枝引起的精度损失。算法 1 展示了我们提出的迭代块剪枝方法的伪代码。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/mofhei-model-optimizing-framework-for-fast-and-efficient-homomorphically-encrypted-neural-network-inference/image-20250102164119279.png&#34;
	width=&#34;789&#34;
	height=&#34;407&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/mofhei-model-optimizing-framework-for-fast-and-efficient-homomorphically-encrypted-neural-network-inference/image-20250102164119279_hu4490656553328759874.png 480w, https://JiangZhiyu-1024.github.io/p/mofhei-model-optimizing-framework-for-fast-and-efficient-homomorphically-encrypted-neural-network-inference/image-20250102164119279_hu11819874384709406149.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20250102164119279&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;465px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们首先展示如何对全连接层进行剪枝，然后解释如何通过一种转换过程将此方法应用于卷积层。由于本研究中使用了批量打包（参见 III-B），对于输出层以外的每个全连接层，我们将块形状选择为 M×1，其中 M 是相应权重矩阵的行数；这相当于对权重矩阵的列进行剪枝。剪去权重矩阵的一整列可以跳过 MM 次同态加法和 M-1 次同态乘法。&lt;/p&gt;
&lt;p&gt;需要强调的是，我们的剪枝方法并不限于按列剪枝，还可以使用任意块形状对权重矩阵进行剪枝。用户可以将我们方法的剪枝块形状与其他打包方法使用的数据编码格式相匹配，以高效地剪枝模型。一旦模型被剪枝，每个可剪枝层都会根据预定义的稀疏度包含一组全为零的权重列。为了简化 HE 侧的计算，我们从权重矩阵中移除这些全为零的列。在全连接层中，这相当于从层中移除一些神经元。&lt;/p&gt;
&lt;p&gt;同样，剪去的列（例如移除偏置）引起的任何精度下降，可以通过对剩余参数的微调来恢复。需要注意的是，从全连接层中移除神经元会影响其输出特征图的形状。为了保持维度一致，下一层权重矩阵中对应于被剪枝层全为零列的所有行也需要被移除（参见图 1b）。这也解释了为什么剪枝后的模型稀疏度显著高于每个可剪枝层的预定义稀疏度。&lt;/p&gt;
&lt;p&gt;图 1 以示意图的形式展示了我们针对全连接层的剪枝方法（按列剪枝）的具体步骤。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/mofhei-model-optimizing-framework-for-fast-and-efficient-homomorphically-encrypted-neural-network-inference/image-20250102164419543.png&#34;
	width=&#34;1603&#34;
	height=&#34;650&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/mofhei-model-optimizing-framework-for-fast-and-efficient-homomorphically-encrypted-neural-network-inference/image-20250102164419543_hu15081137977654305192.png 480w, https://JiangZhiyu-1024.github.io/p/mofhei-model-optimizing-framework-for-fast-and-efficient-homomorphically-encrypted-neural-network-inference/image-20250102164419543_hu3670434003082504870.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20250102164419543&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;246&#34;
		data-flex-basis=&#34;591px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;为了使卷积层受益于我们的迭代块剪枝方法，我们通过一种转换技术将二维卷积层转换为等效的全连接层，该操作在本文中称为 &lt;strong&gt;Conv-Dense 操作&lt;/strong&gt;。以下是转换的具体说明：&lt;/p&gt;
&lt;p&gt;假设一个二维卷积层包含 F 个滤波器，其权重矩阵 W 的大小为 $I \times J \times K$，偏置向量 B 为 F 维；该卷积层将一个 K-通道特征图 X 映射到一个 $U \times V \times F$ 的特征图 Y。对于每一个步幅，每个大小为 $ \times J \times K$ 的滤波器与 X 中相同大小的体积块逐元素相乘，生成一个新的体积块；然后将新体积块中的所有值与滤波器的偏置一起相加，得到 Y 中对应的值。&lt;/p&gt;
&lt;p&gt;由于乘法是逐元素进行的，体积块和滤波器可以分别被展平为行向量和列向量，形状为 $1 \times M = I \times J \times K$ 和 $M \times 1$。随后，可以通过点积将它们相乘并加上偏置。这是将二维卷积转换为等效全连接表示的主要思路。&lt;/p&gt;
&lt;p&gt;根据每个方向上的步幅，可以从 X 中提取所有体积块，并广播到大小为 $N = U \times V$ 行、M 列的矩阵 $\bar{X}$，其中每一行代表 X 中对应不同步幅的体积块。同样，可以将权重矩阵 W 中的所有滤波器展平为大小为 $M \times F $的矩阵 $\bar{W}$，其中每一列对应 W 中的一个滤波器。&lt;/p&gt;
&lt;p&gt;二维特征图 Y 的矩阵表示为 $N \times F $的矩阵 $\bar{Y} = \bar{X} \otimes \bar{W} + B$（⊗ 表示点积），这与全连接层中的计算等效；随后可以轻松地将 Yˉ 转换回 Y。通过这种转换技术，我们可以对卷积层应用我们的迭代块剪枝方法。剪除等效全连接表示中 Wˉ 的列相当于剪除转换后卷积层的滤波器。因此，移除 Wˉ 中被剪枝的列实际上是从卷积层中去掉对应的滤波器。&lt;/p&gt;
&lt;p&gt;最后，我们通过再次进行微调来补偿由于滤波器移除导致的精度损失。图 2 展示了当F = 3，I = 2，J = 2，K = 4，U = 2，V = 2，M=2×2×4=16，N=2×2=4 时 Conv-Dense 操作的一个示例。&lt;/p&gt;
&lt;p&gt;第二步的最终输出是一个 HE 友好的剪枝模型，其精度 $A_{\text{prn}} \approx A_{\text{org}}$。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/image-20250102164825284.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20250102164825284&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;c-第三步私有推理private-inference-pi&#34;&gt;C. 第三步：私有推理（Private Inference, PI）
&lt;/h3&gt;&lt;p&gt;我们将第二步中生成的 HE 友好型剪枝模型的权重和层配置提取出来，用于执行私有推理（PI）。我们使用 SEAL [48] 提供的 CKKS 基元实现 PI 的算法。由于使用了批量打包（参见 III-B），我们可以将所有操作视为在单个实例上执行。例如，考虑一个具有 128 个单元和 256 个输入的全连接层。该层的权重矩阵 W 尺寸为 128×256。输入批次 X 包含 b 个实例，每个实例有 256 个特征，组成一个 b×256的矩阵。&lt;/p&gt;
&lt;p&gt;这一层的输出通过$Y = X \otimes W^T$ 计算得到（此处为简化，忽略偏置），其中 Y 尺寸为 b×128。使用批量打包时，输入批次 XX 被打包为 256 个密文。这 256 个密文可以视为一个向量。尽管计算方式未变，输入和输出现在以向量形式表示而非矩阵形式。这种方法对沿批次轴进行计算的所有神经网络层都适用。&lt;/p&gt;
&lt;p&gt;为了使这种计算正常运行，我们需要将权重矩阵中的每个值编码为单个明文。在编码时，从权重矩阵中取出一个值，将其重复 b 次后转为一个明文对象。这种方式会生成大量的明文对象。为了加速计算，我们可以通过多任务并行化点积计算。&lt;/p&gt;
&lt;p&gt;例如，如果每个任务计算 Y 中的一个值 $y_k \in Y$，则可以同时运行 128 个并行任务。这种并行化的优势在于它是无锁的，因为没有任务会同时修改相同的资源，也不会读取其他任务修改的资源。&lt;/p&gt;
&lt;h2 id=&#34;v-实验设置&#34;&gt;V. 实验设置
&lt;/h2&gt;&lt;p&gt;为了展示我们所提出方法的高效性，我们设计了七个实验，包括四个分类任务和三个自编码器实验。其中，四个分类实验中有三个是图像分类任务，分别使用 LeNet [34] 及其修改版本（详细信息见图 3）对 MNIST [35]、CIFAR-10 [33] 和胸部 X 光图像数据集 [53]（调整为 64×64 的灰度图像）进行分类。我们选择 LeNet 作为标准基准模型，用以评估我们的方法，其也被其他相关研究所采用 [15]。我们对 LeNet 进行了一些修改，以 (1) 构建一个具有更多样化和复杂层的模型，以及 (2) 增强模型对更复杂的 CIFAR-10 和 X 光图像分类任务的能力。&lt;/p&gt;
&lt;p&gt;最后一个分类实验是一个二分类任务，使用一个定制的全连接模型 (FcNet)（详细信息见图 3）对 &lt;strong&gt;Electrical Grid Stability Simulated (EGSS)&lt;/strong&gt; 数据集 [8] 进行分类。EGSS 是一个包含 10,000 个 14 变量样本的非图像数据集，任务是估算电网的稳定性（即是否稳定）。选择该实验的原因是：(1) 展示我们的方法在现实生活中非图像基础设施管理任务中的基准表现，以及 (2) 证明我们的方法能够处理自定义模型。&lt;/p&gt;
&lt;p&gt;最后三个实验是简单的自编码器 (AE) 网络架构，用于重建任务，这些网络架构参考了最近 Aharouni 等人的工作 [4]（详细信息见图 4）。这些自编码器用于 MNIST 数据集的重建任务。我们选择这些实验是为了：(1) 将我们提出的方法与最新的先进工作（即 HE-PEx [4]）进行比较，以及 (2) 展示我们的方法在不同任务（即重建任务）上的有效性。&lt;/p&gt;
&lt;p&gt;在实验中，我们使用表 I 中总结的超参数开发了原始训练模型。对于每个实验，我们对 HE 友好型模型进行了 10 次剪枝，每次剪枝使用不同的层稀疏率，从 50%、55%、60% 依次递增至 95%。然而，由于篇幅限制，我们仅在表 III 中报告了四种稀疏率下的剪枝和 PI 结果。&lt;/p&gt;
&lt;p&gt;对于 MNIST 和 CIFAR-10 数据集中的 8 位整数图像，我们通过将像素值除以 255，将其归一化到 0 到 1 之间。对于 EGSS 数据集，我们将变量线性缩放到 0 到 1 的范围内。所有实验的模型训练（或微调）的停止条件为：(1) 达到最大训练轮次，或 (2) 验证指标（如损失或准确率）在指定的容忍轮次后没有改进，以先达到的条件为准。此外，为了更平滑的收敛，如果验证指标未改进，每五轮将学习率降低 50%，最低可降至 $1 \times 10^{-7}$。&lt;/p&gt;
&lt;p&gt;在私有推理 (PI) 中，我们采用批量打包 [20] 对数据进行编码和加密，并在所有实验中使用 SEAL [48] 的 CKKS 加密方案，提供 128 位的安全性。我们使用 TensorFlow 模型优化工具包 [43] 实现了我们的迭代块剪枝方法。&lt;/p&gt;
&lt;p&gt;在 HE 友好模型的训练、微调以及剪枝步骤中，我们使用一台 Tesla V100-SXM2 GPU（32 GB 显存）。对于 PI，我们使用两台 52 核 Intel(R) Xeon(R) Gold 6230R CPU（主频 2.10GHz），总计 755 GB 内存。&lt;/p&gt;
&lt;h2 id=&#34;vi评估与讨论&#34;&gt;&lt;strong&gt;VI.评估与讨论&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;我们首先检验基于学习的方法的性能，然后讨论每个实验的结果，以评估我们的迭代块剪枝方法。为与当前最先进的研究进行比较，我们将MNIST-LeNet实验的结果与Hunter论文[15]进行对比，同时将自动编码器实验的结果与HE-PEx论文[4]进行对比。&lt;/p&gt;
&lt;p&gt;表2比较了我们的实验模型在不同数据集上训练的原始版本和HE友好版本，以展示我们提出的基于学习的方法在将训练好的模型转换为HE友好版本时的性能。结果表明，在大多数情况下，我们的方法不会显著降低模型的准确性，这显示了该方法的有效性。此外，实验结果还表明，我们的方法能够在合理的时间内完成模型的转换。&lt;/p&gt;
&lt;p&gt;表3总结了我们七个实验的HE友好模型和十个剪枝模型中四个模型（剪枝稀疏度分别为50%、60%、80%和90%）的结果。正如第一部分所述，我们方法的主要目标是通过减少HE操作的数量来加速隐私推理（PI）。实验结果表明，我们的方法以HE友好模型为基准，通过比较不同稀疏度剪枝模型的HE操作数量及其他因素（如剪枝时间、最大内存需求、PI延迟、准确性或均方误差、剪枝后模型的最终稀疏度）验证了其有效性。此外，对于每个实验模型的可剪枝层（参见图3和图4的标注），我们报告了神经元或滤波器的数量、其减少率及HE操作数量。需要注意的是，HE操作的总数并不等于可剪枝层HE操作的总和，因为每个模型中还有一些不可剪枝层（例如池化层、激活层、输出层等）也包含HE操作。&lt;/p&gt;
&lt;p&gt;此外，图5用示意图展示了七个实验中所有十个层级稀疏度（50%、55%到95%）与以下指标的关系：(1) PI延迟（log10刻度）、(2) 相对于HE友好模型的PI时间减少率、(3) HE操作总数（log10刻度）、(4) HE操作总数减少率、(5) PI内存使用量（log10刻度）、(6) PI内存减少率以及(7) 与基线（即原始模型）相比的性能（准确性或均方误差）变化率。&lt;/p&gt;
&lt;p&gt;将MNIST-LeNet实验的结果与Hunter论文[15]的结果进行比较，在几乎没有精度下降的情况下，我们的方法将HE操作总数减少了69.32%，而Hunter方法仅减少了47.35%。在最高稀疏度且仅降低2%精度的情况下，我们的方法将HE操作数量减少了93.41%，PI运行时间和所需内存分别减少了9.63倍和4.04倍。此外，Hunter方法需要1.2小时来剪枝该模型，而我们的方法在训练过程中完成剪枝，仅需几分钟。Hunter方法通过交互式PI使用较小的加密参数，从而降低了内存需求，但代价是通信成本增加；相比之下，我们的模型优化框架生成了一个优化版本的模型，使我们能够在无需客户交互的情况下高效地在加密下执行PI。&lt;/p&gt;
&lt;p&gt;在X-Ray-LeNet实验中，剪枝后的模型总体稀疏度接近98%，不仅保持了性能，甚至优于基线模型，这表明LeNet在X-Ray数据集上可能存在过度参数化。在最高稀疏度下，HE操作减少了93.42%，PI运行时间和所需内存分别减少了89.62%和74.25%。&lt;/p&gt;
&lt;p&gt;在CIFAR-10-MLeNet实验中，由于资源和选定的加密参数限制，HE友好（未剪枝）模型过于庞大，无法进行计算，仅第一个卷积层就需要超过600 GB的内存。然而，正如表3所示，当该模型剪枝至73%时，精度损失仍可忽略。这使我们能够在剪枝后的CIFAR-10-MLeNet模型上进行PI，而性能几乎没有显著下降，证明我们的剪枝方法使在复杂模型上进行PI变得更加实际。&lt;/p&gt;
&lt;p&gt;在EGSS-FcNet实验中，剪枝至最终稀疏度94%时，模型保持了相同的性能，同时HE操作减少了93.85%。相应地，所需内存和PI延迟分别减少了12倍和8倍。在最高稀疏度下，仅保留了基线模型HE操作的2.88%，这显示了剪枝方法在显著减少HE操作的同时保留模型性能的卓越效果。&lt;/p&gt;
&lt;p&gt;在所有自动编码器中，由于其简单的架构，增加稀疏度会导致性能下降。然而，根据表3和图5，AE3的性能优于其他两个模型，其性能在层级稀疏度达到50%时仍能保持不变。将自动编码器实验的结果与HE-PEx[4]进行比较可以发现，在近似相同的重建均方误差（≈0.03）下，我们的方法将AE3的PI延迟减少了65%，这一结果与HE-PEx[4]在AE3模型上的最佳结果相同。然而，我们的方法在减少内存消耗方面表现更优，将其降低了73.68%，而HE-PEx[4]的降低率为65%。&lt;/p&gt;
&lt;p&gt;此外，HE-PEx[4]的方法需要对剪枝后的模型执行一系列排列和扩展操作，以使其符合数据打包的要求。为适配这些模型结构的变化，他们还需要对模型的输入和输出执行两次转换操作，这增加了额外的复杂性。而我们的方法在训练过程中按需以块形状对模型进行剪枝，使其与数据打包要求一致，因此无需在剪枝后对模型执行额外操作，也无需对输入和输出数据进行任何转换。&lt;/p&gt;
&lt;p&gt;尽管HE-PEx[4]声称其方法可以扩展到卷积层，但他们仅在简单的全连接网络（自动编码器）上评估了该方法。相较之下，我们通过一系列广泛的实验展示了我们的方法同样能够高效地应用于卷积层。&lt;/p&gt;
&lt;h2 id=&#34;vii-结论&#34;&gt;&lt;strong&gt;VII. 结论&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;本研究提出了一种模型优化框架——MOFHEI，用于在同态加密（HE）环境下优化预训练的机器学习（ML）模型，以实现更快、更高效的非交互式隐私推理（PI）。我们的方法能够有效地将ML模型转换为适应HE的版本，并根据HE打包方法对模型进行剪枝。因此，在保持模型准确性的同时，减少了HE操作的数量，从而降低了PI的延迟和内存使用量。&lt;/p&gt;
&lt;p&gt;我们的迭代块剪枝方法适用于卷积层和全连接层，并结合批量打包（batch packing）方法使用。在实验中，我们通过对比应用剪枝方法前后不同稀疏度下HE操作数量、延迟和内存消耗的显著差异，证明了该剪枝技术的有效性。与最先进的研究相比，MOFHEI具有以下优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;采用过度训练的方法，剪枝时间更短；&lt;/li&gt;
&lt;li&gt;能够优化复杂网络并支持PI的执行；&lt;/li&gt;
&lt;li&gt;提供基于学习的方法，自动将模型转换为HE友好版本；&lt;/li&gt;
&lt;li&gt;能够与其他打包方法集成；&lt;/li&gt;
&lt;li&gt;无需客户端交互及其通信成本；&lt;/li&gt;
&lt;li&gt;无需对输入输出数据进行任何转换或后剪枝操作（例如，根据数据打包要求进行置换）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;该框架通过提供一种在模型性能、隐私和计算效率之间平衡的解决方案，为隐私保护机器学习（PPML）做出了贡献。未来工作中，我们计划扩展支持的层类型（如循环神经网络），并将剪枝方法与批量打包以外的其他打包方法集成。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
