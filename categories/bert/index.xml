<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Bert on Zion Blaze</title>
        <link>https://JiangZhiyu-1024.github.io/categories/bert/</link>
        <description>Recent content in Bert on Zion Blaze</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>Zion Blaze</copyright>
        <lastBuildDate>Fri, 06 Dec 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://JiangZhiyu-1024.github.io/categories/bert/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>InferDPT：面向黑盒大语言模型的隐私保护推理</title>
        <link>https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/</link>
        <pubDate>Fri, 06 Dec 2024 00:00:00 +0000</pubDate>
        
        <guid>https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/</guid>
        <description>&lt;img src="https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/liverworts-8616125_1280.jpg" alt="Featured image of post InferDPT：面向黑盒大语言模型的隐私保护推理" /&gt;&lt;h1 id=&#34;inferdpt面向黑盒大语言模型的隐私保护推理&#34;&gt;InferDPT：面向黑盒大语言模型的隐私保护推理
&lt;/h1&gt;&lt;h2 id=&#34;摘要&#34;&gt;&lt;strong&gt;摘要&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;以ChatGPT为代表的大型语言模型（LLMs）极大简化了文本生成任务。然而，它们也引发了关于隐私风险的担忧，如数据泄露和未经授权的信息收集。现有的隐私保护推理解决方案面临着与计算时间和通信成本相关的实际挑战。本文提出了InferDPT，这是第一个针对黑盒LLM的隐私保护推理的实用框架，旨在实现文本生成中的差分隐私。InferDPT包括两个关键模块：“扰动模块”利用差分隐私机制生成扰动的提示，从而实现与黑盒LLM的隐私保护推理；“提取模块”则受到知识蒸馏和我们观察到的现象的启发，从扰动生成结果中提取一致且连贯的文本，确保成功完成文本生成。为了解决与先前差分隐私机制易受嵌入逆转攻击的隐私问题，我们引入了RANTEXT，这是一种新型的差分隐私机制，集成在InferDPT的扰动模块中，提出了“随机邻接列表”（RANdom adjacency list）概念，用于对提示中的文本进行扰动。实验结果表明，InferDPT的文本生成质量与非隐私的GPT-4相当，而RANTEXT在隐私与效用之间的权衡上超越了现有的最先进机制，即SANTEXT+和CUSTEXT+。即使在隐私参数ε值为6.0的情况下，RANTEXT也能实现超过90%的平均隐私保护率，抵御嵌入逆转攻击，比SANTEXT+高出0.58倍，比CUSTEXT+高出3.35倍。&lt;/p&gt;
&lt;h2 id=&#34;i-introduction&#34;&gt;I. INTRODUCTION
&lt;/h2&gt;&lt;p&gt;近年来，大语言模型（LLMs）的快速发展引起了全球学术界和工业界的广泛关注 [1]。ChatGPT [2] 作为一个显著的例子，在2023年11月6日，由OpenAI首席执行官Sam Altman在公司首次开发者大会上宣布，已达到每周1亿活跃用户的里程碑 [3]。ChatGPT的广泛流行极大地方便了人们的日常工作和生活。用户通过API或网页界面与ChatGPT互动，用于生成文本，应用场景包括但不限于撰写文章、记录日常工作活动、以及为新产品撰写广告文案 [4]。然而，技术是把双刃剑。虽然LLMs提供了无与伦比的便利和实用性，但它们也带来了关于隐私泄露的重大担忧。有些情况下，LLMs的滥用导致了严重的隐私侵犯。例如，三星员工泄露了公司机密的会议记录和关于未发布产品的敏感数据 [5]。此外，最近发生的一起事件中，GPT-3.5意外泄露了个人的自拍照 [6]。这些事件重新激发了公众对上传个人数据到LLMs可能带来的隐私风险的担忧 [7]。因此，解决上传查询内容（在LLMs文本生成背景下称为“prompt”）的隐私问题变得至关重要。通常，文本生成任务中的prompt包括一个基本的写作指令和上传的私人文档1（根据微软AI Builder文档的定义 [8]）。&lt;/p&gt;
&lt;h3 id=&#34;existing-solutions&#34;&gt;Existing Solutions
&lt;/h3&gt;&lt;p&gt;以往的研究未能在实际文本生成任务中的推理过程中保护prompt中文档的隐私，尽管它们已经探讨了语言模型的隐私保护技术。如表I所示，CipherGPT [9] 在变换器架构模型中利用同态加密技术，实现在加密数据上的推理。尽管这些技术在理论上可以用于隐私保护的文本生成任务，但由于计算时间和通信成本的显著问题，它们在实际应用中存在局限性。TextObfuscator [10] 和 DP-Forward [11] 在分割学习中的数据传输过程中加入噪声。然而，这些方法主要设计用于分类任务，且不适用于模型拥有者（如OpenAI [14]）未公开LLM架构细节的黑盒场景，这通常出于模型的知识产权和商业价值考虑。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241204222232299.png&#34;
	width=&#34;790&#34;
	height=&#34;306&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241204222232299_hu8459393146709076970.png 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241204222232299_hu11660151332839433541.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241204222232299&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;258&#34;
		data-flex-basis=&#34;619px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;另一方面，SANTEXT+ [12] 和 CUSTEXT+ [13] 利用差分隐私（DP）技术 [15]，将文本中的敏感词替换为语义上相近的固定词汇集中的词，这在DP的背景下称为“词邻接列表”。这些方法同样设计用于隐私保护的分类任务，能够容忍差分隐私噪声引入的显著信息失真。对于本文探讨的隐私保护文本生成任务 [16]，即使是prompt中的轻微信息失真，也会导致生成文本的连贯性和一致性问题，因此SANTEXT+ 和 CUSTEXT+ 对此类任务并不直接有效。此外，我们在图6中的实验结果表明，SANTEXT+ 和 CUSTEXT+ 易受嵌入反演攻击 [17] 的影响：即使在隐私参数ε设置为0.01的极端情况下，攻击者仍然可以从SANTEXT+或CUSTEXT+中恢复出40%的原始私密词。这一现象的原因在于：（1）在SANTEXT+中，一定比例的词汇没有被扰动；（2）在CUSTEXT+中，每个词汇都有一个固定的小型词邻接列表，默认为20，这导致了词汇未被替换的概率较高，从而引发隐私泄漏。&lt;/p&gt;
&lt;h3 id=&#34;our-proposal&#34;&gt;Our Proposal
&lt;/h3&gt;&lt;p&gt;为了保护在黑盒LLM推理过程中文档的隐私，并解决差分隐私（DP）引发的信息偏差问题，我们提出了一个框架——InferDPT，用于文本生成任务。InferDPT的基本思路来源于知识蒸馏 [18] 和我们的观察，后者通过实验结果在第IV-B节中得到支持：DP扰动生成的prompt中的词汇，在原始prompt的多个部分中共享相同的词汇。此外，它们之间相同词汇的数量与隐私参数ε呈正相关。InferDPT由扰动模块和提取模块组成。在扰动模块中，InferDPT采用差分隐私机制（如SANTEXT+ 和 CUSTEXT+）对原始文档进行扰动，得到扰动后的prompt，并将其上传至远程LLMs。在提取模块中，InferDPT部署了一个本地模型，该模型比远程LLMs更轻量且能力较弱。该本地模型提取并重构远程LLMs生成的扰动结果。利用扰动后的生成结果作为参考，根据原始文档推断文本，InferDPT不仅保护了prompt的隐私，而且通过蒸馏远程大语言模型的能力，提升了本地模型生成的文本质量。&lt;/p&gt;
&lt;p&gt;为了解决SANTEXT+和CUSTEXT+在抵抗嵌入反演攻击中的脆弱性，我们开发了RANTEXT。RANTEXT是一个新颖的差分隐私机制，集成到InferDPT的文本扰动过程中。RANTEXT引入了“随机邻接列表”的概念，用于令牌级扰动。对于每个令牌，它使用拉普拉斯分布 [19] 动态确定随机邻接列表的大小，然后从该列表中采样一个新令牌，以替换原始的私密令牌。&lt;/p&gt;
&lt;p&gt;为了评估我们方案的效用和隐私保护能力，我们在GPT-4 [14]（当前最流行的黑盒大语言模型之一）上进行了实验，针对三个数据集进行实际的开放式文本生成任务。我们发现，现有的差分隐私攻击策略对RANTEXT的效果不足。我们提出了一种自适应攻击——GPT推理攻击，利用了GPT-4的能力。&lt;/p&gt;
&lt;h3 id=&#34;our-contributions&#34;&gt;Our Contributions
&lt;/h3&gt;&lt;p&gt;我们总结了主要贡献如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们提出了 &lt;strong&gt;InferDPT&lt;/strong&gt;，这是首个针对黑盒大语言模型隐私保护推理的实用框架，在文本生成中实现了差分隐私。&lt;/li&gt;
&lt;li&gt;我们开发了 &lt;strong&gt;RANTEXT&lt;/strong&gt;，一种新颖的局部差分隐私指数机制，集成到InferDPT的文档扰动过程中。RANTEXT解决了现有差分隐私机制易受嵌入反演攻击的问题，进一步增强了对隐私威胁的防御能力。&lt;/li&gt;
&lt;li&gt;我们在第VI-B节中针对三个数据集进行了实际开放式文本生成任务的实验。实验结果表明，当隐私参数ε设置为3.0，且使用3.89GB的本地模型时，InferDPT在三个指标上的生成质量与GPT-4相当。&lt;/li&gt;
&lt;li&gt;我们在第VII节评估了四类隐私威胁。特别是，当隐私参数ε设置为6.0，并选择嵌入反演攻击的前10个候选项时，RANTEXT的平均隐私保护率超过90%，相比CUSTEXT+提升了3.35倍，相比SANTEXT+提升了0.58倍。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ii-preliminaries&#34;&gt;II. PRELIMINARIES
&lt;/h2&gt;&lt;h3 id=&#34;a-large-language-models&#34;&gt;A. Large Language Models
&lt;/h3&gt;&lt;p&gt;大语言模型（LLMs）是先进的人工智能系统，训练于庞大的数据集。它们旨在理解、生成和解释人类语言，展示了在各种与语言相关任务中的卓越多功能性。通常，LLMs根据用户上传的$prompt P_{\text{ro}} $生成文本$ \text{Gen}$。这些模型有不同类型，包括像ChatGPT [2] 和Claude [20] 这样的闭源商业服务，以及像Llama [21] 和Vicuna [22] 这样的开源模型。本文重点关注闭源LLMs，并旨在解决它们在开放式文本生成任务中的黑盒推理过程中的隐私问题。&lt;/p&gt;
&lt;p&gt;具体而言，在开放式文本生成任务 [23] 中，这些黑盒LLMs的作用是根据$prompt P_{\text{ro}} $继续生成文本 $\text{Gen}$，以提高文本生成质量，并根据多维度指标进行评估。详细来说，给定一个$prompt P_{\text{ro}} = \text{Insw} \parallel \text{Doc}$，其中Insw是基础写作指令，$Doc =\langle x_i \rangle_{i=1}^L$ 是由L个令牌或词 $x_i$ 组成的原始文档，分别属于令牌词汇表 $V_t$ 和词汇表 V，LLMs承诺提供推理函数 $\text{Infer}: P_{\text{ro}} \to \text{Gen} $来生成文本。&lt;/p&gt;
&lt;h3 id=&#34;b-local-differential-privacy--exponential-mechanism&#34;&gt;B. (Local) Differential Privacy &amp;amp; Exponential Mechanism
&lt;/h3&gt;&lt;p&gt;差分隐私 [15] 是一种隐私保护概念。作为其最流行的模型之一，ε-局部差分隐私（ε-LDP）允许数据拥有者在将数据上传到任何不受信任的聚合器之前，使用随机机制 $M(\cdot)$ 对其数据进行本地扰动。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定义1 (ε-局部差分隐私 [24])&lt;/strong&gt;：在ε-LDP中，给定隐私参数 $\epsilon \geq 0$，如果一个随机机制  M 满足以下条件，对于任何两个输入 $x, x&amp;rsquo; \in X$ 和任何可能的输出 $y \in Y$，则称 M 是ε-LDP合规的：&lt;/p&gt;
$$\frac{ \text{Pr}[M(x) = y] }{ \text{Pr}[M(x&#39;) = y] } \leq e^\epsilon$$&lt;p&gt;通常，较小的 $\epsilon$ 值提供更高的隐私保护，但以减少数据效用为代价。此外，这里的一个关键定义是输入集 X。在以往的自然语言处理研究 [12], [13] 中，大多数研究者假设词汇表中的任意一对词汇共享相同的输入集 X 和输出集 Y。我们观察到，这种定义导致了效用和隐私之间的权衡问题。本文在第V-B节中使用随机邻接列表重新定义了ε-LDP的输入集。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定义2 (指数机制 [25])&lt;/strong&gt;：对于给定的评分函数$u : X \times Y \to \mathbb{R}$，如果随机机制 $M(\cdot)$ 满足以下条件，对于任何输入 $x \in X $和任何可能的输出 $y \in Y$，则 M 是ε-LDP合规的：&lt;/p&gt;
&lt;p&gt;$\text{Pr}[y | x] \propto \exp \left( \frac{\epsilon \cdot u(x, y)}{2 \Delta_u} \right)$&lt;/p&gt;
&lt;p&gt;其中，敏感度 $\Delta_u$ 定义为：&lt;/p&gt;
&lt;p&gt;$\Delta_u = \max_{x, x&amp;rsquo; \in X, y \in Y} |u(x, y) - u(x&amp;rsquo;, y)|$&lt;/p&gt;
&lt;p&gt;评分函数 u 在不同场景下可能有所不同。通常，我们可以调整 u 的上界来将 $\Delta_u$ 设置为特定的实数，其中 $\Delta_u$ 表示评分函数 u 的敏感度。类似地，$\epsilon$ 值越小，隐私保护能力的安全性越高，但数据的效用越低。当选择较小的 $\epsilon$ 时，评分函数 $u(x, y)$ 对任何扰动结果的输出概率不再起决定性作用。&lt;/p&gt;
&lt;h2 id=&#34;iii-problem-statement&#34;&gt;III. PROBLEM STATEMENT
&lt;/h2&gt;&lt;h3 id=&#34;a-threat-model&#34;&gt;A. Threat Model
&lt;/h3&gt;&lt;p&gt;我们考虑的场景是LLM平台（如ChatGPT）是一个诚实但好奇的对手，称为Adv。用户（记作Usr）打算上传一个prompt，并调用Adv的推理服务 $\text{Infer}: P_{\text{ro}} \to \text{Gen}$，以完成由开源模型执行不佳的文本生成任务。在这里，Gen表示由Adv生成的文本。上传的$P_{\text{ro}} = \text{Insw} \parallel \text{Doc}$ 代表Usr的原始prompt，包含Insw（基础写作指令）和$\langle x_i \rangle_{i=1}^L$（由L个令牌或单词 $x_i$ 组成的原始文档，分别属于令牌词汇表 $V_t$ 和词汇表 V）。根据以往的研究 [10], [17]，隐私信息与每个令牌或单词相关。为了保护原始文档Doc中的每个令牌或单词，Usr对Doc应用差分隐私 [15]，生成一个扰动后的文档Docp。因此，Usr上传扰动后的$P_{\text{ro}}^p = \text{Insw} \parallel \text{Doc}^p$。此外，Usr可以部署一个能力较弱的语言模型，而不是LLMs。为了保护模型的商业价值，Adv不会透露LLM的内部架构或参数，而只会暴露其令牌词汇表，以便在推理过程中进行计费验证。&lt;/p&gt;
&lt;p&gt;给定一个$P_{\text{ro}} = \text{Insw} \parallel \text{Doc}$，Adv的目标是获得Doc中每个令牌或单词。以一个草拟文章的prompt为例，Adv承诺执行文本生成任务，但可能意图窃取其实验结果以进行未经授权的收集。此外，我们假设Adv完全了解差分隐私算法的细节，除了原始文档Doc之外。Adv预计会利用DP中的漏洞发起攻击，旨在基于扰动版本Docp恢复Doc中的每个单词或令牌。表II总结了本文中经常使用的符号。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241205151844980.png&#34;
	width=&#34;757&#34;
	height=&#34;590&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241205151844980_hu16071382376308516125.png 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241205151844980_hu15211694219699638673.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241205151844980&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;128&#34;
		data-flex-basis=&#34;307px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;b-existing-solutions-and-limitations&#34;&gt;B. Existing Solutions and Limitations
&lt;/h3&gt;&lt;p&gt;现有的解决方案，如SANTEXT+ [12] 和 CUSTEXT+ [13]，主要集中在分类任务中的隐私保护模型训练：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SANTEXT+&lt;/strong&gt; 在分类任务的训练过程中实现了差分隐私（DP）。在SANTEXT+中，部分单词不受DP的干扰。它仅将敏感单词替换为来自单词邻接列表（整个词汇表）中的其他单词，基于度量本地差分隐私 [26]。最终，这会导致在嵌入反演攻击 [17] 下发生隐私泄露。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CUSTEXT+&lt;/strong&gt; 在分类任务的训练过程中对所有单词进行扰动。它采用指数机制 [25]，将每个单词原封不动地替换为来自单词邻接列表中在嵌入距离上接近的单词。与SANTEXT+相比，CUSTEXT+将单词邻接列表的大小减少为一个默认的小数字。然而，单词邻接列表的大小较小使得它容易受到嵌入反演攻击。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了保护在文本生成任务推理过程中的文档隐私并解决由DP噪声引入的信息失真问题，我们提出了一个框架InferDPT（见第四节）。我们还提出了一种指数机制RANTEXT（见第五节），作为解决SANTEXT+和CUSTEXT在抵御嵌入反演攻击时存在漏洞的方案。&lt;/p&gt;
&lt;h2 id=&#34;iv-the-inferdpt-framework&#34;&gt;IV. THE INFERDPT FRAMEWORK
&lt;/h2&gt;&lt;h3 id=&#34;a-overview&#34;&gt;A. Overview
&lt;/h3&gt;&lt;p&gt;我们提出了InferDPT框架，旨在保护文本生成任务中LLM推理过程中的隐私。如图1所示，InferDPT由两个模块组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;扰动模块&lt;/strong&gt;：保护隐私。通过差分隐私生成扰动提示，并将文档（Doc）中的每个单词或标记替换为在嵌入距离上接近的单词或标记。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提取模块&lt;/strong&gt;：保持实用性。通过一个本地语言模型，从扰动生成的文本中提取连贯一致的文本，并将其重构为与原始提示对齐的输出。本地语言模型的能力低于黑盒LLM。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;InferDPT的设计面临两个主要挑战：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;为原始文档Doc提供强大的隐私保护&lt;/strong&gt;。为了解决这个隐私挑战，InferDPT的扰动模块利用差分隐私机制，顺序地将原始文档Doc中的每个单词或标记替换为嵌入距离上接近的替代词。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在语义扰动下保持文本的实用性&lt;/strong&gt;。这一挑战比第一个更为艰难。为了解决这个挑战，我们在LLMs上进行了大量实验。我们发现一个现象：如果将原始提示生成文本中出现的所有单词构成一个集合，那么在扰动提示生成的文本中，很多单词也属于这个集合。随着扰动的减少，这个数字逐渐增加。这个现象表明，扰动输出包括了由GPT-4直接生成的文本中的单词。为了正式描述这个现象，我们提出了关于差分隐私扰动输出的以下观察结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;b-key-observations&#34;&gt;B. Key Observations
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Observation&lt;/strong&gt;. 考虑一个局部差分隐私的随机函数 $M(\cdot)$，满足以下条件：对于词汇表  V（或标记词汇表  $V_t$）中的任意单词（或标记） x，以及属于  x 的单词邻接列表（或随机邻接列表）中的  y 和  z，如果 $d(x, y) \geq d(x, z)$，则有：&lt;/p&gt;
&lt;p&gt;$P_r[M(x) = y] \leq P_r[M(x) = z]$&lt;/p&gt;
&lt;p&gt;其中，$d(\cdot)$ 测量两个输入之间的语义相似度，输出值越小表示相似度越大。&lt;/p&gt;
&lt;p&gt;原始文档  Doc 被 $M(\cdot)$ 扰动，得到扰动文档 $Doc_p$。如果  Doc 和 $Doc_p$ 共享相同的推理服务 $Infer(\cdot)$ 和写作指令  Insw，则它们形成提示 $P_ro = Insw | Doc$ 和扰动提示 $P_ro_p = Insw | Doc_p$。扰动生成结果 $Gen_p = \langle g_i \rangle_{i=1}^K = Infer(P_ro_p)$ 满足以下条件：&lt;/p&gt;
&lt;p&gt;$Infer_j(P_ro) = \langle h(j)&lt;em&gt;i \rangle&lt;/em&gt;{i=1}^K$&lt;/p&gt;
&lt;p&gt;期望集合（Expected set）为：&lt;/p&gt;
&lt;p&gt;$Expected set = N \left[ j=1 \left{ h(j)_i | h(j)_i \in Infer_j(P_ro) \right} \right]$&lt;/p&gt;
&lt;p&gt;交集集合（Intersection set）为：&lt;/p&gt;
&lt;p&gt;$Intersection set = { g_i | g_i \in Expected set \text{ and } g_i \notin stopwords }$&lt;/p&gt;
&lt;p&gt;其中，$g_i $和 $h(j)&lt;em&gt;i$ 属于词汇表 V，$\langle g_i \rangle&lt;/em&gt;{i=1}^K$ 代表由 K 个 $g_i$ 组成的文本，$\langle h(j)&lt;em&gt;i \rangle&lt;/em&gt;{i=1}^K$ 代表由K 个 $h(j)_i$ 组成的文本，N 是大于 1 的整数，stopwords [27] 是在文本分析中通常因信息量低而被忽略的常见词，Count(·) 计算集合的大小，Corr(·) 是测量两个变量之间关系的相关系数，其值范围为 -1（完全负相关）到 1（完全正相关）。&lt;/p&gt;
&lt;p&gt;该观察指出，如果期望集合是从原始文本生成结果的 N 次迭代中构建的，那么期望集合中出现在扰动生成结果中的单词数量将与 ε 呈正相关。为了验证这一点，我们进行了以下实验。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;经验验证&lt;/strong&gt;。我们通过收集来自 GPT-4 [14] 在 CNN/Daily Mail 数据集 [29] 上生成 100 次的原始提示输出中的 100 个单词来得到期望集合。原始提示包括一个基本写作指令和一个由 50 个标记组成的原始文档，如图 1 所示。我们利用 SANTEXT+ [12]、CUSTEXT+ [13] 和第 V 节中介绍的 RANTEXT 生成了在不同 ε 值下，GPT-4 生成的 100 个单词的扰动输出。我们计算了来自 GPT-4 扰动和非隐私生成结果中属于期望集合的单词数量。图 2 显示了实验结果。可以看出，随着 ε 的增大和扰动的减少，三种机制中期望集合中的单词数量显著增加。这验证了观察结果，确认了期望集合中出现在扰动生成结果中的单词数量与 ε 呈正相关。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241205165259413.png&#34;
	width=&#34;820&#34;
	height=&#34;451&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241205165259413_hu10156324952594317771.png 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241205165259413_hu13044006134224350919.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241205165259413&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;181&#34;
		data-flex-basis=&#34;436px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;基于这一观察，InferDPT 只需要一个提取模块来提取和重构来自远程黑盒 LLM 的扰动输出，提取其能力以完成文本生成任务。在接下来的子节中，我们将深入探讨 InferDPT 的这两个模块。&lt;/p&gt;
&lt;h3 id=&#34;c-扰动模块&#34;&gt;&lt;strong&gt;C. 扰动模块&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;InferDPT 的扰动模块采用差分隐私机制，通过从一个集合中选择与嵌入距离接近的单词或标记来替换每个单词或标记。这个集合被称为词邻接列表 Cw（使用 SANTEXT+ [12] 和 CUSTEXT+ [13]）或随机邻接列表 Cr（使用 RANTEXT）。如表 III 和表 IV 所示，大多数被扰动的单词或标记并不是它们原始形式的同义词，而是与原始单词在嵌入距离上接近。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241205172055236.png&#34;
	width=&#34;794&#34;
	height=&#34;553&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241205172055236_hu341239649803994987.png 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241205172055236_hu13511803732051773430.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241205172055236&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;344px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;考虑一个随机机制 M(·)，其中 ε ≥ 0。给定一个私密文档 Doc = ⟨xi⟩L i=1，由 L 个标记或单词组成，其中每个 xi ∈ V 或 xi ∈ Vt。扰动模块通过将每个 xi 替换为随机输出 yi = M(xi, Cw(xi)) 或 yi = M(xi, Cr(xi)) 来获取扰动文档 Docp = ⟨yi⟩L i=1。扰动文档的示例见图 1。扰动模块的详细过程在算法 1 中概述。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241205172528036.png&#34;
	width=&#34;1617&#34;
	height=&#34;680&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241205172528036_hu8891469316524497567.png 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241205172528036_hu8698016683007117628.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241205172528036&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;237&#34;
		data-flex-basis=&#34;570px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/67f9c7ca0238a5a12d68ba6fdd7e36c.jpg&#34;
	width=&#34;2560&#34;
	height=&#34;1068&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/67f9c7ca0238a5a12d68ba6fdd7e36c_hu7109286674396743404.jpg 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/67f9c7ca0238a5a12d68ba6fdd7e36c_hu5782788693162705550.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;67f9c7ca0238a5a12d68ba6fdd7e36c&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;239&#34;
		data-flex-basis=&#34;575px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;在 InferDPT 的扰动模块中，采用了三种不同的差分隐私机制：SANTEXT+、CUSTEXT+ 和 RANTEXT。经过扰动后，Usr 上传一个扰动的提示 P rop = Insw ∥ Docp，其中包含写作指令 Insw 和扰动文档 Docp，如图 1 所示。然后，黑盒 LLM 会返回扰动生成结果 Genp = Infer(P rop) 给用户。&lt;/p&gt;
&lt;h3 id=&#34;d-提取模块&#34;&gt;&lt;strong&gt;D. 提取模块&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;如图 1 所示，由扰动提示生成的文本与原始文档 Doc 部分不一致，并且在语义上不连贯。值得注意的是，尽管扰动生成 Genp 和原始生成 Gen 共享相同的文本，但没有原始文档信息，难以将 Genp 与原始文档 Doc 对齐，因为关键信息已经被扰动。为了获得对齐的生成结果，InferDPT 的提取模块使用一个被认为是可信的本地语言模型，且不会引发隐私泄露问题。该本地模型比远程黑盒 LLM 小且能力较弱，便于部署。用户随后将原始文档 Doc 和扰动生成结果 Genp 输入，生成与原始提示对齐的最终输出。&lt;/p&gt;
&lt;p&gt;值得注意的是，本地语言模型本身可以生成对齐的生成结果，但由于其能力有限，生成质量不尽如人意。通过使用扰动生成结果 Genp，我们可以将远程黑盒 LLM 的能力提取到我们的本地小型语言模型中。提取模块的提示可以在附录 A 中找到。&lt;/p&gt;
&lt;p&gt;基于上述描述，我们可以对 InferDPT 有一个全局的理解。需要注意的是，扰动模块可以采用现有的差分隐私机制，如 SANTEXT+ [12] 和 CUSTEXT+ [13]。然而，正如在 III-B 节中分析的，这两种机制容易受到嵌入反演攻击 [17]。为了解决这个问题，我们将在下一节引入 RANTEXT。&lt;/p&gt;
&lt;h2 id=&#34;v-rantext-机制&#34;&gt;&lt;strong&gt;V. RANTEXT 机制&lt;/strong&gt;
&lt;/h2&gt;&lt;h3 id=&#34;a-概述&#34;&gt;&lt;strong&gt;A. 概述&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;我们设计了 RANTEXT 机制，以解决差分隐私机制在嵌入反演攻击下的漏洞。如图 3 所示，RANTEXT 包含两个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;计算随机邻接列表&lt;/strong&gt;：此步骤通过两项操作为每个原始 token 计算一个随机邻接列表：计算随机嵌入和欧几里得距离。随机邻接列表中的所有 token 共享相同的输入集。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;通过 ε-LDP 采样扰动 token&lt;/strong&gt;：此步骤为每个原始 token 采样一个扰动 token，并通过 ε-LDP 从其随机邻接列表中替换文档中的原始 token，从而获得扰动文档。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;正如在 III-A 节中提到的，LLM 会暴露其 token 词汇表 Vt 用于推理服务的计费验证。利用 token 词汇表 Vt 和字节对编码 (BPE) 算法 [30]，用户可以获得 LLM 的 tokenizer(·) 算法。给定原始文档 Doc，RANTEXT 首先使用 LLM 的 tokenizer(·) 算法将 Doc 转换为 tokens ⟨ti⟩L  i=1，其中 ti ∈ Vt：&lt;/p&gt;
&lt;p&gt;$\text{Tokenset} = \langle t_i \rangle_{i=1}^{L} = \text{tokenizer}(Doc).$&lt;/p&gt;
&lt;p&gt;为了保护 Doc 的隐私，RANTEXT 丢弃 Doc 中不属于 Vt 的 tokens，并使用指数机制来替换每个剩余的 token，将其替换为与其独有的随机邻接列表中的某个 token 在嵌入距离上接近的 token：&lt;/p&gt;
&lt;p&gt;$\text{Tokensetp} = \langle r_i \rangle_{i=1}^{l} = \langle M(t_i) \rangle_{i=1}^{l},$&lt;/p&gt;
&lt;p&gt;其中，$r_i \in Vt$，Tokensetp 表示扰动后的 token 集合，$C_t(t_i)$ 表示 $t_i$ 的随机邻接列表。RANTEXT 将扰动 token 集合 Tokensetp 中的 tokens 连接起来，得到一个扰动文档 Docp，从而实现隐私保护。&lt;/p&gt;
&lt;h3 id=&#34;b-计算随机邻接列表&#34;&gt;&lt;strong&gt;B. 计算随机邻接列表&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;为了正式定义随机邻接列表，我们首先给出随机邻接嵌入的定义：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定义 3 (随机邻接嵌入)&lt;/strong&gt;。给定 token $t \in V_t$，其随机邻接嵌入定义如下：&lt;/p&gt;
&lt;p&gt;$C_e(t) = {e_b \mid d_e(e_b, \varphi(t)) &amp;lt; d_e(\hat{\varphi}(t), \varphi(t)), e_b \in \mathbb{R}^N },$&lt;/p&gt;
&lt;p&gt;其中，$e_b \in \mathbb{R}^N$ 表示任何 $N$ 维的实数向量。函数 $d_e(\cdot)$ 用于计算两个向量之间的距离，定义为：&lt;/p&gt;
&lt;p&gt;$d_e(a, b) = \sqrt{\sum_{i=1}^{n}(a_i - b_i)^2}.$&lt;/p&gt;
&lt;p&gt;函数 $\varphi: V_t \to \mathbb{R}^N$ 将任何给定的 token 映射到 $N$ 维实数向量空间中的一个向量。函数 $\hat{\varphi}(t) = \varphi(t) + Y$，其中随机向量 $Y$ 满足概率密度：&lt;/p&gt;
&lt;p&gt;$Y \sim f(x) = Z \cdot 2^{\Delta\varphi} \cdot \exp\left(- \frac{|x|}{\Delta\varphi} \right)$,Z={ϵ如果 ϵ&amp;lt;2,alog⁡(b⋅ϵ+c)+d否则,$Z =  \begin{cases}  \epsilon &amp;amp; \text{if} \ \epsilon &amp;lt; 2, \ a \log(b \cdot \epsilon + c) + d &amp;amp; \text{else},  \end{cases}$&lt;/p&gt;
&lt;p&gt;其中，$\Delta\varphi$ 是函数 $\varphi(\cdot)$ 的敏感性，$a \approx 0.0165, b \approx 19.0648, c \approx -38.1294, d \approx 9.3111$。&lt;/p&gt;
&lt;p&gt;给定一个 token $t \in V_t$，要计算其随机邻接嵌入，我们需要完成两步计算：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;步骤 1：计算随机嵌入&lt;/strong&gt;。我们使用拉普拉斯分布 [19] 构造随机向量 $Y$。我们独立地将 $Y$ 添加到 $\varphi(t)$ 的每个维度中，从而获得原始私有 token $t$ 的随机嵌入 $\hat{\varphi}(t) = \varphi(t) + Y$。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;步骤 2：计算欧几里得距离&lt;/strong&gt;。我们计算 $\varphi(t)$ 和 $\hat{\varphi}(t)$ 之间的欧几里得距离，记作 $d_e(\hat{\varphi}(t), \varphi(t))$。随机邻接嵌入由那些与 $\varphi(t)$ 的欧几里得距离小于 $d_e(\hat{\varphi}(t), \varphi(t))$ 的嵌入组成。&lt;/p&gt;
&lt;p&gt;我们使用 $Y$ 动态地确定随机邻接列表的大小。随机向量 $Y$ 的详细构造过程可以在附录 B 中找到。通过对随机邻接嵌入的定义，我们进一步给出随机邻接列表的定义：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定义 4 (随机邻接列表)&lt;/strong&gt;。给定 token $t \in V_t$，其随机邻接列表定义如下：&lt;/p&gt;
&lt;p&gt;$C_r(t) = { t&amp;rsquo; \mid \varphi(t&amp;rsquo;) \in C_e(t), t&amp;rsquo; \in V_t }.$&lt;/p&gt;
&lt;p&gt;给定一个 token $t \in V_t$，其随机邻接列表由 token 词汇表 $V_t$ 中的任意 token $t&amp;rsquo;$ 组成，其中 $t&amp;rsquo;$ 的嵌入 $\varphi(t&amp;rsquo;)$ 与 $t$ 的嵌入 $\varphi(t)$ 之间的欧几里得距离小于 $t$ 的随机嵌入与 $t$ 的嵌入 $\varphi(t)$ 之间的欧几里得距离。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理 1&lt;/strong&gt;。给定一个 token $t \in V_t$ 和任意 token $t&amp;rsquo; \in V_t$，存在一个 RANTEXT 的随机邻接列表 $C_r(t)$，使得 $t&amp;rsquo; \in C_r(t)$。&lt;/p&gt;
&lt;p&gt;定理 1 表明，RANTEXT 解决了 CUSTEXT+ [13] 中固定且小的邻接列表带来的隐私错误。它确保一个 token $t$ 可以被 $V_t$ 中的任何 token 替换。RANTEXT 中不确定的随机邻接列表的潜在大小等同于整个 token 词汇表 $V_t$ 的大小。定理 1 的证明见附录 B。&lt;/p&gt;
&lt;h3 id=&#34;c-通过-ε-ldp-采样扰动的-token&#34;&gt;&lt;strong&gt;C. 通过 ε-LDP 采样扰动的 Token&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;在 SANTEXT+ [12] 中，一部分词汇没有受到差分隐私（DP）的扰动。为了避免原始文本中的隐私泄露问题，RANTEXT 对 Tokenset = ⟨$t_i$⟩$L$$_{i=1}$ 中的每个 token 进行扰动。为了扰动 token $t_i$，RANTEXT 使用满足 ε-LDP 的指数机制 [25]，从 $C_r(t_i)$ 中选择一个新的 token 来替代原始的 token。对于任何不属于 $V_t$ 的特殊 token $t_s$，RANTEXT 会将其丢弃，以确保 Docp 中没有特殊 token 泄露。&lt;/p&gt;
&lt;p&gt;为了保证扰动文档的有效性，RANTEXT 中指数机制的随机机制 $M(·)$ 需要满足以下条件：&lt;/p&gt;
&lt;p&gt;$d(x, y) \geq d(x, z) \Rightarrow \Pr[M(x) = y] \leq \Pr[M(x) = z],$&lt;/p&gt;
&lt;p&gt;其中 $x \in V_t$，$y$ 和 $z$ 属于 $x$ 的随机邻接列表。$d(·)$ 衡量两个输入之间的语义相似度，输出越小，表示相似度越高。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;算法 2 RANTEXT 机制&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;输入&lt;/strong&gt;: Token 集合 $Tokenset = \langle t_i \rangle^L_{i=1}$，token 词汇表 $V_t$，隐私参数 $\epsilon$，嵌入函数 $\varphi(\cdot)$，距离函数 $d_e(\cdot)$，随机向量 $Y$；
&lt;strong&gt;输出&lt;/strong&gt;: 扰动后的文档 $Doc_p$；&lt;/p&gt;
&lt;p&gt;初始化 $Tokenset_p \leftarrow \emptyset$；&lt;/p&gt;
&lt;p&gt;对于 $i = 1$ 到 $L$，执行：&lt;/p&gt;
&lt;p&gt;​	如果 $t_i \notin V_t$，则：&lt;/p&gt;
&lt;p&gt;​		丢弃 token $t_i$；&lt;/p&gt;
&lt;p&gt;​		跳过当前循环；&lt;/p&gt;
&lt;p&gt;​	结束如果；&lt;/p&gt;
&lt;p&gt;​	采样一个随机向量 $Y$；&lt;/p&gt;
&lt;p&gt;​	计算嵌入 $eb_t \leftarrow \varphi(t_i)$；&lt;/p&gt;
&lt;p&gt;​	计算随机嵌入 $eb_n \leftarrow eb_t + Y$；&lt;/p&gt;
&lt;p&gt;​	计算欧几里得距离 $d_{\text{threshold}} \leftarrow d_e(eb_n, eb_t)$；&lt;/p&gt;
&lt;p&gt;​	计算随机邻接集 $C_e(t_i) = {eb | d_e(eb, eb_t) &amp;lt; d_{\text{threshold}}, eb \in \mathbb{R}^N }$；&lt;/p&gt;
&lt;p&gt;​	计算随机邻接列表 $C_r(t_i) = {t_i&amp;rsquo; | \varphi(t_i&amp;rsquo;) \in C_e(t_i), t_i&amp;rsquo; \in V_t }$；&lt;/p&gt;
&lt;p&gt;​	对于每个 $t_i&amp;rsquo; \in C_r(t_i)$，执行：&lt;/p&gt;
&lt;p&gt;​		计算 $d_{t_i&amp;rsquo;} \leftarrow d_e(\varphi(t_i), \varphi(t_i&amp;rsquo;))$；&lt;/p&gt;
&lt;p&gt;​		计算评分函数 $u(t_i, t_i&amp;rsquo;) \leftarrow 1 - \frac{d_{t_i&amp;rsquo;}}{d_{\text{threshold}}}$；&lt;/p&gt;
&lt;p&gt;​		更新总分 $p_{\text{total}} \leftarrow p_{\text{total}} + \exp \left( \frac{\epsilon}{2} \cdot u(t_i, t_i&amp;rsquo;) \right)$；&lt;/p&gt;
&lt;p&gt;​	结束对于；&lt;/p&gt;
&lt;p&gt;​	对于每个 $t_i&amp;rsquo;&amp;rsquo; \in C_r(t_i)$，执行：&lt;/p&gt;
&lt;p&gt;​		计算条件概率 $p(t_i&amp;rsquo;&amp;rsquo;|t_i) \leftarrow \frac{\exp \left( \frac{\epsilon}{2} \cdot u(t_i, t_i&amp;rsquo;&amp;rsquo;) \right)}{p_{\text{total}}}$；&lt;/p&gt;
&lt;p&gt;​	结束对于；&lt;/p&gt;
&lt;p&gt;​	从随机邻接列表中采样 $r_i \sim p(t_i&amp;rsquo;&amp;rsquo;|t_i)$；&lt;/p&gt;
&lt;p&gt;​	将新 token $r_i$ 添加到扰动 token 集合 $Tokenset_p$ 中；&lt;/p&gt;
&lt;p&gt;结束对于；&lt;/p&gt;
&lt;p&gt;将 $Tokenset_p = \langle r_i \rangle^L_{i=1}$ 连接起来，得到 $Doc_p$；&lt;/p&gt;
&lt;p&gt;输出扰动后的文档 $Doc_p$；&lt;/p&gt;
&lt;p&gt;为了实现这一点，RANTEXT 中随机机制 $M(\cdot)$ 的评分函数 $u(\cdot)$ 如下所述：&lt;/p&gt;
&lt;p&gt;给定一个 token $t$，RANTEXT 认为在扰动 token $t$ 时，$C_r(t)$ 中的任何两个 token 都共享相同的输入集和输出集。对于任意两个 token $x, y \in C_r(t)$，评分函数为：&lt;/p&gt;
&lt;p&gt;$u(x, y) = 1 - \frac{|d_e(\varphi(x), \varphi(t)) - d_e(\varphi(y), \varphi(t))|}{d_e(\varphi(t), \hat{\varphi}(t))} \tag{16}$&lt;/p&gt;
&lt;p&gt;根据方程 (11) 和方程 (14)，可以得出：&lt;/p&gt;
&lt;p&gt;$|d_e(\varphi(x), \varphi(t)) - d_e(\varphi(y), \varphi(t))| &amp;lt; d_e(\varphi(t), \hat{\varphi}(t)) \tag{17}$&lt;/p&gt;
&lt;p&gt;$0 \leq \frac{|d_e(\varphi(x), \varphi(t)) - d_e(\varphi(y), \varphi(t))|}{d_e(\varphi(t), \hat{\varphi}(t))} &amp;lt; 1 \tag{18}$&lt;/p&gt;
&lt;p&gt;结合方程 (16) 和方程 (17)，可以推导出：&lt;/p&gt;
&lt;p&gt;$0 &amp;lt; u(x, y) \leq 1 \tag{19}$&lt;/p&gt;
&lt;p&gt;$\Delta u = 1 \tag{20}$&lt;/p&gt;
$$
P_r[y|x] = \frac{\exp \left( \frac{\epsilon}{2} \cdot u(x, y) \right)}{\sum_{y&#39; \in C_r(t)} \exp \left( \frac{\epsilon}{2} \cdot u(x, y&#39;) \right)} \tag{21}
$$$$
= \frac{\exp \left( \frac{\epsilon}{2} \cdot \left( 1 - \frac{|d_e(\varphi(x), \varphi(t)) - d_e(\varphi(y), \varphi(t))|}{d_e(\varphi(t), \hat{\varphi}(t))} \right) \right)}{\sum_{y&#39; \in C_r(t)} \exp \left( \frac{\epsilon}{2} \cdot \left( 1 - \frac{|d_e(\varphi(x), \varphi(t)) - d_e(\varphi(y&#39;), \varphi(t))|}{d_e(\varphi(t), \hat{\varphi}(t))} \right) \right)} \tag{22}
$$$$
u(t, y) = 1 - \frac{d_e(\varphi(y), \varphi(t))}{d_e(\varphi(t), \hat{\varphi}(t))} \tag{23}
$$$$
P_r[y|t] = \frac{\exp \left( \frac{\epsilon}{2} \cdot \left( 1 - \frac{d_e(\varphi(t), \varphi(y))}{d_e(\varphi(t), \hat{\varphi}(t))} \right) \right)}{\sum_{y&#39; \in C_r(t)} \exp \left( \frac{\epsilon}{2} \cdot \left( 1 - \frac{d_e(\varphi(t), \varphi(y&#39;))}{d_e(\varphi(t), \hat{\varphi}(t))} \right) \right)} \tag{24}
$$&lt;p&gt;RANTEXT 的详细过程如算法 2 所示。此外，RANTEXT 满足 ε-LDP 的定义，符合第 IV-B 节的观察条件：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理 2&lt;/strong&gt;：给定隐私参数 $\epsilon \geq 0$ 和 token $t$ 的随机邻接列表 $C_r(t)$，对于任意输入 $x, x&amp;rsquo; \in C_r(t)$ 和输出 $y \in C_r(t)$，RANTEXT 的随机机制 $M$ 满足：&lt;/p&gt;
&lt;p&gt;$\frac{P_r[M(x) = y]}{P_r[M(x&amp;rsquo;) = y]} \leq e^{\epsilon} \tag{25}$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理 2&lt;/strong&gt; 证明了，给定 token $t$ 的随机邻接列表 $C_r(t)$，RANTEXT 机制满足 ε-LDP。定理 2 的证明见附录 B。&lt;/p&gt;
&lt;h2 id=&#34;vi-实验&#34;&gt;VI. 实验
&lt;/h2&gt;&lt;h4 id=&#34;a-实验设置&#34;&gt;A. 实验设置
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;数据集&lt;/strong&gt;：
对于开放式文本生成任务，我们使用了两个经典的NLP数据集：CNN/Daily Mail [29] 用于新闻文章，Wikitext-103-v1 [31] 用于维基百科文章。对于实际应用，我们使用了ArXiv数据集 [32] 来撰写科学论文。这些数据集涵盖了大量的事件和个人。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基准&lt;/strong&gt;：
InferDPT 是首个实际应用于文本生成任务中实现差分隐私的隐私保护推理框架 [33]。由于目前没有其他同类型的框架，因此我们没有将 InferDPT 与其他框架进行比较。对于扰动模块中的差分隐私机制，我们将 RANTEXT 与现有的最先进机制，SANTEXT+ [12] 和 CUSTEXT+ [13] 在其默认设置下进行比较。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;评估指标&lt;/strong&gt;：
遵循以往的开放式文本生成工作 [23]，[33]，我们使用文章的前 50 个标记作为原始文档 Doc，这些需要保护的部分。我们使用 Doc 的继续写作部分，称为 Gen，长度为 100 个标记。标记由 GPT-2 的分词器函数 [34] 进行计数。与 [35] 一致，采用了以下三种指标来评估生成文本在开放式生成任务中的质量：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;多样性 (Diversity)&lt;/strong&gt;
该指标通过计算独特的n-gram重复率来衡量文本的多样性，计算公式如下：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$\text{diversity} = \frac{1}{4} \sum_{n=2}^4 \frac{| \text{unique n-grams(Gen)} |}{| \text{total n-grams(Gen)} |}$&lt;/p&gt;
&lt;p&gt;较低的得分表示模型容易产生重复内容，而较高的得分则表明模型使用了更广泛的词汇。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;MAUVE [36]&lt;/strong&gt;
该指标用于评估语言模型生成的文本与人工编写的目标继续文本之间的相似性。在该指标中，较高的得分是期望的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;连贯性 (Coherence)&lt;/strong&gt;
连贯性通过计算文档 &lt;code&gt;Doc&lt;/code&gt; 和继续文本 &lt;code&gt;Gen&lt;/code&gt; 的嵌入向量之间的余弦相似性来衡量，计算公式如下：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$\text{COH(Doc, Gen)} = \frac{\text{SimCSE(Doc)} \cdot \text{SimCSE(Gen)}}{| \text{SimCSE(Doc)} | \cdot | \text{SimCSE(Gen)} |}$&lt;/p&gt;
&lt;p&gt;其中，SimCSE(x) 代表预训练模型 [37]。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实现&lt;/strong&gt;
我们在一个集群上运行实验，配备有 NVIDIA RTX A6000 GPU 和 Intel Xeon Gold 6130 2.10 GHz CPU。所有机制的实现均使用 Python 语言完成。对于黑盒推理，我们使用 GPT-4 [14] 作为远程大语言模型，温度参数设置为 0.5。相应地，GPT-4 的标记词汇表使用 cl100k base [38]。我们将 cl100k base 的前 11,000 个英文标记作为 Vt。对于嵌入函数 φ(·)，我们选择 text-embedding-ada-002 [39]，该函数使用与 GPT-4 训练过程中相同的标记词汇表 cl100k base。我们使用 Vicuna-7b-4bit [40] 和 Llama2-7b-4bit [21] 作为提取模块的本地语言模型，温度参数设置为 0.5。&lt;/p&gt;
&lt;h3 id=&#34;b-效用评估-evaluation-of-utility&#34;&gt;B. &lt;strong&gt;效用评估 (Evaluation of Utility)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;我们评估了在扰动模块中使用不同差分隐私机制生成的 InferDPT 输出质量，使用提取模块中的 Vicuna-7b-4bit (3.89GB) 在不同数据集上的表现。表 V 显示了 InferDPT 生成的质量与非隐私的 GPT-4 生成质量的比较：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206154218412.png&#34;
	width=&#34;1522&#34;
	height=&#34;662&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206154218412_hu12757519237573247356.png 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206154218412_hu572430292615687628.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241206154218412&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;229&#34;
		data-flex-basis=&#34;551px&#34;
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;尽管上传的提示（prompt）受到了差分隐私的扰动，但 InferDPT 生成的文本质量与非隐私的 GPT-4 生成的文本质量相当，并且优于本地模型的输出。这证明了 InferDPT 的有效性。&lt;/li&gt;
&lt;li&gt;GPT-4 生成的文本质量通常优于本地模型直接生成的文本。&lt;/li&gt;
&lt;li&gt;在相同隐私参数 ε 下，InferDPT 中使用 RANTEXT 生成的文本质量与 CUSTEXT+ 相当，并且优于 SANTEXT+。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们还测量了 InferDPT 每次推理的时间成本，结果见表 VI。实验结果表明，InferDPT 提供了隐私保护，同时没有产生巨大的时间开销。我们还调查了 InferDPT 是否能够在不同本地模型中工作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206154459156.png&#34;
	width=&#34;794&#34;
	height=&#34;278&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206154459156_hu17781280429639485369.png 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206154459156_hu6992587025998647198.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241206154459156&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;285&#34;
		data-flex-basis=&#34;685px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;正如表 VII 所示，实验结果证明 InferDPT 在不同模型中仍然有效。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206154536731.png&#34;
	width=&#34;1515&#34;
	height=&#34;440&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206154536731_hu7768346121373081312.png 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206154536731_hu7338434310421378643.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241206154536731&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;344&#34;
		data-flex-basis=&#34;826px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;我们进一步比较了 InferDPT 使用 Vicuna-7b-4bit 最终生成文本与 GPT-4 从原始提示生成的输出之间的余弦相似度。比较结果显示在表 VIII 中。在相同隐私参数 ε 下，三种数据集上的 RANTEXT 扰动生成的文本的余弦相似度接近于表现最好的 CUSTEXT+。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206154627728.png&#34;
	width=&#34;783&#34;
	height=&#34;502&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206154627728_hu4598467975981166615.png 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206154627728_hu15094036774587768838.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241206154627728&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;155&#34;
		data-flex-basis=&#34;374px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;此外，我们还研究了隐私参数 ε 对 RANTEXT 中随机邻接列表大小的概率分布的影响。如图 4 所示，我们使用 Cr/Vt 来表示随机邻接列表在整个标记词汇表中的比例。随着 ε 增加，RANTEXT 更倾向于出现较小尺寸的随机邻接列表。&lt;/p&gt;
&lt;h2 id=&#34;vii-针对隐私威胁的防御-defense-against-privacy-threat&#34;&gt;VII. &lt;strong&gt;针对隐私威胁的防御 (Defense Against Privacy Threat)&lt;/strong&gt;
&lt;/h2&gt;&lt;h3 id=&#34;a-输入推断攻击-input-inference-attack&#34;&gt;A. &lt;strong&gt;输入推断攻击 (Input Inference Attack)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;在输入推断攻击中 [12]，攻击者使用预训练的 BERT 模型从扰动版本的文档 Docp 恢复原始文档 Doc。BERT 模型通过掩码语言建模 [28] 进行训练，能够预测原始标记，方法是依次将扰动文本中的每个标记替换为特殊标记 &amp;ldquo;[MASK]&amp;quot;。这种方法利用了 BERT 理解上下文的能力，使其能够推断出被掩码的标记。如果输出标记与输入标记匹配，则攻击成功。随后，我们计算所有攻击的成功率，记为 rats。差分隐私的隐私保护度定义为 1 − rats。&lt;/p&gt;
&lt;p&gt;如图 5 所示，与 SANTEXT+ 和 RANTEXT+ 相比，RANTEXT 在输入推断攻击中提供了更好的隐私保护。实验结果表明，在 ε 值范围为 0.01 到 18.0 之间，RANTEXT 提供超过 80% 的隐私保护。特别是在 CNN/Daily Mail 数据集上，当 ε 值为 18.0 时，RANTEXT 的隐私保护是 SANTEXT+ 的 1.11 倍，是 CUSTEXT+ 的 1.41 倍。我们分析了实验结果，发现 BERT 无法识别 GPT-4 的标记。为了更全面地评估 RANTEXT 的安全性，我们在第 VII-C 节提出了利用 GPT-4 能力的自适应攻击方法，即 GPT 推理攻击。&lt;/p&gt;
&lt;h3 id=&#34;b-嵌入反转攻击-embedding-inversion-attack&#34;&gt;B. &lt;strong&gt;嵌入反转攻击 (Embedding Inversion Attack)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;嵌入反转攻击 [17] 计算扰动文档中每个标记的嵌入与词汇表中其他标记嵌入之间的距离，返回与其欧几里得距离最接近的前 K 个标记。实验在 top K = 1 和 10 的条件下进行。图 6 表明，在这两种条件下，SANTEXT+ 和 CUSTEXT+ 都容易受到嵌入反转攻击，表明它们提供的隐私保护水平相对较低。即使在 ε = 0.01 时，这些方法也只能为超过 40% 的原始文档提供隐私保护。随着 top K 从 1 增加到 10，SANTEXT+ 和 CUSTEXT+ 的隐私保护率变化不大。另一方面，RANTEXT 由于其随机邻接列表的设计，有效地阻止了攻击者利用邻接信息进行成功攻击，从而在此类攻击中表现出更强的隐私保护。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206155447226.png&#34;
	width=&#34;1618&#34;
	height=&#34;531&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206155447226_hu2186551056065881375.png 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206155447226_hu8143722568308899251.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241206155447226&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;304&#34;
		data-flex-basis=&#34;731px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;c-自适应攻击gpt推理攻击-gpt-inference-attack&#34;&gt;C. &lt;strong&gt;自适应攻击：GPT推理攻击 (GPT Inference Attack)&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;RANTEXT 对 GPT-4 的标记词汇表进行扰动。由于 GPT-4 能识别所有标记，因此假设 GPT-4 可以更好地恢复被 RANTEXT 扰动的文本。因此，我们提出了一种自适应攻击方法——GPT推理攻击。在该方法中，攻击者将扰动文本输入 GPT-4，并指示其恢复每个标记。如果恢复的标记与原始标记一致，则攻击成功。GPT推理攻击的提示见附录 D。图 5 显示了 GPT推理攻击的结果。GPT-4 在所有测试中比 BERT 具有更高的攻击成功率。这可能是由于 GPT-4 的更大规模和更好的理解能力，使其在推理攻击中更有效。在面对 GPT 推理攻击时，SANTEXT+ 和 CUSTEXT+ 的隐私保护率低于 RANTEXT，而 RANTEXT 保持了最佳的隐私保护。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206155552152.png&#34;
	width=&#34;1610&#34;
	height=&#34;536&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206155552152_hu11536179040085547095.png 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206155552152_hu2913164283366427188.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241206155552152&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;300&#34;
		data-flex-basis=&#34;720px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;d-扰动生成中的隐私泄露&#34;&gt;D. &lt;strong&gt;扰动生成中的隐私泄露&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;我们进一步讨论了原始文档 Doc 是否会通过扰动生成结果 Genp 泄露。图 7 显示了 Doc 和 Genp 之间的余弦相似度。实验结果表明，RANTEXT 保持了原始文档 Doc 与扰动生成结果 Genp 之间的低语义相似度，表明通过扰动结果泄露隐私的风险较低。此外，我们通过检查原始文档中的 n-gram 词是否在扰动输出中重复来衡量隐私泄露。在原始文本和扰动输出中都找到的 n-gram 词被视为泄露。如表 IX 所示，即使是非隐私提示，原始文档的隐私泄露也不到 11%。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206160207415.png&#34;
	width=&#34;645&#34;
	height=&#34;620&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206160207415_hu7202164887462472562.png 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206160207415_hu11661822535527173895.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241206160207415&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;104&#34;
		data-flex-basis=&#34;249px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206160101477.png&#34;
	width=&#34;1531&#34;
	height=&#34;493&#34;
	srcset=&#34;https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206160101477_hu10227667281407578236.png 480w, https://JiangZhiyu-1024.github.io/p/inferdpt%E9%9D%A2%E5%90%91%E9%BB%91%E7%9B%92%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E6%8E%A8%E7%90%86/image-20241206160101477_hu4806271135479395857.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20241206160101477&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;310&#34;
		data-flex-basis=&#34;745px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;e-隐私与效用之间的权衡&#34;&gt;E. &lt;strong&gt;隐私与效用之间的权衡&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;随后，我们比较了 RANTEXT、CUSTEXT+ 和 SANTEXT+ 在隐私与效用之间的权衡。我们使用每种机制在顶部 1 的嵌入倒转攻击下的隐私保护率作为衡量每个方案隐私级别的指标。我们比较了在相同生成文本质量下，RANTEXT、CUSTEXT+ 和 SANTEXT+ 在 CNN/Daily Mail 数据集上的隐私保护水平，使用 Vicuna-7b-4bit（3.89GB）作为提取模块。如图 8 所示，RANTEXT 在相同的生成文本质量下提供了最佳的隐私保护，超过了 SANTEXT+ 和 CUSTEXT+。总结来说，RANTEXT 相较于 SANTEXT+ 和 CUSTEXT+ 展现了在差分隐私机制下对各种攻击的强大隐私保护，同时能够生成高质量的文本。&lt;/p&gt;
&lt;h2 id=&#34;viii-相关工作&#34;&gt;VIII. &lt;strong&gt;相关工作&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;CipherGPT [9] 已将同态加密 [41] 应用于基于 Transformer 的语言模型，能够在加密数据上执行推理。然而，这导致了一个目前无法完全解决的问题：显著的计算时间和通信成本：推理一个令牌需要 24 分钟和 93 GB 的带宽，导致部署变得不切实际。PromptPATE [42] 和 DP-OPT [43] 利用差分隐私（DP）重建用于分类任务的数据集，从而在提示学习（调优）过程中保护训练数据的隐私。然而，它们专注于分类任务，未能解决差分隐私噪声引入的信息失真问题。Tang 等人 [44] 提出了一种差分隐私方法，用于生成隐私保护示例以进行上下文学习。他们部署了一个大型语言模型，通过少量生成的差分隐私推理来重建私密示例。他们的工作也主要集中在分类任务上。&lt;/p&gt;
&lt;h2 id=&#34;ix-结论&#34;&gt;IX. &lt;strong&gt;结论&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;本文探讨了在黑箱大语言模型执行文本生成任务时隐私泄露的挑战，并提出了 InferDPT 作为一种潜在解决方案。此外，我们提出了 RANTEXT，一种新型的差分隐私算法，旨在通过使用指数机制增强大语言模型中的用户隐私保护。我们期望我们的解决方案和研究成果能够为当前的隐私挑战提供技术性见解，并为未来在新兴大语言模型中的隐私保护探索提供启示。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
